{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec2d55bc-9ba2-4a01-9351-81aff784df0c",
   "metadata": {},
   "source": [
    "- 시작 하기 전에\n",
    "\n",
    "이 코드는 python 3.10 버전 기준으로 돌아가는 코드입니다. 해당 버전에서 아래 라이브러리들을 전부 설치해주셔야 돌아갑니다\n",
    "\n",
    "그리고 처음부터 전부 작동시키면 하루정도 걸려야 다 돌아가니 가급적 제가드린 데이터파일(중간 세이브 파일 개념)을 사용해주세요.\n",
    "\n",
    "밑바닥부터 다 돌려보고 싶다면 dataguide에서 데이터 받아서 돌리시면 됩니다만 권장하진 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cc41eba-35c1-4218-a08e-6de2a7fd7edb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# 수집할 지표의 티커(symbol) 목록\n",
    "tickers = {\n",
    "    'KRW_USD_Exchange': 'KRW=X', # 원/달러 환율\n",
    "    # 추가적인 지표를 여기에 추가\n",
    "}\n",
    "\n",
    "# 데이터프레임을 저장할 딕셔너리\n",
    "data = {}\n",
    "\n",
    "# 각 티커에 대해 데이터 다운로드\n",
    "for name, ticker in tickers.items():\n",
    "    # 데이터 다운로드\n",
    "    df = yf.download(ticker, start='2007-9-30', end='2024-12-01', interval='1mo')\n",
    "    # 월말 데이터로 리샘플링\n",
    "    df = df.resample('M').last()\n",
    "    # 필요한 열만 선택\n",
    "    df = df[['Adj Close']]\n",
    "    # 열 이름 변경\n",
    "    df.columns = [name]\n",
    "    # 딕셔너리에 저장\n",
    "    data[name] = df\n",
    "\n",
    "# 모든 데이터를 하나의 데이터프레임으로 병합\n",
    "result = pd.concat(data.values(), axis=1)\n",
    "\n",
    "# 결과 출력\n",
    "result.to_csv('KRW_USD_Exchange.csv')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606ccafe-c18f-44c8-84ee-808d55daeaef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\fawke\\anaconda3\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\fawke\\anaconda3\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\fawke\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\fawke\\anaconda3\\lib\\site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\fawke\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\fawke\\anaconda3\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\fawke\\anaconda3\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\fawke\\anaconda3\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\fawke\\appdata\\roaming\\python\\python311\\site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\fawke\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\fawke\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\fawke\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64657c3-f098-4eab-9c40-bf899ba7b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import hotshot as hs\n",
    "# import networkx as nx  # networkx 임포트\n",
    "# from causalnex.structure.notears import from_pandas\n",
    "# from causalnex.network import BayesianNetwork\n",
    "# from econml.dr import DRLearner\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 팩터 전략별로 필요한 데이터를 계산하여 monthly_merged_df에 추가합니다.\n",
    "\n",
    "if 'monthly_merged_df' not in globals():\n",
    "    monthly_merged_df = pd.read_csv(\n",
    "        'data/merged_df_monthly_preprocessing.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6328d54-d6a3-419b-9a36-a97435953b07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CSV 부르기 및 기본적인 전처리 : 돌릴 필요 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa522af-a990-4a33-b348-445c51e6c468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 통합한 월별 데이터 파일이 존재합니다. 해당 CSV를 불러옵니다.\n",
      "월별 CSV를 불러왔습니다.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame을 저장할 리스트 생성\n",
    "df_list = []\n",
    "\n",
    "# 1. 'data' 폴더 내에 'KSIF'가 포함된 CSV 파일 목록 가져오기\n",
    "file_list = glob.glob('data/*KSIF*.csv')\n",
    "\n",
    "# 파일이 존재하는지 확인\n",
    "if not file_list:\n",
    "    print(\"패턴에 맞는 파일을 찾을 수 없습니다.\")\n",
    "elif os.path.exists('data/merged_df_monthly.csv'):\n",
    "    print(\"이미 통합한 월별 데이터 파일이 존재합니다. 해당 CSV를 불러옵니다.\")\n",
    "    merged_df_backup = pd.read_csv(\n",
    "        'data/merged_df_monthly.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "        parse_dates=True  # 인덱스를 datetime으로 파싱\n",
    "    )\n",
    "    print(\"월별 CSV를 불러왔습니다.\")\n",
    "elif os.path.exists('data/merged_data.csv'):\n",
    "    print(\"이미 통합한 일별 데이터 파일이 존재합니다. 해당 CSV를 월별로 전환합니다.\")\n",
    "    merged_df_backup = pd.read_csv(\n",
    "        'data/merged_data.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "    # 인덱스를 datetime으로 변환\n",
    "    merged_df_backup.index = pd.to_datetime(merged_df_backup.index, errors='coerce')\n",
    "    \n",
    "    # 월별 리샘플링\n",
    "    merged_df_backup = merged_df_backup.resample('M').last()\n",
    "    \n",
    "    # 월별 데이터 저장\n",
    "    merged_df_backup.to_csv('data/merged_df_monthly.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"월별 리샘플링된 데이터가 'merged_df_monthly.csv'로 저장되었습니다.\")\n",
    "    print(\"월별 CSV를 불러왔습니다.\")\n",
    "else:\n",
    "    # tqdm을 사용하여 진행 상황 표시\n",
    "    for file_path in tqdm(file_list, desc=\"파일 처리 중\"):\n",
    "        # 각 CSV 파일 읽기 (적절한 인코딩과 인덱스 설정)\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                skiprows=8,\n",
    "                header=[0, 1, 2, 3, 4, 5],\n",
    "                index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "                encoding='cp949',\n",
    "                parse_dates=True\n",
    "            )\n",
    "        except UnicodeDecodeError:\n",
    "            # 'cp949' 인코딩이 안 될 경우 'euc-kr'로 시도\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                skiprows=8,\n",
    "                header=[0, 1, 2, 3, 4, 5],\n",
    "                index_col=0,\n",
    "                encoding='euc-kr',\n",
    "                parse_dates=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"파일 {file_path}를 로드하는 중 에러 발생: {e}\")\n",
    "            continue  # 에러 발생 시 다음 파일로 넘어감\n",
    "        \n",
    "        # 멀티인덱스 컬럼에 이름 지정\n",
    "        df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "        \n",
    "        # 인덱스 이름 지정 ('Date'로 설정)\n",
    "        df.index.name = 'Date'\n",
    "        \n",
    "        # 인덱스를 datetime으로 변환\n",
    "        df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "        \n",
    "        # 'Kind', 'Frequency' 레벨 제거하여 필요한 컬럼만 남김\n",
    "        df.columns = df.columns.droplevel(['Kind', 'Frequency'])\n",
    "        \n",
    "        # 리스트에 DataFrame 추가\n",
    "        df_list.append(df)\n",
    "    \n",
    "    # 2. 모든 DataFrame을 수평적으로 병합\n",
    "    print(\"DataFrame 병합 중...\")\n",
    "    merged_df_backup = pd.concat(df_list, axis=1)\n",
    "    del df_list  # 리스트 메모리에서 삭제\n",
    "    gc.collect()  # 가비지 컬렉션 실행\n",
    "    \n",
    "    # 월별 리샘플링\n",
    "    print(\"월별 리샘플링 중...\")\n",
    "    merged_df_backup = merged_df_backup.resample('M').last()\n",
    "    \n",
    "    # 월별 데이터 저장\n",
    "    merged_df_backup.to_csv('data/merged_df_monthly.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"월별 리샘플링된 데이터가 'merged_df_monthly.csv'로 저장되었습니다.\")\n",
    "    \n",
    "    # 필요에 따라 일별 데이터를 저장하려면 아래 주석을 해제하세요.\n",
    "    # merged_df_backup.to_csv('data/merged_data.csv', encoding='utf-8-sig')\n",
    "    # print(\"모든 CSV 파일을 병합하여 'merged_data.csv'로 저장했습니다.\")\n",
    "\n",
    "    # 메모리 관리\n",
    "    del merged_df_backup\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993372a2-821d-46b6-b494-f828a95d8281",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m issues\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 점검 실행\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mcheck_dataframe_issues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#여기서 인덱스 2번이 뜨는 이유는 얘가 하루 더 있거등요 ㅇㅇ\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mcheck_dataframe_issues\u001b[1;34m(df_list)\u001b[0m\n\u001b[0;32m     10\u001b[0m issues \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_unique_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmismatched_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 기준 인덱스는 첫 번째 데이터프레임의 인덱스로 설정\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m base_index \u001b[38;5;241m=\u001b[39m \u001b[43mdf_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 각 데이터프레임 점검\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_list):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 1. 고유하지 않은 인덱스 확인\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def check_dataframe_issues(df_list):\n",
    "    \"\"\"\n",
    "    점검 함수: 데이터프레임 리스트에서 고유하지 않은 인덱스와 기준 인덱스 불일치 확인\n",
    "    Args:\n",
    "        df_list (list): pandas 데이터프레임들의 리스트\n",
    "    Returns:\n",
    "        dict: 문제를 가진 데이터프레임의 인덱스 (non_unique_index, mismatched_index)\n",
    "    \"\"\"\n",
    "    # 결과 저장용 딕셔너리\n",
    "    issues = {\"non_unique_index\": [], \"mismatched_index\": []}\n",
    "    \n",
    "    # 기준 인덱스는 첫 번째 데이터프레임의 인덱스로 설정\n",
    "    base_index = df_list[0].index\n",
    "\n",
    "    # 각 데이터프레임 점검\n",
    "    for i, df in enumerate(df_list):\n",
    "        # 1. 고유하지 않은 인덱스 확인\n",
    "        if not df.index.is_unique:\n",
    "            issues[\"non_unique_index\"].append(i)\n",
    "        \n",
    "        # 2. 기준 인덱스와 불일치 확인\n",
    "        if not base_index.equals(df.index):\n",
    "            issues[\"mismatched_index\"].append(i)\n",
    "\n",
    "    return issues\n",
    "\n",
    "# 점검 실행\n",
    "check_dataframe_issues(df_list)#여기서 인덱스 2번이 뜨는 이유는 얘가 하루 더 있거등요 ㅇㅇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f466bdd7-d688-49ec-8d17-d66b687424ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['수정주가(원)', 'PER(보통)(배)', 'PER(직전4분기)(배)', 'PER(보통,자사주차감)(배)',\n",
       "       'BPS(발표기준기말주식수)(원)', 'BPS(자사주차감)(원)', '상장주식수(주)', '시가총액 (평균)(원)',\n",
       "       '상장주식수 (보통)(주)', '매출총이익(원)', '총자산(원)', '유동자산(원)', '현금및현금성자산(원)',\n",
       "       '유동부채(원)', '단기차입금(원)', '이연법인세부채(원)', '거래대금(원)', '관리종목지정사유', '기타포괄손익(원)',\n",
       "       '베타 (M,3Yr)', '베타 (D,1Yr)', '보통주자본금(원)', '수익률(%)', '수익률 (1개월)(%)',\n",
       "       '수정주가 (52주 최고)(원)', '유무형자산상각비(원)', '이익잉여금(원)', 'Unnamed: 3182_level_4',\n",
       "       '이익잉여금(천원)'],\n",
       "      dtype='object', name='item Name')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_backup.columns.get_level_values(3).unique()#우리 데이터 뭐있나 함 볼까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24f2a1-46a7-4777-bd42-1f82fb9cf369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 월별 데이터로 작업할 merged_df 생성\n",
    "merged_df = merged_df_backup.copy()\n",
    "\n",
    "# 1. \"(원)\"으로 끝나는 컬럼 처리\n",
    "# 'item Name'이 '(원)'으로 끝나는 컬럼 선택\n",
    "won_mask = merged_df.columns.get_level_values('item Name').str.endswith('(원)')\n",
    "\n",
    "# 쉼표 제거 및 숫자 변환을 벡터화된 연산으로 수행\n",
    "# 문자열 'None', 'nan', '', 'N/A' 등을 NaN으로 변환\n",
    "merged_df.loc[:, won_mask] = (\n",
    "    merged_df.loc[:, won_mask]\n",
    "    .astype(str)  # 모든 데이터를 문자열로 변환\n",
    "    .replace(',', '', regex=True)  # 쉼표 제거\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A'], np.nan)  # 비정상적인 값들을 NaN으로 변환\n",
    "    .apply(pd.to_numeric, errors='coerce')  # 숫자로 변환 (변환 불가 시 NaN)\n",
    ")\n",
    "\n",
    "print(\"'(원)' 컬럼의 문자열 변환 및 숫자 변환 완료\")\n",
    "\n",
    "# 2. '홀딩스', '지주', '스펙'으로 끝나는 종목 제거\n",
    "pattern = ('홀딩스', '지주', '스펙', '스팩')\n",
    "symbol_names = merged_df.columns.get_level_values('Symbol Name')\n",
    "mask = symbol_names.str.endswith(pattern)\n",
    "merged_df = merged_df.loc[:, ~mask]\n",
    "\n",
    "# 3. '관리종목지정사유' 처리\n",
    "# '관리종목지정사유'가 있는 종목 추출\n",
    "management_mask = merged_df.columns.get_level_values('item Name') == '관리종목지정사유'\n",
    "management_df = merged_df.loc[:, management_mask]\n",
    "\n",
    "# 인덱스를 datetime 형태로 변환\n",
    "merged_df.index = pd.to_datetime(merged_df.index, errors='coerce')\n",
    "\n",
    "# 각 종목별로 처리\n",
    "for symbol in management_df.columns.get_level_values('Symbol').unique():\n",
    "    symbol_management = management_df.loc[:, management_df.columns.get_level_values('Symbol') == symbol]\n",
    "    \n",
    "    # NaN이 아닌 첫 번째 날짜 찾기\n",
    "    dates_with_issue = symbol_management[symbol_management.notna().any(axis=1)].index\n",
    "    \n",
    "    if not dates_with_issue.empty:\n",
    "        try:\n",
    "            # 이슈 발생 날짜\n",
    "            issue_date = dates_with_issue[0]\n",
    "            \n",
    "            # 해당 Symbol의 데이터를 처리\n",
    "            symbol_mask = merged_df.columns.get_level_values('Symbol') == symbol\n",
    "            price_mask = merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "            other_mask = symbol_mask & ~price_mask\n",
    "            \n",
    "            # 이슈 발생 월부터 이후 데이터에 대해 NaN으로 설정 (수정주가는 제외)\n",
    "            merged_df.loc[merged_df.index >= issue_date, other_mask] = np.nan\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing symbol: {symbol}, issue_date: {issue_date}, Error: {e}\")\n",
    "\n",
    "print('관리종목 포트폴리오 정상화')\n",
    "\n",
    "# 4. '거래대금(원)' 기반 종목 제거\n",
    "trading_value_mask = merged_df.columns.get_level_values('item Name') == '거래대금(원)'\n",
    "trading_value_df = merged_df.loc[:, trading_value_mask]\n",
    "\n",
    "# 인덱스를 datetime으로 변환\n",
    "trading_value_df.index = pd.to_datetime(trading_value_df.index)\n",
    "\n",
    "# 2014년 이후 데이터 선택\n",
    "trading_value_df = trading_value_df[trading_value_df.index >= '2014-01-31']\n",
    "\n",
    "# 문자열을 숫자로 변환 (오류 발생 시 NaN 처리)\n",
    "trading_value_df = trading_value_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 거래대금이 4천만원 이하인 경우 True, NaN은 False로 처리\n",
    "low_trading_value = (trading_value_df <= 40000000).fillna(False)\n",
    "\n",
    "# 각 Symbol마다 거래대금이 4천만원 이하인 달이 하나라도 있는지 확인\n",
    "symbols_to_remove = low_trading_value.any(axis=0)\n",
    "symbols_to_remove = symbols_to_remove[symbols_to_remove].index.get_level_values('Symbol').unique().tolist()\n",
    "\n",
    "# 해당 Symbol 제거\n",
    "symbol_mask = merged_df.columns.get_level_values('Symbol').isin(symbols_to_remove)\n",
    "merged_df = merged_df.loc[:, ~symbol_mask]\n",
    "\n",
    "print('market impact 조정 완료')\n",
    "\n",
    "# 5. 수정주가 기반 1개월 수익률 계산\n",
    "# 인덱스를 datetime으로 변환\n",
    "merged_df.index = pd.to_datetime(merged_df.index)\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = merged_df.loc[:, price_mask]\n",
    "\n",
    "# 월별 수익률 계산\n",
    "returns_df = price_df.pct_change()\n",
    "\n",
    "# 'item Name'을 '1개월 수익률(계산)'으로 변경\n",
    "returns_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, item, '1개월 수익률(계산)') for symbol, symbol_name, item in zip(\n",
    "        returns_df.columns.get_level_values('Symbol'),\n",
    "        returns_df.columns.get_level_values('Symbol Name'),\n",
    "        returns_df.columns.get_level_values('item')\n",
    "    )],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 수익률 데이터를 merged_df에 추가\n",
    "merged_df = pd.concat([merged_df, returns_df], axis=1)\n",
    "\n",
    "print('1개월 수익률 계산 완료')\n",
    "\n",
    "# 6. 결측치를 직전 값으로 대체\n",
    "merged_df = merged_df.fillna(method='ffill')\n",
    "\n",
    "print(\"전처리 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba780af-3c56-4772-b5c9-50d29dbc54ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('data/merged_df_monthly_preprocessing.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483dc094-5740-457f-9e86-f6022005d452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol   Symbol Name  item        item Name       \n",
       "A000660  SK하이닉스       S410000700  수정주가(원)               int64\n",
       "                      6000701101  PER(보통)(배)          float64\n",
       "                      6000701007  PER(직전4분기)(배)       float64\n",
       "                      6000701006  PER(보통,자사주차감)(배)    float64\n",
       "A373220  LG에너지솔루션     S410000700  수정주가(원)             float64\n",
       "                                                       ...   \n",
       "A900030  연합과기         S410000700  1개월 수익률(계산)         float64\n",
       "A900060  중국식품포장       S410000700  1개월 수익률(계산)         float64\n",
       "A900150  성융광전투자       S410000700  1개월 수익률(계산)         float64\n",
       "A950030  네프로아이티       S410000700  1개월 수익률(계산)         float64\n",
       "A950070  중국고섬         S410000700  1개월 수익률(계산)         float64\n",
       "Length: 58059, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_backup.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4290465-1b88-424e-9971-8e99a319a7a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 팩터값 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ee2c22-003a-4f71-8acd-265d6781415f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 팩터 전략별로 필요한 데이터를 계산하여 monthly_merged_df에 추가합니다.\n",
    "\n",
    "if 'monthly_merged_df' not in globals():\n",
    "    monthly_merged_df = pd.read_csv(\n",
    "        'data/merged_df_monthly_preprocessing.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "424f8216-865c-4d17-a2ac-66bacc9a1025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_high_pe_ratio.csv' 파일이 저장되었습니다.\n",
      "(206, 2052)\n",
      "'factor_high_pe_ratio_large_industry.csv' 파일이 저장되었습니다.\n",
      "'factor_high_pe_ratio_medium_industry.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 1: High P/E Ratio =====\n",
    "# 상위 20% 종목에 롱 포지션, 하위 20% 종목에 숏 포지션을 취하는 전략\n",
    "\n",
    "# 'PER(직전4분기)(배)' 데이터 추출\n",
    "per_mask = monthly_merged_df.columns.get_level_values('item Name') == 'PER(보통,자사주차감)(배)'\n",
    "per_df = monthly_merged_df.loc[:, per_mask]\n",
    "per_df.columns = per_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 결측치 처리 전에 per_df의 데이터를 float 타입으로 변환\n",
    "per_df = per_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 결측치 처리\n",
    "per_df = per_df.replace(0, np.nan)\n",
    "per_df = per_df.replace(np.inf, np.nan)\n",
    "per_df = per_df.fillna(method='ffill')\n",
    "\n",
    "# 전체 종목에 대해 z-score 계산\n",
    "per_zscore = -per_df.apply(lambda x: (x - x.mean()) / x.std(), axis=1)\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore.to_csv('factor_high_pe_ratio.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 산업 분류 데이터 불러오기\n",
    "try:\n",
    "    industry_df = pd.read_csv(\n",
    "        'data/industry.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    industry_df = pd.read_csv(\n",
    "        'data/industry.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "        encoding='cp949',\n",
    "        parse_dates=True  # 인덱스를 datetime으로 파싱\n",
    "    )\n",
    "    \n",
    "# 멀티인덱스 설정\n",
    "industry_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "industry_df.index.name = 'Date'\n",
    "\n",
    "# '한국표준산업분류10차(대분류)', '한국표준산업분류10차(중분류)' 데이터 추출\n",
    "industry_large_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(대분류)'\n",
    "industry_medium_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(중분류)'\n",
    "\n",
    "industry_large_df = industry_df.loc[:, industry_large_mask]\n",
    "industry_large_df.columns = industry_large_df.columns.droplevel(['item', 'item Name'])\n",
    "industry_medium_df = industry_df.loc[:, industry_medium_mask]\n",
    "industry_medium_df.columns = industry_medium_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# PER 데이터와 산업 분류 데이터의 인덱스 및 컬럼 정렬\n",
    "per_df, industry_large_df = per_df.align(industry_large_df, join='inner', axis=1)\n",
    "per_df, industry_medium_df = per_df.align(industry_medium_df, join='inner', axis=1)\n",
    "\n",
    "# 디버깅 출력을 위한 함수\n",
    "def debug_print(message, df=None):\n",
    "    print(message)\n",
    "    if df is not None:\n",
    "        print(df.head())\n",
    "        print(df.shape)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# 산업별로 z-score 계산\n",
    "def industry_zscore(per_series, industry_series):\n",
    "    df = pd.DataFrame({'PER': per_series, 'Industry': industry_series})\n",
    "    # NaN 값이 있는 행 제거\n",
    "    df = df.dropna()\n",
    "    # 산업별 그룹화 및 z-score 계산\n",
    "    grouped = df.groupby('Industry')\n",
    "    z_scores = grouped['PER'].transform(lambda x: -(x - x.mean()) / x.std() if x.std() != 0 else 0)\n",
    "    return z_scores\n",
    "\n",
    "# 대분류 산업별 z-score\n",
    "per_zscore_large = per_df.copy()\n",
    "print(per_zscore_large.shape)\n",
    "for date in per_zscore_large.index:\n",
    "    per_zscore_large.loc[date] = industry_zscore(per_df.loc[date], industry_large_df.loc[date])\n",
    "    # 디버깅 출력\n",
    "    # debug_print(f\"[Large Industry] Date: {date}\", per_zscore_large.loc[[date]])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "per_zscore_large.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'PER_zscore_large', 'PER_zscore_large') for symbol, symbol_name in per_zscore_large.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore_large.to_csv('factor_high_pe_ratio_large_industry.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio_large_industry.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 중분류 산업별 z-score\n",
    "per_zscore_medium = per_df.copy()\n",
    "for date in per_zscore_medium.index:\n",
    "    per_zscore_medium.loc[date] = industry_zscore(per_df.loc[date], industry_medium_df.loc[date])\n",
    "    # 디버깅 출력\n",
    "    # debug_print(f\"[Medium Industry] Date: {date}\", per_zscore_medium.loc[[date]])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "per_zscore_medium.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'PER_large', 'PER_large') for symbol, symbol_name in per_zscore_medium.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "# 팩터 값 저장\n",
    "per_zscore_medium.to_csv('factor_high_pe_ratio_medium_industry.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio_medium_industry.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore.to_csv('factor_high_pe_ratio.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b1ba1e-178a-436f-b550-6a1fa21dd198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_hml.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 2: HML (Kang, 2013) =====\n",
    "# Book-to-Market Ratio 계산 (BPS / 주가)\n",
    "\n",
    "# 'BPS(자사주차감)(원)' 데이터 추출\n",
    "bps_mask = monthly_merged_df.columns.get_level_values('item Name') == 'BPS(자사주차감)(원)'\n",
    "bps_df = monthly_merged_df.loc[:, bps_mask]\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = monthly_merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = monthly_merged_df.loc[:, price_mask]\n",
    "\n",
    "# 컬럼 레벨 중 'item'과 'item Name'을 제거하여 컬럼 정렬\n",
    "bps_df.columns = bps_df.columns.droplevel(['item', 'item Name'])\n",
    "price_df.columns = price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "bps_df, price_df = bps_df.align(price_df, join='inner', axis=0)\n",
    "bps_df, price_df = bps_df.align(price_df, join='inner', axis=1)\n",
    "\n",
    "# 계산 전에 데이터 타입 변환\n",
    "bps_df = bps_df.apply(pd.to_numeric, errors='coerce')\n",
    "price_df = price_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Book-to-Market Ratio 계산\n",
    "bm_ratio_df = bps_df / price_df\n",
    "\n",
    "# 결측치 처리\n",
    "bm_ratio_df = bm_ratio_df.replace([np.inf, -np.inf], np.nan)\n",
    "bm_ratio_df = bm_ratio_df.fillna(method='ffill')\n",
    "\n",
    "# 멀티레벨 컬럼 구조 재설정\n",
    "bm_ratio_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'BM Ratio', 'BM Ratio') for symbol, symbol_name in bm_ratio_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "bm_ratio_df.to_csv('factor_hml.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_hml.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e451f8b-6323-46bf-aa1c-ae95be7984ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_momentum.csv', 'factor_momentum_zscore.csv', 'factor_momentum_large_industry.csv', 'factor_momentum_medium_industry.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 5: Momentum 전략 =====\n",
    "# 지난 12-1개월 수익률 계산 (직전 1개월은 제외)\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = monthly_merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = monthly_merged_df.loc[:, price_mask]\n",
    "price_df.columns = price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 타입 변환\n",
    "price_df = price_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "price_df = price_df.sort_index()\n",
    "\n",
    "# 결측치 처리\n",
    "price_df = price_df.fillna(method='ffill')\n",
    "\n",
    "# 12개월 전 가격과 1개월 전 가격 추출\n",
    "price_12m_ago = price_df.shift(12)\n",
    "price_1m_ago = price_df.shift(1)\n",
    "\n",
    "# 모멘텀 계산\n",
    "momentum_df = (price_1m_ago - price_12m_ago) / price_12m_ago\n",
    "\n",
    "# 결측치 처리\n",
    "momentum_df = momentum_df.replace([np.inf, -np.inf], np.nan)\n",
    "momentum_df = momentum_df.fillna(method='ffill')\n",
    "\n",
    "# 전체 종목에 대해 z-score 계산\n",
    "momentum_zscore = momentum_df.apply(lambda x: (x - x.mean()) / x.std(), axis=1)\n",
    "\n",
    "# 산업 분류 데이터 불러오기 (이미 불러온 industry_df 사용)\n",
    "# '한국표준산업분류11차(대분류)', '한국표준산업분류11차(중분류)' 데이터 추출\n",
    "industry_large_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(대분류)'\n",
    "industry_medium_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(중분류)'\n",
    "\n",
    "industry_large_df = industry_df.loc[:, industry_large_mask]\n",
    "industry_large_df.columns = industry_large_df.columns.droplevel(['item', 'item Name'])\n",
    "industry_medium_df = industry_df.loc[:, industry_medium_mask]\n",
    "industry_medium_df.columns = industry_medium_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 산업별로 z-score 계산\n",
    "def industry_zscore(per_series, industry_series):\n",
    "    df = pd.DataFrame({'PER': per_series, 'Industry': industry_series})\n",
    "    # NaN 값이 있는 행 제거\n",
    "    df = df.dropna()\n",
    "    # 산업별 그룹화 및 z-score 계산\n",
    "    grouped = df.groupby('Industry')\n",
    "    z_scores = grouped['PER'].transform(lambda x: -(x - x.mean()) / x.std() if x.std() != 0 else 0)\n",
    "    return z_scores\n",
    "\n",
    "\n",
    "# 대분류 산업별 z-score\n",
    "momentum_zscore_large = momentum_df.copy()\n",
    "for date in momentum_zscore_large.index:\n",
    "    momentum_zscore_large.loc[date] = industry_zscore(momentum_df.loc[date], industry_large_df.loc[date])\n",
    "\n",
    "# 중분류 산업별 z-score\n",
    "momentum_zscore_medium = momentum_df.copy()\n",
    "for date in momentum_zscore_medium.index:\n",
    "    momentum_zscore_medium.loc[date] = industry_zscore(momentum_df.loc[date], industry_medium_df.loc[date])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "# 원래의 컬럼 정보를 사용하여 멀티인덱스 생성\n",
    "momentum_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum', 'Momentum') for symbol, symbol_name in momentum_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_zscore', 'Momentum_zscore') for symbol, symbol_name in momentum_zscore.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore_large.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_large', 'Momentum_large') for symbol, symbol_name in momentum_zscore_large.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore_medium.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_medium', 'Momentum_medium') for symbol, symbol_name in momentum_zscore_medium.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "momentum_df.to_csv('factor_momentum.csv', encoding='utf-8-sig')\n",
    "momentum_zscore.to_csv('factor_momentum_zscore.csv', encoding='utf-8-sig')\n",
    "momentum_zscore_large.to_csv('factor_momentum_large_industry.csv', encoding='utf-8-sig')\n",
    "momentum_zscore_medium.to_csv('factor_momentum_medium_industry.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(\"'factor_momentum.csv', 'factor_momentum_zscore.csv', 'factor_momentum_large_industry.csv', 'factor_momentum_medium_industry.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f0bebdf-f11c-4477-9e8a-e2385681d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_retained_earnings.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 6: Retained Earnings and Market-to-Book =====\n",
    "# 이익잉여금(원) / 시가총액 계산\n",
    "\n",
    "# '이익잉여금(원)' 데이터 추출\n",
    "retained_earnings_mask = monthly_merged_df.columns.get_level_values('item Name') == '이익잉여금(원)'\n",
    "retained_earnings_df = monthly_merged_df.loc[:, retained_earnings_mask]\n",
    "\n",
    "# '시가총액 (평균)(원)' 데이터 추출\n",
    "market_cap_mask = monthly_merged_df.columns.get_level_values('item Name') == '시가총액 (평균)(원)'\n",
    "market_cap_df = monthly_merged_df.loc[:, market_cap_mask]\n",
    "\n",
    "# 컬럼 레벨 중 'item'과 'item Name'을 제거하여 컬럼 정렬\n",
    "retained_earnings_df.columns = retained_earnings_df.columns.droplevel(['item', 'item Name'])\n",
    "market_cap_df.columns = market_cap_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "retained_earnings_df, market_cap_df = retained_earnings_df.align(market_cap_df, join='inner', axis=0)\n",
    "retained_earnings_df, market_cap_df = retained_earnings_df.align(market_cap_df, join='inner', axis=1)\n",
    "\n",
    "# 데이터 타입 변환\n",
    "retained_earnings_df = retained_earnings_df.apply(pd.to_numeric, errors='coerce')\n",
    "market_cap_df = market_cap_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 이익잉여금 / 시가총액 계산\n",
    "re_mc_ratio_df = retained_earnings_df / market_cap_df\n",
    "\n",
    "# 결측치 처리\n",
    "re_mc_ratio_df = re_mc_ratio_df.replace([np.inf, -np.inf], np.nan)\n",
    "re_mc_ratio_df = re_mc_ratio_df.fillna(method='ffill')\n",
    "\n",
    "# 멀티레벨 컬럼 구조 재설정\n",
    "re_mc_ratio_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'RE/MC Ratio', 'RE/MC Ratio') for symbol, symbol_name in re_mc_ratio_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "re_mc_ratio_df.to_csv('factor_retained_earnings.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_retained_earnings.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ec265dd-fffe-4dda-a358-760292967329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 종목 수: 2053\n",
      "필터링된 종목 수: 2052\n",
      "일별 가격 데이터 타입 확인:\n",
      "[dtype('int64') dtype('float64')]\n",
      "일별 수익률 계산 완료. 종목 수: 2053\n",
      "시장 수익률 데이터 기간: 2007-10-21 00:00:00 ~ 2024-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "베타 계산 중: 100%|██████████████████████████████████████████████████████████████████| 206/206 [09:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_betting_against_beta.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 10: Betting Against Beta =====\n",
    "# 베타를 직접 계산하여 역수를 팩터 값으로 사용\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 전처리된 월별 데이터에서 종목 리스트와 기간 추출\n",
    "symbols = monthly_merged_df.columns.get_level_values('Symbol').unique()\n",
    "dates = monthly_merged_df.index.unique()\n",
    "\n",
    "# 각 종목별로 시작 날짜 추출\n",
    "symbol_start_dates = {}\n",
    "for symbol in symbols:\n",
    "    # 해당 종목의 컬럼 선택\n",
    "    symbol_cols = monthly_merged_df.loc[:, monthly_merged_df.columns.get_level_values('Symbol') == symbol]\n",
    "    # 해당 종목의 데이터가 있는 날짜 추출\n",
    "    symbol_data = symbol_cols.dropna(how='all')\n",
    "    # 데이터가 있는 경우\n",
    "    if not symbol_data.empty:\n",
    "        start_date = symbol_data.index.min()\n",
    "        # 시작 날짜에서 30일을 뺌\n",
    "        adjusted_start_date = start_date - pd.Timedelta(days=30)\n",
    "        # daily_df의 시작 날짜와 비교하여 실제 시작 날짜 결정\n",
    "        symbol_start_dates[symbol] = adjusted_start_date\n",
    "    else:\n",
    "        # 데이터가 없는 경우 최소 날짜 설정\n",
    "        symbol_start_dates[symbol] = pd.to_datetime('2000-01-01')  # 필요에 따라 최소 날짜 설정\n",
    "\n",
    "print(f\"전처리된 종목 수: {len(symbols)}\")\n",
    "\n",
    "# 2. 일별 데이터 로드 (data/KSIF_1.csv 파일)\n",
    "file_path = 'data/KSIF_1.csv'\n",
    "\n",
    "try:\n",
    "    daily_df = pd.read_csv(\n",
    "        file_path,\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='cp949',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    daily_df = pd.read_csv(\n",
    "        file_path,\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='euc-kr',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"파일 {file_path}를 로드하는 중 에러 발생: {e}\")\n",
    "    raise e  # 에러 발생 시 종료\n",
    "\n",
    "# 멀티인덱스 컬럼 이름 지정\n",
    "daily_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "daily_df.index.name = 'Date'\n",
    "\n",
    "# 'Kind', 'Frequency' 레벨 제거\n",
    "daily_df.columns = daily_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "# 필요한 종목(Symbol)만 선택\n",
    "symbol_mask = daily_df.columns.get_level_values('Symbol').isin(symbols)\n",
    "daily_df = daily_df.loc[:, symbol_mask]\n",
    "\n",
    "print(f\"필터링된 종목 수: {len(daily_df.columns.get_level_values('Symbol').unique())}\")\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = daily_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "daily_price_df = daily_df.loc[:, price_mask]\n",
    "daily_price_df.columns = daily_price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "daily_price_df = (\n",
    "    daily_price_df\n",
    "    .astype(str)  # 모든 데이터를 문자열로 변환\n",
    "    .replace(',', '', regex=True)  # 쉼표 제거\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)  # 비정상적인 값들을 NaN으로 변환\n",
    "    .apply(pd.to_numeric, errors='coerce')  # 숫자로 변환 (변환 불가 시 NaN)\n",
    ")\n",
    "\n",
    "# 데이터 타입 확인\n",
    "print(\"일별 가격 데이터 타입 확인:\")\n",
    "print(daily_price_df.dtypes.unique())\n",
    "\n",
    "# 종목별 일별 수익률 계산\n",
    "daily_returns_dict = {}\n",
    "for symbol in symbols:\n",
    "    if symbol in daily_price_df.columns:\n",
    "        symbol_price = daily_price_df[symbol]\n",
    "        if not symbol_price.empty:\n",
    "            # 해당 종목의 시작 날짜 계산\n",
    "            start_date = symbol_start_dates[symbol]\n",
    "            # 시작 날짜부터 데이터 선택\n",
    "            symbol_price = symbol_price.loc[start_date:]\n",
    "            # 수익률 계산\n",
    "            symbol_returns = symbol_price.pct_change().dropna()\n",
    "            daily_returns_dict[symbol] = symbol_returns\n",
    "        else:\n",
    "            # 해당 종목의 데이터가 없는 경우\n",
    "            daily_returns_dict[symbol] = pd.Series(dtype=float)\n",
    "    else:\n",
    "        daily_returns_dict[symbol] = pd.Series(dtype=float)\n",
    "\n",
    "print(f\"일별 수익률 계산 완료. 종목 수: {len(daily_returns_dict)}\")\n",
    "\n",
    "# 시장 수익률 계산 (종가지수(포인트) 기반)\n",
    "try:\n",
    "    market_df = pd.read_csv(\n",
    "        'data/kor_market.csv',\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='cp949',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    market_df = pd.read_csv(\n",
    "        'data/kor_market.csv',\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='euc-kr',\n",
    "        parse_dates=True\n",
    "    )\n",
    "\n",
    "# 멀티인덱스 컬럼 이름 지정\n",
    "market_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "market_df.index.name = 'Date'\n",
    "\n",
    "# 'Kind', 'Frequency' 레벨 제거\n",
    "market_df.columns = market_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "# '종가지수(포인트)' 데이터 추출\n",
    "index_mask = market_df.columns.get_level_values('item Name') == '종가지수(포인트)'\n",
    "index_df = market_df.loc[:, index_mask]\n",
    "\n",
    "# '코스피'와 '코스닥' 지수만 선택\n",
    "symbol_names = index_df.columns.get_level_values('Symbol Name')\n",
    "kospi_kosdaq_mask = (symbol_names == '코스피') | (symbol_names == '코스닥')\n",
    "kospi_kosdaq_indices = index_df.loc[:, kospi_kosdaq_mask]\n",
    "kospi_kosdaq_indices.columns = kospi_kosdaq_indices.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "kospi_kosdaq_indices = (\n",
    "    kospi_kosdaq_indices\n",
    "    .astype(str)\n",
    "    .replace(',', '', regex=True)\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)\n",
    "    .apply(pd.to_numeric, errors='coerce')\n",
    ")\n",
    "\n",
    "# 코스피와 코스닥 지수의 일별 수익률 계산\n",
    "market_returns = kospi_kosdaq_indices.mean(axis=1).pct_change().dropna()\n",
    "\n",
    "# 시장 수익률 데이터 기간 확인\n",
    "print(f\"시장 수익률 데이터 기간: {market_returns.index.min()} ~ {market_returns.index.max()}\")\n",
    "\n",
    "# 3. 베타 계산 함수 정의 및 계산\n",
    "def calculate_beta(stock_returns, market_returns, window=365):\n",
    "    # 결측치 제거\n",
    "    combined = pd.concat([stock_returns, market_returns], axis=1).dropna()\n",
    "    if len(combined) < 30:\n",
    "        return np.nan\n",
    "    else:\n",
    "        stock_ret = combined.iloc[:, 0]\n",
    "        market_ret = combined.iloc[:, 1]\n",
    "        cov = stock_ret.cov(market_ret)\n",
    "        var = market_ret.var()\n",
    "        beta = cov / var if var != 0 else np.nan\n",
    "        return beta\n",
    "\n",
    "# 베타 값을 저장할 데이터프레임 생성\n",
    "beta_df = pd.DataFrame(index=dates, columns=symbols)\n",
    "\n",
    "for date in tqdm(dates, desc='베타 계산 중'):\n",
    "    for symbol in symbols:\n",
    "        # 해당 종목의 일별 수익률 시리즈\n",
    "        stock_returns = daily_returns_dict[symbol]\n",
    "        # 해당 날짜까지의 데이터 사용\n",
    "        stock_returns = stock_returns[stock_returns.index <= date]\n",
    "        market_returns_up_to_date = market_returns[market_returns.index <= date]\n",
    "        # 최근 window 기간의 데이터 추출\n",
    "        stock_returns = stock_returns.iloc[-365:]\n",
    "        market_returns_up_to_date = market_returns_up_to_date.iloc[-365:]\n",
    "        # 베타 계산\n",
    "        beta = calculate_beta(stock_returns, market_returns_up_to_date)\n",
    "        beta_df.at[date, symbol] = beta\n",
    "\n",
    "# 베타의 역수를 팩터 값으로 사용\n",
    "inv_beta_df = (1 / beta_df.astype(float)).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "inv_beta_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, monthly_merged_df.columns.get_level_values('Symbol Name')[monthly_merged_df.columns.get_level_values('Symbol') == symbol][0], 'Inverse Beta', 'Inverse Beta') for symbol in inv_beta_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "inv_beta_df.index.name = 'Date'\n",
    "\n",
    "# 팩터 값 저장\n",
    "inv_beta_df.to_csv('factor_betting_against_beta.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(\"'factor_betting_against_beta.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96caf0fc-2d5c-445e-be7d-6d5bee346662",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: factor_high_pe_ratio.csv\n",
      "  Loaded successfully. Shape: (206, 2067)\n",
      "  Max Missing Date: 2008-01-31 00:00:00\n",
      "  Max Missing Count: 1544\n",
      "  Total Columns: 2067\n",
      "  Max Missing Ratio (%): 74.70%\n",
      "Processing file: factor_high_pe_ratio_large_industry.csv\n",
      "  Error processing file factor_high_pe_ratio_large_industry.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_high_pe_ratio_medium_industry.csv\n",
      "  Error processing file factor_high_pe_ratio_medium_industry.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_hml.csv\n",
      "  Error processing file factor_hml.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_momentum.csv\n",
      "  Error processing file factor_momentum.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_retained_earnings.csv\n",
      "  Error processing file factor_retained_earnings.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_betting_against_beta.csv\n",
      "  Loaded successfully. Shape: (426005, 5)\n",
      "  Max Missing Date: 2008-01-31 00:00:00\n",
      "  Max Missing Count: 1\n",
      "  Total Columns: 5\n",
      "  Max Missing Ratio (%): 20.00%\n",
      "\n",
      "===== Missing Data Summary =====\n",
      "                       Factor File Max Missing Date  Max Missing Count  \\\n",
      "0         factor_high_pe_ratio.csv       2008-01-31               1544   \n",
      "1  factor_betting_against_beta.csv       2008-01-31                  1   \n",
      "\n",
      "   Total Columns  Max Missing Ratio (%)  \n",
      "0           2067              74.697629  \n",
      "1              5              20.000000  \n",
      "\n",
      "결측치 분석 결과가 'factor_missing_data_summary.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "#계산한 팩터값에 결측치 확인\n",
    "import pandas as pd\n",
    "\n",
    "# ===== 팩터 값 CSV 확인 및 결측치 분석 =====\n",
    "\n",
    "# 저장된 팩터 값 CSV 파일 목록\n",
    "factor_files = [\n",
    "    'factor_high_pe_ratio.csv',\n",
    "    'factor_high_pe_ratio_large_industry.csv',\n",
    "    'factor_high_pe_ratio_medium_industry.csv',\n",
    "    'factor_hml.csv',\n",
    "    'factor_momentum.csv',\n",
    "    'factor_retained_earnings.csv',\n",
    "    'factor_betting_against_beta.csv'\n",
    "]\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "missing_data_summary = []\n",
    "\n",
    "for file in factor_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    try:\n",
    "        # CSV 파일 로드\n",
    "        factor_df = pd.read_csv(file, \n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "        )\n",
    "\n",
    "        # 멀티인덱스 설정\n",
    "        factor_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "        factor_df.index.name = 'Date'\n",
    "        \n",
    "        print(f\"  Loaded successfully. Shape: {factor_df.shape}\")\n",
    "        \n",
    "        # 2008년 이후 데이터만 필터링\n",
    "        factor_df = factor_df.loc[factor_df.index >= '2008-01-01']\n",
    "        \n",
    "        # 결측치 분석\n",
    "        missing_summary = factor_df.isna().sum(axis=1)  # 각 날짜별 결측치 수\n",
    "        total_columns = factor_df.shape[1]  # 전체 컬럼 수\n",
    "        \n",
    "        # 가장 결측치가 많은 날짜와 해당 날짜의 결측치 비율\n",
    "        max_missing_date = missing_summary.idxmax()\n",
    "        max_missing_count = missing_summary.max()\n",
    "        max_missing_ratio = (max_missing_count / total_columns) * 100  # 결측치 비율\n",
    "        \n",
    "        # 결측치 요약 추가\n",
    "        missing_data_summary.append({\n",
    "            'Factor File': file,\n",
    "            'Max Missing Date': max_missing_date,\n",
    "            'Max Missing Count': max_missing_count,\n",
    "            'Total Columns': total_columns,\n",
    "            'Max Missing Ratio (%)': max_missing_ratio\n",
    "        })\n",
    "        \n",
    "        print(f\"  Max Missing Date: {max_missing_date}\")\n",
    "        print(f\"  Max Missing Count: {max_missing_count}\")\n",
    "        print(f\"  Total Columns: {total_columns}\")\n",
    "        print(f\"  Max Missing Ratio (%): {max_missing_ratio:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing file {file}: {e}\")\n",
    "\n",
    "# 결측치 분석 결과 DataFrame 생성\n",
    "missing_summary_df = pd.DataFrame(missing_data_summary)\n",
    "\n",
    "# 결측치 분석 결과 출력\n",
    "print(\"\\n===== Missing Data Summary =====\")\n",
    "print(missing_summary_df)\n",
    "\n",
    "# 결측치 분석 결과 저장\n",
    "missing_summary_df.to_csv('factor_missing_data_summary.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n결측치 분석 결과가 'factor_missing_data_summary.csv' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea0115-500f-4531-8c1c-bca6231d31c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 백테스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1c477390-2308-4cae-b45a-ac661a5f9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(factor_csv, merged_df, rebalancing_period=1, long_only=True, threshold=0.2, cutoff=0.0, reversal=False, weighting_method='equal', start_date='2008-10-31'):\n",
    "    \"\"\"\n",
    "    백테스팅 함수를 구현합니다.\n",
    "\n",
    "    Parameters:\n",
    "    - factor_csv (str): 팩터값 CSV 파일의 경로\n",
    "    - merged_df (pd.DataFrame): 수익률 데이터가 포함된 데이터프레임\n",
    "    - rebalancing_period (int): 리밸런싱 주기 (1, 3, 6, 12 중 하나)\n",
    "    - long_only (bool): 롱 온리 전략 여부\n",
    "    - threshold (float): 포지션을 취할 상위/하위 퍼센트 (0 < threshold <= 1)\n",
    "    - cutoff (float): 포지션을 취할 시작 퍼센트 (0 <= cutoff < threshold)\n",
    "    - reversal (bool): 전략을 반대로 적용할지 여부\n",
    "    - weighting_method (str): 'equal' 또는 'value' 중 하나로, 동일가중 또는 가치가중을 결정\n",
    "    - start_date (str): 백테스트 시작 날짜 (예: '2008-10-31')\n",
    "\n",
    "    Returns:\n",
    "    - results_df (pd.DataFrame): 월별 포트폴리오 변동과 포지션을 포함한 데이터프레임\n",
    "    \"\"\"\n",
    "    # 팩터 데이터 불러오기\n",
    "    factor_df = pd.read_csv(factor_csv, index_col=0, header=[0, 1, 2, 3], parse_dates=True)\n",
    "    factor_df.index.name = 'Date'\n",
    "    factor_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "\n",
    "    # 팩터 데이터에서 'item'과 'item Name' 레벨을 제거하여 심볼과 종목명만 남김\n",
    "    factor_df.columns = factor_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "    # 팩터 데이터 날짜 필터링 (백테스트 시작일 이후 데이터만 사용)\n",
    "    factor_df = factor_df[factor_df.index >= start_date]\n",
    "\n",
    "    # 수익률 데이터 추출 ('1개월 수익률(계산)')\n",
    "    returns_mask = merged_df.columns.get_level_values('item Name') == '1개월 수익률(계산)'\n",
    "    returns_df = merged_df.loc[:, returns_mask]\n",
    "    returns_df.columns = returns_df.columns.droplevel(['item', 'item Name'])\n",
    "    returns_df.columns.names = ['Symbol', 'Symbol Name']\n",
    "\n",
    "    # 수익률 데이터 날짜 필터링 (백테스트 시작일 이후 데이터만 사용)\n",
    "    returns_df = returns_df[returns_df.index >= start_date]\n",
    "\n",
    "    # 월말 기준으로 데이터 리샘플링\n",
    "    factor_df = factor_df.resample('M').last()\n",
    "    returns_df = returns_df.resample('M').last()\n",
    "\n",
    "    # 팩터 데이터와 수익률 데이터의 공통 심볼(Symbol)만 사용\n",
    "    common_symbols = factor_df.columns.intersection(returns_df.columns)\n",
    "    factor_df = factor_df[common_symbols]\n",
    "    returns_df = returns_df[common_symbols]\n",
    "\n",
    "    # 팩터 데이터와 수익률 데이터를 날짜와 심볼 기준으로 정렬\n",
    "    factor_df = factor_df.sort_index().sort_index(axis=1)\n",
    "    returns_df = returns_df.sort_index().sort_index(axis=1)\n",
    "\n",
    "    # 리밸런싱 날짜 설정\n",
    "    rebalancing_dates = factor_df.index[::rebalancing_period]\n",
    "\n",
    "    # 포트폴리오 초기화\n",
    "    portfolio = pd.DataFrame(index=returns_df.index, columns=['Portfolio Value', 'Monthly Return', 'Transaction Cost'])\n",
    "    portfolio['Portfolio Value'] = 1.0  # 초기 투자금 1로 설정\n",
    "    portfolio['Transaction Cost'] = 0.0  # 초기 거래 비용 0으로 설정\n",
    "\n",
    "    # 각 날짜의 포지션을 저장할 딕셔너리\n",
    "    positions = {}\n",
    "\n",
    "    # 거래 비용 비율 설정 (0.1%)\n",
    "    transaction_cost_rate = 0.001\n",
    "\n",
    "    # 백테스트 진행\n",
    "    for i, date in enumerate(returns_df.index):\n",
    "        # 이전 날짜 설정\n",
    "        if i > 0:\n",
    "            prev_date = returns_df.index[i - 1]\n",
    "        else:\n",
    "            prev_date = None\n",
    "\n",
    "        # 리밸런싱 시점인지 확인\n",
    "        if date in rebalancing_dates:\n",
    "            # 리밸런싱 시점에서는 새로운 포지션을 설정\n",
    "            factor = factor_df.loc[date].dropna()\n",
    "\n",
    "            # 종목 수 계산\n",
    "            num_assets = len(factor)\n",
    "            num_selected = int(num_assets * threshold)\n",
    "            num_cutoff = int(num_assets * cutoff)\n",
    "\n",
    "            if long_only:\n",
    "                # 롱 온리 전략\n",
    "                if reversal:\n",
    "                    # 하위 cutoff% ~ threshold% 종목을 선택\n",
    "                    selected_symbols = factor.nsmallest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                else:\n",
    "                    # 상위 cutoff% ~ threshold% 종목을 선택\n",
    "                    selected_symbols = factor.nlargest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "\n",
    "                # 가중치 계산\n",
    "                if weighting_method == 'equal':\n",
    "                    weights = pd.Series(1.0 / len(selected_symbols), index=selected_symbols)\n",
    "                elif weighting_method == 'value':\n",
    "                    weights = factor[selected_symbols] / factor[selected_symbols].abs().sum()\n",
    "                else:\n",
    "                    raise ValueError(\"weighting_method must be 'equal' or 'value'\")\n",
    "            else:\n",
    "                # 롱숏 전략\n",
    "                if reversal:\n",
    "                    # 하위 cutoff% ~ threshold% 종목을 롱, 상위 cutoff% ~ threshold% 종목을 숏\n",
    "                    long_symbols = factor.nsmallest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                    short_symbols = factor.nlargest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                else:\n",
    "                    # 상위 cutoff% ~ threshold% 종목을 롱, 하위 cutoff% ~ threshold% 종목을 숏\n",
    "                    long_symbols = factor.nlargest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                    short_symbols = factor.nsmallest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "\n",
    "                # 가중치 계산\n",
    "                if weighting_method == 'equal':\n",
    "                    long_weights = pd.Series(1.0 / len(long_symbols), index=long_symbols)\n",
    "                    short_weights = pd.Series(-1.0 / len(short_symbols), index=short_symbols)\n",
    "                elif weighting_method == 'value':\n",
    "                    long_weights = factor[long_symbols] / factor[long_symbols].abs().sum()\n",
    "                    short_weights = -factor[short_symbols] / factor[short_symbols].abs().sum()\n",
    "                else:\n",
    "                    raise ValueError(\"weighting_method must be 'equal' or 'value'\")\n",
    "\n",
    "                # 롱과 숏 포지션 합치기\n",
    "                weights = pd.concat([long_weights, short_weights])\n",
    "\n",
    "            # 거래 비용 계산 (포지션 변경에 따른)\n",
    "            if prev_date is not None and prev_date in positions:\n",
    "                prev_weights = positions[prev_date]\n",
    "                # 포지션 변경량 계산\n",
    "                weight_diff = weights.reindex(prev_weights.index).fillna(0) - prev_weights.reindex(weights.index).fillna(0)\n",
    "            else:\n",
    "                # 처음 포지션을 잡을 때는 전체 포지션이 신규 진입\n",
    "                weight_diff = weights\n",
    "\n",
    "            # 거래 비용 계산\n",
    "            transaction_cost = transaction_cost_rate * weight_diff.abs().sum()\n",
    "\n",
    "            # 현재 포지션 저장\n",
    "            positions[date] = weights\n",
    "\n",
    "        else:\n",
    "            # 리밸런싱 시점이 아니면 이전 포지션을 그대로 유지\n",
    "            if prev_date in positions:\n",
    "                positions[date] = positions[prev_date]\n",
    "                transaction_cost = 0.0  # 거래 비용 없음\n",
    "            else:\n",
    "                # 이전 포지션이 없으면 포지션 없음\n",
    "                positions[date] = pd.Series()\n",
    "                transaction_cost = 0.0  # 거래 비용 없음\n",
    "\n",
    "        # 수익률 계산 (선행 편향 방지를 위해 이전 포지션 사용)\n",
    "        if prev_date in positions and not positions[prev_date].empty:\n",
    "            weights = positions[prev_date]\n",
    "\n",
    "            # 해당 월의 수익률 계산\n",
    "            returns = returns_df.loc[date]\n",
    "            # 포지션에 해당하는 종목의 수익률만 선택\n",
    "            aligned_returns = returns.reindex(weights.index).fillna(0)\n",
    "            # 포트폴리오 수익률 계산 (벡터화 연산)\n",
    "            portfolio_return = (weights * aligned_returns).sum()\n",
    "        else:\n",
    "            # 포지션이 없으면 수익률 0\n",
    "            portfolio_return = 0.0\n",
    "\n",
    "        # 거래 비용을 수익률에 반영\n",
    "        net_return = portfolio_return - transaction_cost\n",
    "\n",
    "        # 포트폴리오 가치 업데이트\n",
    "        if i > 0:\n",
    "            portfolio.loc[date, 'Monthly Return'] = net_return\n",
    "            portfolio.loc[date, 'Transaction Cost'] = transaction_cost\n",
    "            portfolio.loc[date, 'Portfolio Value'] = portfolio.iloc[i - 1]['Portfolio Value'] * (1 + net_return)\n",
    "        else:\n",
    "            # 첫 번째 기간은 수익률 계산하지 않음\n",
    "            portfolio.loc[date, 'Monthly Return'] = 0.0\n",
    "            portfolio.loc[date, 'Transaction Cost'] = 0.0\n",
    "\n",
    "    # 포지션 정보를 데이터프레임으로 변환\n",
    "    positions_df = pd.DataFrame.from_dict(positions, orient='index')\n",
    "    positions_df.index.name = 'Date'\n",
    "\n",
    "    # 결과 합치기\n",
    "    results_df = portfolio.join(positions_df, how='left')\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9279f865-95d8-43a9-a8da-d6e60a76eb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [17:17<00:00, 103.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# 'factor'라는 글자가 포함된 모든 CSV 파일 목록을 가져옵니다.\n",
    "factor_files = glob.glob('*factor*.csv')\n",
    "\n",
    "# 백테스팅에 사용할 파라미터 그리드 설정\n",
    "rebalancing_periods = [1, 3, 6]        # 리밸런싱 주기\n",
    "thresholds = [0.1, 0.2, 0.3]           # 상위/하위 퍼센트\n",
    "cutoffs = [0, 0.05, 0.1]               # 시작 퍼센트\n",
    "weighting_methods = ['equal', 'value'] # 가중치 방법\n",
    "start_date = '2008-10-31'              # 백테스트 시작일\n",
    "\n",
    "# 모든 팩터 파일에 대해 백테스팅 수행\n",
    "for factor_csv in tqdm(factor_files):\n",
    "    # print(f\"백테스팅 시작: {factor_csv}\")\n",
    "    \n",
    "    # 팩터 파일명에서 확장자를 제거하여 폴더명을 생성합니다.\n",
    "    factor_name = os.path.splitext(factor_csv)[0]\n",
    "    \n",
    "    # 팩터별 폴더 생성 (이미 존재하면 생략)\n",
    "    if not os.path.exists(factor_name):\n",
    "        os.makedirs(factor_name)\n",
    "    \n",
    "    # 모든 파라미터 조합에 대해 백테스팅 수행\n",
    "    for rebalancing_period, threshold, cutoff, weighting_method in itertools.product(\n",
    "        rebalancing_periods, thresholds, cutoffs, weighting_methods):\n",
    "        \n",
    "        # cutoff는 threshold보다 작아야 합니다.\n",
    "        if cutoff >= threshold:\n",
    "            continue\n",
    "        \n",
    "        # 백테스팅 함수 호출\n",
    "        try:\n",
    "            results_df = backtest_strategy(\n",
    "                factor_csv=factor_csv,\n",
    "                merged_df=monthly_merged_df,  # 수익률 데이터가 포함된 데이터프레임 (사전에 정의되어 있어야 합니다)\n",
    "                rebalancing_period=rebalancing_period,\n",
    "                long_only=True,  # Long-only 전략\n",
    "                threshold=threshold,\n",
    "                cutoff=cutoff,\n",
    "                reversal=False,  # 기본값\n",
    "                weighting_method=weighting_method,\n",
    "                start_date=start_date\n",
    "            )\n",
    "            \n",
    "            # 파일명 생성 (스네이크 케이스로 파라미터 명명)\n",
    "            file_name = f\"rebalancing_{rebalancing_period}_threshold_{threshold}_cutoff_{cutoff}_weighting_{weighting_method}\"\n",
    "            file_name = file_name.replace('.', '_')  # 파일명에 있는 점을 언더스코어로 변경\n",
    "            \n",
    "            # 결과 저장 경로 생성\n",
    "            save_path = os.path.join(factor_name, file_name)\n",
    "            \n",
    "            # 백테스팅 결과를 CSV 파일로 저장\n",
    "            results_df.to_csv(save_path+'.csv', encoding='utf-8-sig')\n",
    "            \n",
    "            # print(f\"완료: {factor_csv}, 리밸런싱 주기: {rebalancing_period}, threshold: {threshold}, cutoff: {cutoff}, 가중치 방법: {weighting_method}\")\n",
    "            # print(f\"저장 위치: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"에러 발생: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "99a04c59-303c-4701-80b2-8ada777d821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "각 팩터별로 Sharpe Ratio가 가장 높은 파일 목록:\n",
      "factor_betting_against_beta\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
      "factor_high_pe_ratio\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
      "factor_high_pe_ratio_large_industry\\rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_high_pe_ratio_medium_industry\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_value.csv\n",
      "factor_hml\\rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum_large_industry\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum_medium_industry\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
      "factor_momentum_zscore\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_retained_earnings\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 시장 수익률 계산 (종가지수(포인트) 기반)\n",
    "def get_risk_free_rate():\n",
    "    \"\"\"\n",
    "    위험 무시 수익률(rf)을 계산하는 함수입니다.\n",
    "    코스피와 코스닥 지수의 일별 수익률을 평균하여 사용합니다.\n",
    "    월별 수익률로 변환하여 반환합니다.\n",
    "    \n",
    "    Returns:\n",
    "    - rf_monthly_returns (pd.Series): 월별 위험 무시 수익률 시리즈\n",
    "    \"\"\"\n",
    "    # 시장 데이터 로드\n",
    "    try:\n",
    "        market_df = pd.read_csv(\n",
    "            'data/rf.csv',\n",
    "            skiprows=8,\n",
    "            header=[0, 1, 2, 3, 4, 5],\n",
    "            index_col=0,\n",
    "            encoding='cp949',\n",
    "            parse_dates=True\n",
    "        )\n",
    "    except UnicodeDecodeError:\n",
    "        market_df = pd.read_csv(\n",
    "            'data/rf.csv',\n",
    "            skiprows=8,\n",
    "            header=[0, 1, 2, 3, 4, 5],\n",
    "            index_col=0,\n",
    "            encoding='euc-kr',\n",
    "            parse_dates=True\n",
    "        )\n",
    "\n",
    "    # 멀티인덱스 컬럼 이름 지정\n",
    "    market_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "    market_df.index.name = 'Date'\n",
    "\n",
    "    # 'Kind', 'Frequency' 레벨 제거\n",
    "    market_df.columns = market_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "    # '종가지수(포인트)' 데이터 추출\n",
    "    # index_mask = market_df.columns.get_level_values('item Name') == '종가지수(포인트)'\n",
    "    index_mask = market_df.columns.get_level_values('item Name') == '시장금리:국고1년(%)'\n",
    "    index_df = market_df.loc[:, index_mask]\n",
    "\n",
    "    # '코스피'와 '코스닥' 지수만 선택\n",
    "    symbol_names = index_df.columns.get_level_values('Symbol Name')\n",
    "    # kospi_kosdaq_mask = (symbol_names == '코스피') | (symbol_names == '코스닥')\n",
    "    kospi_kosdaq_mask = (symbol_names == 'ECO')\n",
    "    kospi_kosdaq_indices = index_df.loc[:, kospi_kosdaq_mask]\n",
    "    kospi_kosdaq_indices.columns = kospi_kosdaq_indices.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "    # 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "    kospi_kosdaq_indices = (\n",
    "        kospi_kosdaq_indices\n",
    "        .astype(str)\n",
    "        .replace(',', '', regex=True)\n",
    "        .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)\n",
    "        .apply(pd.to_numeric, errors='coerce')\n",
    "    )\n",
    "\n",
    "    # 코스피와 코스닥 지수의 일별 수익률 계산\n",
    "    market_returns = kospi_kosdaq_indices.mean(axis=1).pct_change().dropna()\n",
    "\n",
    "    # 월별 수익률로 변환\n",
    "    rf_monthly_returns = market_returns.resample('M').apply(lambda x: (1 + x).prod() - 1)\n",
    "    rf_monthly_returns.name = 'Risk-Free Rate'\n",
    "\n",
    "    return rf_monthly_returns\n",
    "\n",
    "# 위험 무시 수익률(rf) 시리즈 가져오기\n",
    "rf_returns = get_risk_free_rate()\n",
    "\n",
    "# Sharpe Ratio를 계산하는 함수 정의\n",
    "def calculate_sharpe_ratio(returns_series, rf_series, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Sharpe Ratio를 계산하는 함수입니다.\n",
    "    \n",
    "    Parameters:\n",
    "    - returns_series (pd.Series): 월별 수익률 시리즈\n",
    "    - rf_series (pd.Series): 월별 위험 무시 수익률 시리즈\n",
    "    - start_date (str): Sharpe Ratio 계산에 사용할 시작 날짜 (예: '2008-10-31')\n",
    "    - end_date (str): Sharpe Ratio 계산에 사용할 종료 날짜 (예: '2018-09-30')\n",
    "    \n",
    "    Returns:\n",
    "    - sharpe_ratio (float): Sharpe Ratio 값\n",
    "    \"\"\"\n",
    "    # 지정된 기간으로 데이터 필터링\n",
    "    returns_series = returns_series.loc[start_date:end_date]\n",
    "    rf_series = rf_series.loc[start_date:end_date]\n",
    "\n",
    "    # 수익률과 위험 무시 수익률의 교집합 날짜 선택\n",
    "    common_index = returns_series.index.intersection(rf_series.index)\n",
    "    returns = returns_series.loc[common_index].dropna()\n",
    "    rf = rf_series.loc[common_index].dropna()\n",
    "\n",
    "    # 위험 프리미엄 계산 (초과 수익률)\n",
    "    excess_returns = returns - rf\n",
    "\n",
    "    # 결측치 제거\n",
    "    excess_returns = excess_returns.dropna()\n",
    "\n",
    "    # 월별 초과 수익률의 평균과 표준편차 계산\n",
    "    mean_excess_return = excess_returns.mean()\n",
    "    std_excess_return = excess_returns.std()\n",
    "\n",
    "    # Sharpe Ratio 계산 (연율화)\n",
    "    if std_excess_return != 0:\n",
    "        sharpe_ratio = (mean_excess_return / std_excess_return) * np.sqrt(12)\n",
    "    else:\n",
    "        sharpe_ratio = np.nan\n",
    "    return sharpe_ratio\n",
    "\n",
    "# 'factor'로 시작하는 모든 폴더 목록을 가져옵니다.\n",
    "factor_folders = [folder for folder in glob.glob('factor*') if os.path.isdir(folder)]\n",
    "\n",
    "# 각 팩터별로 Sharpe Ratio가 가장 높은 파일명을 저장할 리스트 초기화\n",
    "best_results = []\n",
    "\n",
    "# Training 데이터 기간 설정\n",
    "training_start_date = '2008-10-31'\n",
    "training_end_date = '2018-09-30'\n",
    "\n",
    "# 각 팩터 폴더에 대해 반복\n",
    "for folder in tqdm(factor_folders):\n",
    "    # print(f\"폴더 처리 중: {folder}\")\n",
    "    # 폴더 내의 모든 CSV 파일 목록 가져오기\n",
    "    csv_files = glob.glob(os.path.join(folder, '*.csv'))\n",
    "    \n",
    "    # Sharpe Ratio를 저장할 딕셔너리 초기화\n",
    "    sharpe_ratios = {}\n",
    "    \n",
    "    # 각 CSV 파일에 대해 반복\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            # CSV 파일 읽기\n",
    "            df = pd.read_csv(csv_file, index_col=0, parse_dates=True)\n",
    "            # 'Monthly Return' 컬럼이 존재하는지 확인\n",
    "            if 'Monthly Return' in df.columns:\n",
    "                # Sharpe Ratio 계산\n",
    "                sharpe_ratio = calculate_sharpe_ratio(df['Monthly Return'], rf_returns, training_start_date, training_end_date)\n",
    "                # Sharpe Ratio 저장\n",
    "                sharpe_ratios[csv_file] = sharpe_ratio\n",
    "            else:\n",
    "                print(f\"'Monthly Return' 컬럼이 없습니다: {csv_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"에러 발생: {csv_file}, 에러 내용: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 해당 팩터 폴더에서 Sharpe Ratio가 가장 높은 파일 찾기\n",
    "    if sharpe_ratios:\n",
    "        # 최대 Sharpe Ratio를 가진 파일 찾기\n",
    "        best_file = max(sharpe_ratios, key=sharpe_ratios.get)\n",
    "        best_sharpe = sharpe_ratios[best_file]\n",
    "        # print(f\"최고 Sharpe Ratio: {best_sharpe:.4f}, 파일명: {best_file}\")\n",
    "        # 파일명을 리스트에 추가\n",
    "        best_results.append(best_file)\n",
    "    else:\n",
    "        print(f\"Sharpe Ratio를 계산할 수 있는 파일이 없습니다: {folder}\")\n",
    "\n",
    "# best_results 리스트를 'best_results.txt' 파일에 저장\n",
    "with open('best_results.txt', 'w', encoding='utf-8') as f:\n",
    "    for file_path in best_results:\n",
    "        f.write(file_path + '\\n')\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n각 팩터별로 Sharpe Ratio가 가장 높은 파일 목록:\")\n",
    "for best_file in best_results:\n",
    "    print(best_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5744af42-dcbb-4471-aff2-fb1ca63a67d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 최종 선택된 경주마 발표(시각화)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776e0c99-cbaa-46da-a3a7-61832b68fc8a",
   "metadata": {},
   "source": [
    "factor_betting_against_beta\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
    "factor_high_pe_ratio\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
    "factor_high_pe_ratio_large_industry\\rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_high_pe_ratio_medium_industry\\rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal.csv\n",
    "factor_hml\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
    "factor_momentum\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_momentum_large_industry\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_momentum_medium_industry\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
    "factor_momentum_zscore\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_retained_earnings\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2402dd4c-2f82-409b-9469-3338925232bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import os\n",
    "\n",
    "# Plotly 렌더러 설정: 브라우저에서 그래프를 표시하도록 설정\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "# Training 데이터 기간 설정\n",
    "training_start_date = '2008-10-31'\n",
    "training_end_date = '2018-09-30'\n",
    "\n",
    "# 그래프의 트레이스를 저장할 리스트 초기화\n",
    "traces = []\n",
    "\n",
    "# Sharpe Ratio를 저장할 리스트 초기화\n",
    "sharpe_ratio_list = []\n",
    "\n",
    "# Sharpe Ratio 계산 함수 (이미 정의되어 있다고 가정)\n",
    "def calculate_sharpe_ratio(returns_series, rf_series, start_date, end_date):\n",
    "    # 지정된 기간으로 데이터 필터링\n",
    "    returns_series = returns_series.loc[start_date:end_date]\n",
    "    rf_series = rf_series.loc[start_date:end_date]\n",
    "\n",
    "    # 수익률과 위험 무시 수익률의 교집합 날짜 선택\n",
    "    common_index = returns_series.index.intersection(rf_series.index)\n",
    "    returns = returns_series.loc[common_index].dropna()\n",
    "    rf = rf_series.loc[common_index].dropna()\n",
    "\n",
    "    # 위험 프리미엄 계산 (초과 수익률)\n",
    "    excess_returns = returns - rf\n",
    "\n",
    "    # 결측치 제거\n",
    "    excess_returns = excess_returns.dropna()\n",
    "\n",
    "    # 월별 초과 수익률의 평균과 표준편차 계산\n",
    "    mean_excess_return = excess_returns.mean()\n",
    "    std_excess_return = excess_returns.std()\n",
    "\n",
    "    # Sharpe Ratio 계산 (연율화)\n",
    "    if std_excess_return != 0:\n",
    "        sharpe_ratio = (mean_excess_return / std_excess_return) * np.sqrt(12)\n",
    "    else:\n",
    "        sharpe_ratio = np.nan\n",
    "    return sharpe_ratio\n",
    "\n",
    "# 위험 무시 수익률(rf) 시리즈 가져오기 (이미 정의되어 있다고 가정)\n",
    "# rf_returns = get_risk_free_rate()\n",
    "\n",
    "# best_results 리스트에 담긴 CSV 파일들을 순회하면서 차트 생성 및 Sharpe Ratio 계산\n",
    "for csv_file in best_results:\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(csv_file, index_col=0, parse_dates=True)\n",
    "\n",
    "    # 기간 필터링 (Sharpe Ratio 계산 기간과 동일)\n",
    "    df_period = df.loc[training_start_date:training_end_date]\n",
    "\n",
    "    # 포트폴리오 가치와 월별 수익률이 존재하는지 확인\n",
    "    if 'Portfolio Value' in df_period.columns and 'Monthly Return' in df_period.columns:\n",
    "        # 포트폴리오 가치 시계열 데이터 준비\n",
    "        portfolio_values = df_period['Portfolio Value']\n",
    "\n",
    "        # 전략 이름 생성 (팩터 이름과 전략 정보 결합)\n",
    "        folder_name, file_name = os.path.split(csv_file)\n",
    "        factor_name = folder_name\n",
    "        strategy_info = file_name.replace('.csv', '')\n",
    "        strategy_name = f\"{factor_name} - {strategy_info}\"\n",
    "\n",
    "        # 그래프의 트레이스 생성 및 추가\n",
    "        trace = go.Scatter(\n",
    "            x=portfolio_values.index,\n",
    "            y=portfolio_values.values,\n",
    "            mode='lines',\n",
    "            name=strategy_name\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "        # Sharpe Ratio 계산\n",
    "        sharpe_ratio = calculate_sharpe_ratio(df_period['Monthly Return'], rf_returns, training_start_date, training_end_date)\n",
    "\n",
    "        # Sharpe Ratio를 리스트에 저장\n",
    "        sharpe_ratio_list.append({\n",
    "            'Strategy': strategy_name,\n",
    "            'Sharpe Ratio': sharpe_ratio\n",
    "        })\n",
    "    else:\n",
    "        print(f\"'Portfolio Value' 또는 'Monthly Return' 컬럼이 없습니다: {csv_file}\")\n",
    "\n",
    "# 그래프 레이아웃 설정\n",
    "layout = go.Layout(\n",
    "    title='최적의 전략별 포트폴리오 가치 비교 (2008-10-31 ~ 2018-09-30)',\n",
    "    xaxis=dict(title='날짜'),\n",
    "    yaxis=dict(title='포트폴리오 가치'),\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "# 그래프 생성 및 출력\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()\n",
    "\n",
    "# Sharpe Ratio를 데이터프레임으로 생성 및 출력\n",
    "sharpe_ratio_df = pd.DataFrame(sharpe_ratio_list)\n",
    "# print(\"\\n각 전략의 연율화 Sharpe Ratio:\")\n",
    "# print(sharpe_ratio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e2649d5-c7ac-4a14-811b-37cbbbdcbdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factor_betting_against_beta - rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.654546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>factor_high_pe_ratio - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal</td>\n",
       "      <td>1.190827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>factor_high_pe_ratio_large_industry - rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>1.134090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>factor_high_pe_ratio_medium_industry - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_value</td>\n",
       "      <td>1.103080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factor_hml - rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>1.007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>factor_momentum - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.951752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>factor_momentum_large_industry - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.923269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>factor_momentum_medium_industry - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal</td>\n",
       "      <td>0.913603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>factor_momentum_zscore - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.951752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>factor_retained_earnings - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal</td>\n",
       "      <td>1.122443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Strategy  \\\n",
       "0           factor_betting_against_beta - rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal   \n",
       "1                 factor_high_pe_ratio - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal   \n",
       "2   factor_high_pe_ratio_large_industry - rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "3  factor_high_pe_ratio_medium_industry - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_value   \n",
       "4                            factor_hml - rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "5                       factor_momentum - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "6        factor_momentum_large_industry - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "7      factor_momentum_medium_industry - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal   \n",
       "8                factor_momentum_zscore - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "9             factor_retained_earnings - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal   \n",
       "\n",
       "   Sharpe Ratio  \n",
       "0      0.654546  \n",
       "1      1.190827  \n",
       "2      1.134090  \n",
       "3      1.103080  \n",
       "4      1.007334  \n",
       "5      0.951752  \n",
       "6      0.923269  \n",
       "7      0.913603  \n",
       "8      0.951752  \n",
       "9      1.122443  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한 열에 표시되는 최대 문자 수 늘리기 (긴 문자열 표시)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "sharpe_ratio_df.to_csv('picked_strategy.csv', encoding='utf-8-sig')\n",
    "sharpe_ratio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "090e226c-2c8d-43e6-8598-4b1443d6244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c3802-5e5c-4264-aa1c-9e2aa89b81ee",
   "metadata": {},
   "source": [
    "# CausalAI(였지만 지금은 그냥 선작업)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "529cc767-cfae-45f1-bf4a-2f102c621703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 백테스팅 CSV 파일 목록:\n",
      "factor_betting_against_beta\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
      "factor_high_pe_ratio\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
      "factor_high_pe_ratio_large_industry\\rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_high_pe_ratio_medium_industry\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_value.csv\n",
      "factor_hml\\rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum_large_industry\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum_medium_industry\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
      "factor_momentum_zscore\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_retained_earnings\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2. 데이터 로드 및 전처리\n",
    "2.1 선택된 백테스팅 CSV 파일 로드\n",
    "'''\n",
    "# 'best_results.txt' 파일을 읽어서 best_results 리스트를 생성\n",
    "with open('best_results.txt', 'r', encoding='utf-8') as f:\n",
    "    best_results = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"선택된 백테스팅 CSV 파일 목록:\")\n",
    "for file_path in best_results:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "74d055bd-18d3-4717-9215-498c88d075a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. 데이터 로드 및 전처리\n",
    "2.2 그 외 데이터 로드\n",
    "'''\n",
    "# periods = [1,3,6,11]\n",
    "periods = [12]\n",
    "\n",
    "# 코스피/코스닥 지수 데이터 로드\n",
    "market_indices = hs.load_market_indices()\n",
    "market_indices.columns = market_indices.columns.droplevel('Symbol')\n",
    "\n",
    "# 위험 무시 수익률 데이터 로드\n",
    "rf_monthly = hs.load_risk_free_rate()\n",
    "\n",
    "# 환율 데이터 로드\n",
    "exchange_rate = hs.load_exchange_rate()\n",
    "\n",
    "# 함수로 처리: 변화율 컬럼 추가\n",
    "def add_pct_change(df, periods):\n",
    "    \"\"\"독립적으로 pct_change 값을 계산하고 데이터프레임에 추가\"\"\"\n",
    "    new_df = df.copy()  # 원본 데이터를 변경하지 않기 위해 복사\n",
    "    for period in periods:\n",
    "        pct_change_data = df.pct_change(periods=period).shift(1)\n",
    "        pct_change_data = pct_change_data.add_suffix(f'_pct_change_{period}m')\n",
    "        new_df = new_df.join(pct_change_data, how='left')\n",
    "    return new_df\n",
    "\n",
    "# 변화율 계산 및 추가 (1개월, 3개월, 6개월, 12개월)\n",
    "market_indices = add_pct_change(market_indices, periods)\n",
    "rf_monthly = add_pct_change(rf_monthly, periods)\n",
    "exchange_rate = add_pct_change(exchange_rate, periods)\n",
    "\n",
    "# 날짜 정렬 및 결측치 처리\n",
    "market_indices = market_indices.sort_index().fillna(method='ffill').dropna()\n",
    "rf_monthly = rf_monthly.sort_index().fillna(method='ffill').dropna()\n",
    "exchange_rate = exchange_rate.sort_index().fillna(method='ffill').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9cf1d262-0b84-47e0-99b6-13b1824d8f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "합쳐진 데이터프레임의 일부:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return</th>\n",
       "      <th>factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value</th>\n",
       "      <th>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</th>\n",
       "      <th>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value</th>\n",
       "      <th>factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return_pct_change_12m</th>\n",
       "      <th>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return_pct_change_12m</th>\n",
       "      <th>factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value_zscore_12m</th>\n",
       "      <th>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value_zscore_12m</th>\n",
       "      <th>코스피</th>\n",
       "      <th>코스닥</th>\n",
       "      <th>코스피_pct_change_12m</th>\n",
       "      <th>코스닥_pct_change_12m</th>\n",
       "      <th>Risk_Free_Rate</th>\n",
       "      <th>Risk_Free_Rate_pct_change_12m</th>\n",
       "      <th>Exchange_Rate</th>\n",
       "      <th>Exchange_Rate_pct_change_12m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-10-31</th>\n",
       "      <td>-0.032506</td>\n",
       "      <td>2.492724</td>\n",
       "      <td>-0.032034</td>\n",
       "      <td>1.557801</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-1.380729</td>\n",
       "      <td>-1.640817</td>\n",
       "      <td>1580.69</td>\n",
       "      <td>486.46</td>\n",
       "      <td>0.155436</td>\n",
       "      <td>0.147855</td>\n",
       "      <td>3.510</td>\n",
       "      <td>-0.362162</td>\n",
       "      <td>1162.800049</td>\n",
       "      <td>-0.025813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-30</th>\n",
       "      <td>-0.016969</td>\n",
       "      <td>2.450425</td>\n",
       "      <td>-0.026380</td>\n",
       "      <td>1.516707</td>\n",
       "      <td>-1.897261</td>\n",
       "      <td>3.657964</td>\n",
       "      <td>-1.366047</td>\n",
       "      <td>-1.619876</td>\n",
       "      <td>1555.60</td>\n",
       "      <td>464.32</td>\n",
       "      <td>0.420130</td>\n",
       "      <td>0.579262</td>\n",
       "      <td>3.120</td>\n",
       "      <td>-0.283673</td>\n",
       "      <td>1160.599976</td>\n",
       "      <td>-0.098045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>0.121516</td>\n",
       "      <td>2.748192</td>\n",
       "      <td>0.112818</td>\n",
       "      <td>1.687818</td>\n",
       "      <td>-0.001345</td>\n",
       "      <td>2.706723</td>\n",
       "      <td>-1.351967</td>\n",
       "      <td>-1.600265</td>\n",
       "      <td>1682.77</td>\n",
       "      <td>513.57</td>\n",
       "      <td>0.445631</td>\n",
       "      <td>0.510082</td>\n",
       "      <td>3.480</td>\n",
       "      <td>-0.360656</td>\n",
       "      <td>1151.099976</td>\n",
       "      <td>-0.206373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>-0.025541</td>\n",
       "      <td>2.678001</td>\n",
       "      <td>-0.010893</td>\n",
       "      <td>1.669432</td>\n",
       "      <td>-1.268121</td>\n",
       "      <td>-1.301294</td>\n",
       "      <td>-1.336177</td>\n",
       "      <td>-1.575365</td>\n",
       "      <td>1602.43</td>\n",
       "      <td>496.57</td>\n",
       "      <td>0.496501</td>\n",
       "      <td>0.546665</td>\n",
       "      <td>3.220</td>\n",
       "      <td>0.067485</td>\n",
       "      <td>1147.699951</td>\n",
       "      <td>-0.073338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>0.028257</td>\n",
       "      <td>2.753672</td>\n",
       "      <td>0.049845</td>\n",
       "      <td>1.752645</td>\n",
       "      <td>2.638953</td>\n",
       "      <td>3.372724</td>\n",
       "      <td>-1.322149</td>\n",
       "      <td>-1.552547</td>\n",
       "      <td>1594.58</td>\n",
       "      <td>507.03</td>\n",
       "      <td>0.378897</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>3.070</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1133.599976</td>\n",
       "      <td>-0.154113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-31</th>\n",
       "      <td>-0.015329</td>\n",
       "      <td>30.855714</td>\n",
       "      <td>-0.010910</td>\n",
       "      <td>8.425144</td>\n",
       "      <td>-0.479723</td>\n",
       "      <td>-3.547213</td>\n",
       "      <td>1.863306</td>\n",
       "      <td>1.361817</td>\n",
       "      <td>2770.69</td>\n",
       "      <td>803.15</td>\n",
       "      <td>0.091074</td>\n",
       "      <td>-0.032019</td>\n",
       "      <td>3.152</td>\n",
       "      <td>-0.065956</td>\n",
       "      <td>1383.500000</td>\n",
       "      <td>0.043240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-31</th>\n",
       "      <td>-0.032264</td>\n",
       "      <td>29.860183</td>\n",
       "      <td>-0.024565</td>\n",
       "      <td>8.218183</td>\n",
       "      <td>-3.604592</td>\n",
       "      <td>-7.631673</td>\n",
       "      <td>1.891093</td>\n",
       "      <td>1.382030</td>\n",
       "      <td>2674.31</td>\n",
       "      <td>767.66</td>\n",
       "      <td>0.052462</td>\n",
       "      <td>-0.141906</td>\n",
       "      <td>3.060</td>\n",
       "      <td>-0.105308</td>\n",
       "      <td>1336.569946</td>\n",
       "      <td>0.087324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30</th>\n",
       "      <td>0.004362</td>\n",
       "      <td>29.990448</td>\n",
       "      <td>-0.005768</td>\n",
       "      <td>8.170785</td>\n",
       "      <td>-1.140813</td>\n",
       "      <td>-0.801113</td>\n",
       "      <td>1.905673</td>\n",
       "      <td>1.393377</td>\n",
       "      <td>2593.27</td>\n",
       "      <td>763.88</td>\n",
       "      <td>0.046177</td>\n",
       "      <td>-0.173137</td>\n",
       "      <td>2.826</td>\n",
       "      <td>-0.125714</td>\n",
       "      <td>1309.300049</td>\n",
       "      <td>0.010234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31</th>\n",
       "      <td>-0.027178</td>\n",
       "      <td>29.175358</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>8.189742</td>\n",
       "      <td>-0.192602</td>\n",
       "      <td>-1.027701</td>\n",
       "      <td>1.930182</td>\n",
       "      <td>1.411562</td>\n",
       "      <td>2556.15</td>\n",
       "      <td>743.06</td>\n",
       "      <td>0.052007</td>\n",
       "      <td>-0.091722</td>\n",
       "      <td>2.875</td>\n",
       "      <td>-0.228080</td>\n",
       "      <td>1378.569946</td>\n",
       "      <td>-0.031533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-30</th>\n",
       "      <td>-0.024324</td>\n",
       "      <td>28.465684</td>\n",
       "      <td>-0.063772</td>\n",
       "      <td>7.667464</td>\n",
       "      <td>-1.382970</td>\n",
       "      <td>-1.624310</td>\n",
       "      <td>1.955778</td>\n",
       "      <td>1.454628</td>\n",
       "      <td>2482.29</td>\n",
       "      <td>682.91</td>\n",
       "      <td>0.122108</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>2.886</td>\n",
       "      <td>-0.231283</td>\n",
       "      <td>1393.300049</td>\n",
       "      <td>0.022625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return  \\\n",
       "Date                                                                                              \n",
       "2009-10-31                                                                            -0.032506   \n",
       "2009-11-30                                                                            -0.016969   \n",
       "2009-12-31                                                                             0.121516   \n",
       "2010-01-31                                                                            -0.025541   \n",
       "2010-02-28                                                                             0.028257   \n",
       "...                                                                                         ...   \n",
       "2024-07-31                                                                            -0.015329   \n",
       "2024-08-31                                                                            -0.032264   \n",
       "2024-09-30                                                                             0.004362   \n",
       "2024-10-31                                                                            -0.027178   \n",
       "2024-11-30                                                                            -0.024324   \n",
       "\n",
       "            factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value  \\\n",
       "Date                                                                                             \n",
       "2009-10-31                                                                            2.492724   \n",
       "2009-11-30                                                                            2.450425   \n",
       "2009-12-31                                                                            2.748192   \n",
       "2010-01-31                                                                            2.678001   \n",
       "2010-02-28                                                                            2.753672   \n",
       "...                                                                                        ...   \n",
       "2024-07-31                                                                           30.855714   \n",
       "2024-08-31                                                                           29.860183   \n",
       "2024-09-30                                                                           29.990448   \n",
       "2024-10-31                                                                           29.175358   \n",
       "2024-11-30                                                                           28.465684   \n",
       "\n",
       "            factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return  \\\n",
       "Date                                                                                        \n",
       "2009-10-31                                                                      -0.032034   \n",
       "2009-11-30                                                                      -0.026380   \n",
       "2009-12-31                                                                       0.112818   \n",
       "2010-01-31                                                                      -0.010893   \n",
       "2010-02-28                                                                       0.049845   \n",
       "...                                                                                   ...   \n",
       "2024-07-31                                                                      -0.010910   \n",
       "2024-08-31                                                                      -0.024565   \n",
       "2024-09-30                                                                      -0.005768   \n",
       "2024-10-31                                                                       0.002320   \n",
       "2024-11-30                                                                      -0.063772   \n",
       "\n",
       "            factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value  \\\n",
       "Date                                                                                       \n",
       "2009-10-31                                                                      1.557801   \n",
       "2009-11-30                                                                      1.516707   \n",
       "2009-12-31                                                                      1.687818   \n",
       "2010-01-31                                                                      1.669432   \n",
       "2010-02-28                                                                      1.752645   \n",
       "...                                                                                  ...   \n",
       "2024-07-31                                                                      8.425144   \n",
       "2024-08-31                                                                      8.218183   \n",
       "2024-09-30                                                                      8.170785   \n",
       "2024-10-31                                                                      8.189742   \n",
       "2024-11-30                                                                      7.667464   \n",
       "\n",
       "            factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return_pct_change_12m  \\\n",
       "Date                                                                                                             \n",
       "2009-10-31                                                                                                -inf   \n",
       "2009-11-30                                                                                           -1.897261   \n",
       "2009-12-31                                                                                           -0.001345   \n",
       "2010-01-31                                                                                           -1.268121   \n",
       "2010-02-28                                                                                            2.638953   \n",
       "...                                                                                                        ...   \n",
       "2024-07-31                                                                                           -0.479723   \n",
       "2024-08-31                                                                                           -3.604592   \n",
       "2024-09-30                                                                                           -1.140813   \n",
       "2024-10-31                                                                                           -0.192602   \n",
       "2024-11-30                                                                                           -1.382970   \n",
       "\n",
       "            factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return_pct_change_12m  \\\n",
       "Date                                                                                                       \n",
       "2009-10-31                                                                                          -inf   \n",
       "2009-11-30                                                                                      3.657964   \n",
       "2009-12-31                                                                                      2.706723   \n",
       "2010-01-31                                                                                     -1.301294   \n",
       "2010-02-28                                                                                      3.372724   \n",
       "...                                                                                                  ...   \n",
       "2024-07-31                                                                                     -3.547213   \n",
       "2024-08-31                                                                                     -7.631673   \n",
       "2024-09-30                                                                                     -0.801113   \n",
       "2024-10-31                                                                                     -1.027701   \n",
       "2024-11-30                                                                                     -1.624310   \n",
       "\n",
       "            factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value_zscore_12m  \\\n",
       "Date                                                                                                        \n",
       "2009-10-31                                                                                      -1.380729   \n",
       "2009-11-30                                                                                      -1.366047   \n",
       "2009-12-31                                                                                      -1.351967   \n",
       "2010-01-31                                                                                      -1.336177   \n",
       "2010-02-28                                                                                      -1.322149   \n",
       "...                                                                                                   ...   \n",
       "2024-07-31                                                                                       1.863306   \n",
       "2024-08-31                                                                                       1.891093   \n",
       "2024-09-30                                                                                       1.905673   \n",
       "2024-10-31                                                                                       1.930182   \n",
       "2024-11-30                                                                                       1.955778   \n",
       "\n",
       "            factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value_zscore_12m  \\\n",
       "Date                                                                                                  \n",
       "2009-10-31                                                                                -1.640817   \n",
       "2009-11-30                                                                                -1.619876   \n",
       "2009-12-31                                                                                -1.600265   \n",
       "2010-01-31                                                                                -1.575365   \n",
       "2010-02-28                                                                                -1.552547   \n",
       "...                                                                                             ...   \n",
       "2024-07-31                                                                                 1.361817   \n",
       "2024-08-31                                                                                 1.382030   \n",
       "2024-09-30                                                                                 1.393377   \n",
       "2024-10-31                                                                                 1.411562   \n",
       "2024-11-30                                                                                 1.454628   \n",
       "\n",
       "                코스피     코스닥  코스피_pct_change_12m  코스닥_pct_change_12m  \\\n",
       "Date                                                                  \n",
       "2009-10-31  1580.69  486.46            0.155436            0.147855   \n",
       "2009-11-30  1555.60  464.32            0.420130            0.579262   \n",
       "2009-12-31  1682.77  513.57            0.445631            0.510082   \n",
       "2010-01-31  1602.43  496.57            0.496501            0.546665   \n",
       "2010-02-28  1594.58  507.03            0.378897            0.360839   \n",
       "...             ...     ...                 ...                 ...   \n",
       "2024-07-31  2770.69  803.15            0.091074           -0.032019   \n",
       "2024-08-31  2674.31  767.66            0.052462           -0.141906   \n",
       "2024-09-30  2593.27  763.88            0.046177           -0.173137   \n",
       "2024-10-31  2556.15  743.06            0.052007           -0.091722   \n",
       "2024-11-30  2482.29  682.91            0.122108            0.009455   \n",
       "\n",
       "            Risk_Free_Rate  Risk_Free_Rate_pct_change_12m  Exchange_Rate  \\\n",
       "Date                                                                       \n",
       "2009-10-31           3.510                      -0.362162    1162.800049   \n",
       "2009-11-30           3.120                      -0.283673    1160.599976   \n",
       "2009-12-31           3.480                      -0.360656    1151.099976   \n",
       "2010-01-31           3.220                       0.067485    1147.699951   \n",
       "2010-02-28           3.070                       0.272727    1133.599976   \n",
       "...                    ...                            ...            ...   \n",
       "2024-07-31           3.152                      -0.065956    1383.500000   \n",
       "2024-08-31           3.060                      -0.105308    1336.569946   \n",
       "2024-09-30           2.826                      -0.125714    1309.300049   \n",
       "2024-10-31           2.875                      -0.228080    1378.569946   \n",
       "2024-11-30           2.886                      -0.231283    1393.300049   \n",
       "\n",
       "            Exchange_Rate_pct_change_12m  \n",
       "Date                                      \n",
       "2009-10-31                     -0.025813  \n",
       "2009-11-30                     -0.098045  \n",
       "2009-12-31                     -0.206373  \n",
       "2010-01-31                     -0.073338  \n",
       "2010-02-28                     -0.154113  \n",
       "...                                  ...  \n",
       "2024-07-31                      0.043240  \n",
       "2024-08-31                      0.087324  \n",
       "2024-09-30                      0.010234  \n",
       "2024-10-31                     -0.031533  \n",
       "2024-11-30                      0.022625  \n",
       "\n",
       "[182 rows x 16 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2.3 전략 데이터 로드 및 합치기\n",
    "'''\n",
    "#딱 세 개만 사용 : 위의 전략 목록중 3개 임의로 선택\n",
    "best_results = [best_results[1], best_results[5]\n",
    "                # , best_results[9]\n",
    "               ]\n",
    "\n",
    "# 각 전략의 월별 수익률과 포트폴리오 가치를 저장할 데이터프레임 리스트 초기화\n",
    "strategy_returns = []\n",
    "\n",
    "# 각 CSV 파일을 읽어서 데이터프레임 생성\n",
    "for csv_file in best_results:\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(csv_file, index_col=0, parse_dates=True)\n",
    "    \n",
    "    # 전략 이름 생성\n",
    "    folder_name, file_name = os.path.split(csv_file)\n",
    "    factor_name = folder_name\n",
    "    strategy_info = file_name.replace('.csv', '')\n",
    "    strategy_name = f\"{factor_name}_{strategy_info}\"\n",
    "    \n",
    "    # 'Monthly Return'과 'Portfolio Value' 컬럼 존재 여부 확인\n",
    "    if 'Monthly Return' in df.columns and 'Portfolio Value' in df.columns:\n",
    "        # 데이터프레임에 전략 이름을 접두사로 추가하여 컬럼 이름 변경\n",
    "        df = df[['Monthly Return', 'Portfolio Value']].copy()\n",
    "        df.columns = [f\"{strategy_name}_Return\", f\"{strategy_name}_Value\"]\n",
    "        \n",
    "        # 리스트에 추가\n",
    "        strategy_returns.append(df)\n",
    "    else:\n",
    "        print(f\"'Monthly Return' 또는 'Portfolio Value' 컬럼이 없습니다: {csv_file}\")\n",
    "\n",
    "# 모든 전략의 데이터프레임을 하나로 합치기\n",
    "combined_df = pd.concat(strategy_returns, axis=1)\n",
    "\n",
    "# 날짜로 정렬\n",
    "combined_df = combined_df.sort_index()\n",
    "\n",
    "# 수익률 데이터에 pct_change 계산 및 추가\n",
    "return_columns = [col for col in combined_df.columns if '_Return' in col]\n",
    "for period in periods:\n",
    "    for col in return_columns:\n",
    "        combined_df[f\"{col}_pct_change_{period}m\"] = combined_df[col].pct_change(periods=period)\n",
    "\n",
    "# 누적 수익률 데이터에 대해 횡단면적 Z-Score 계산\n",
    "value_columns = [col for col in combined_df.columns if '_Value' in col]\n",
    "\n",
    "def calculate_zscore_over_periods(df, columns, periods):\n",
    "    \"\"\"기간별 Z-Score 계산\"\"\"\n",
    "    for period in periods:\n",
    "        # 숫자형 데이터만 선택\n",
    "        numeric_columns = df[columns].select_dtypes(include=[\"number\"])\n",
    "        rolling_window = numeric_columns.rolling(window=period).mean()\n",
    "        \n",
    "        # Z-Score 계산\n",
    "        zscore_df = rolling_window.apply(lambda x: zscore(x, nan_policy='omit') if len(x) > 1 else None, raw=False)\n",
    "        zscore_df.columns = [f\"{col}_zscore_{period}m\" for col in numeric_columns.columns]\n",
    "\n",
    "        # 직전 시점 값으로 이동\n",
    "        zscore_df = zscore_df.shift(1)\n",
    "        \n",
    "        # 원본 데이터프레임에 추가\n",
    "        df = df.join(zscore_df)\n",
    "    return df\n",
    "\n",
    "# Z-Score 계산 (3개월, 6개월, 12개월)\n",
    "combined_df = calculate_zscore_over_periods(combined_df, value_columns, periods)\n",
    "\n",
    "# 추가 데이터 합치기\n",
    "combined_df = combined_df.join(market_indices, how='left')\n",
    "combined_df = combined_df.join(rf_monthly, how='left')\n",
    "combined_df = combined_df.join(exchange_rate, how='left')\n",
    "\n",
    "# 결측치 처리 (앞 방향으로 채우기)\n",
    "combined_df = combined_df.fillna(method='ffill').dropna()\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\n합쳐진 데이터프레임의 일부:\")\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3e15bf82-a76e-4e86-8e54-f208de69d4c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "레이블이 추가된 데이터프레임의 일부:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best_Strategy</th>\n",
       "      <th>Best_Strategy_Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-10-31</th>\n",
       "      <td>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-30</th>\n",
       "      <td>factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-31</th>\n",
       "      <td>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-31</th>\n",
       "      <td>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30</th>\n",
       "      <td>factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31</th>\n",
       "      <td>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-30</th>\n",
       "      <td>factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  Best_Strategy  \\\n",
       "Date                                                                                              \n",
       "2009-10-31        factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return   \n",
       "2009-11-30  factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return   \n",
       "2009-12-31  factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return   \n",
       "2010-01-31        factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return   \n",
       "2010-02-28        factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return   \n",
       "...                                                                                         ...   \n",
       "2024-07-31        factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return   \n",
       "2024-08-31        factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return   \n",
       "2024-09-30  factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return   \n",
       "2024-10-31        factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return   \n",
       "2024-11-30  factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return   \n",
       "\n",
       "            Best_Strategy_Label  \n",
       "Date                             \n",
       "2009-10-31                    1  \n",
       "2009-11-30                    0  \n",
       "2009-12-31                    0  \n",
       "2010-01-31                    1  \n",
       "2010-02-28                    1  \n",
       "...                         ...  \n",
       "2024-07-31                    1  \n",
       "2024-08-31                    1  \n",
       "2024-09-30                    0  \n",
       "2024-10-31                    1  \n",
       "2024-11-30                    0  \n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3. 레이블 생성\n",
    "'''\n",
    "# 각 시점마다 가장 높은 수익률을 보인 전략의 이름을 레이블로 생성\n",
    "return_columns = [col for col in combined_df.columns if 'Return' in col and 'pct_change' not in col and 'STD' not in col]\n",
    "combined_df['Best_Strategy'] = combined_df[return_columns].idxmax(axis=1)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "combined_df['Best_Strategy_Label'] = label_encoder.fit_transform(combined_df['Best_Strategy'])\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\n레이블이 추가된 데이터프레임의 일부:\")\n",
    "combined_df[['Best_Strategy', 'Best_Strategy_Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3a4ce0eb-e5a2-425b-8440-989e9735cf49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 개수: 109\n",
      "Best_Strategy_Label\n",
      "0    59\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "Validation 데이터 개수: 36\n",
      "Best_Strategy_Label\n",
      "0    21\n",
      "1    15\n",
      "Name: count, dtype: int64\n",
      "Test 데이터 개수: 36\n",
      "Best_Strategy_Label\n",
      "0    21\n",
      "1    15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_start_date = pd.to_datetime('2007-11-30')\n",
    "train_end_date = pd.to_datetime('2018-10-31')\n",
    "val_start_date = pd.to_datetime('2018-11-30')\n",
    "val_end_date = pd.to_datetime('2021-10-31')\n",
    "test_start_date = pd.to_datetime('2021-11-30')\n",
    "test_end_date = pd.to_datetime('2024-10-31')\n",
    "\n",
    "# Train, validation, test 데이터 나누기\n",
    "train_data = combined_df[(combined_df.index >= train_start_date) & (combined_df.index <= train_end_date)]\n",
    "val_data = combined_df[(combined_df.index >= val_start_date) & (combined_df.index <= val_end_date)]\n",
    "test_data = combined_df[(combined_df.index >= test_start_date) & (combined_df.index <= test_end_date)]\n",
    "\n",
    "# 각 데이터셋의 샘플 개수 출력\n",
    "print(f\"Train 데이터 개수: {len(train_data)}\")\n",
    "print(train_data['Best_Strategy_Label'].value_counts())\n",
    "print(f\"Validation 데이터 개수: {len(val_data)}\")\n",
    "print(val_data['Best_Strategy_Label'].value_counts())\n",
    "print(f\"Test 데이터 개수: {len(test_data)}\")\n",
    "print(test_data['Best_Strategy_Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e686c-daf2-4ac9-854a-c80b5b4ec41c",
   "metadata": {},
   "source": [
    "# 딥-러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "312d6126-8d49-4611-a625-ce84d1d710fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# 0. 가정된 전역 변수들 (사용 예)\n",
    "###################################\n",
    "# 날짜 범위\n",
    "train_start_date = pd.to_datetime('2007-11-30')\n",
    "train_end_date = pd.to_datetime('2018-10-31')\n",
    "val_start_date = pd.to_datetime('2018-11-30')\n",
    "val_end_date = pd.to_datetime('2021-10-31')\n",
    "test_start_date = pd.to_datetime('2021-11-30')\n",
    "test_end_date = pd.to_datetime('2024-10-31')\n",
    "\n",
    "label_col = 'Best_Strategy_Label'\n",
    "strategy_return_cols = [\n",
    "    'factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return',\n",
    "    'factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return'\n",
    "    # 'factor_retained_earnings_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return'\n",
    "]\n",
    "\n",
    "num_classes = len(strategy_return_cols)\n",
    "\n",
    "# feature_cols에서 다음을 제외:\n",
    "# - 타겟 라벨(Best_Strategy_Label)\n",
    "# - 직접적으로 전략 수익률 컬럼(strategy_return_cols)\n",
    "# - Best_Strategy (라벨과 유사, 미래예측에 활용 불가한 정보)\n",
    "#\n",
    "# pct_change나 Value_zscore 컬럼도 사용해볼 수 있으므로 제외 조건 제거\n",
    "feature_cols = [\n",
    "    col for col in combined_df.columns \n",
    "    if col not in [label_col, 'Best_Strategy'] + strategy_return_cols\n",
    "]\n",
    "\n",
    "# Hyperparameters\n",
    "lookback = 12\n",
    "batch_size = 64\n",
    "epochs = 80\n",
    "learning_rate = 0.001\n",
    "use_gru = True  # True면 GRU, False면 LSTM\n",
    "use_diff = False  # 비정상성 데이터 차분 적용여부\n",
    "diff_cols = []    # 차분 적용할 컬럼 리스트\n",
    "use_pca = False    # PCA 적용 여부\n",
    "n_pca_components = 5\n",
    "use_oversampling = False  # 오버샘플링 여부 (ADASYN)\n",
    "unit = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bb608008-8ab1-4a7a-85c3-a35441dce282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value',\n",
       " 'factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value',\n",
       " 'factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return_pct_change_12m',\n",
       " 'factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return_pct_change_12m',\n",
       " 'factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value_zscore_12m',\n",
       " 'factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value_zscore_12m',\n",
       " '코스피',\n",
       " '코스닥',\n",
       " '코스피_pct_change_12m',\n",
       " '코스닥_pct_change_12m',\n",
       " 'Risk_Free_Rate',\n",
       " 'Risk_Free_Rate_pct_change_12m',\n",
       " 'Exchange_Rate',\n",
       " 'Exchange_Rate_pct_change_12m']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "42f40547-1fb4-4ce2-b07e-7a6996662566",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# 함수 정의 (반복적으로 사용하는 것만)\n",
    "###################################\n",
    "def custom_loss_fn(y_true, y_pred, returns):\n",
    "    actual_return = tf.reduce_sum(y_true * returns, axis=1)\n",
    "    predicted_return = tf.reduce_sum(y_pred * returns, axis=1)\n",
    "    return tf.reduce_mean(tf.square(actual_return - predicted_return))\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, optimizer, x, y, r):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True)\n",
    "        loss_value = custom_loss_fn(y, y_pred, r)\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def val_step(model, x, y, r):\n",
    "    y_pred = model(x, training=False)\n",
    "    loss_value = custom_loss_fn(y, y_pred, r)\n",
    "    return loss_value, y_pred\n",
    "\n",
    "def scale_returns(train_ret, val_ret, test_ret):\n",
    "    scaler = StandardScaler()\n",
    "    train_ret_scaled = scaler.fit_transform(train_ret)\n",
    "    val_ret_scaled = scaler.transform(val_ret)\n",
    "    test_ret_scaled = scaler.transform(test_ret)\n",
    "    return train_ret_scaled, val_ret_scaled, test_ret_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "25c86ed7-6181-4dad-b073-cebac03ad798",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# 메인 코드 시작\n",
    "###################################\n",
    "\n",
    "# 1. 차분 적용 (if use_diff)\n",
    "if use_diff and len(diff_cols) > 0:\n",
    "    df = combined_df.copy()\n",
    "    for c in diff_cols:\n",
    "        if c in df.columns:\n",
    "            df[c+'_diff'] = df[c].diff()\n",
    "    df.dropna(inplace=True)\n",
    "    # 차분 적용 시, feature_cols 갱신\n",
    "    for c in diff_cols:\n",
    "        if c in df.columns and c+'_diff' in df.columns:\n",
    "            feature_cols.append(c+'_diff')\n",
    "    # 원본 컬럼을 유지하거나 제거할지 결정\n",
    "    # 여기서는 원본 유지 + diff컬럼 추가한 상태로 진행\n",
    "    combined_df = df\n",
    "else:\n",
    "    # 차분 적용 안함\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5559d357-35fc-4ea5-bcc0-6658ca0ae044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train/Val/Test split\n",
    "train_df = combined_df.loc[train_start_date:train_end_date]\n",
    "val_df = combined_df.loc[val_start_date:val_end_date]\n",
    "test_df = combined_df.loc[test_start_date:test_end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6156c844-452a-4d3a-8fac-e01446fd921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차분, PCA 등 전처리 완료 후 스케일링 전 단계\n",
    "train_df[feature_cols] = train_df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "val_df[feature_cols] = val_df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "test_df[feature_cols] = test_df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 결측치 드롭 (필요 시 전략적으로 처리)\n",
    "train_df = train_df.dropna(subset=feature_cols)\n",
    "val_df = val_df.dropna(subset=feature_cols)\n",
    "test_df = test_df.dropna(subset=feature_cols)\n",
    "\n",
    "# 3. PCA 적용 (if use_pca)\n",
    "# PCA는 (samples, features) 형태로 변환 후 다시 dataframe에 붙여야 함\n",
    "if use_pca:\n",
    "    pca_scaler = StandardScaler()\n",
    "    train_scaled = pca_scaler.fit_transform(train_df[feature_cols])\n",
    "    pca = PCA(n_components=n_pca_components)\n",
    "    train_pca = pca.fit_transform(train_scaled)\n",
    "\n",
    "    # validation, test PCA 적용\n",
    "    val_scaled = pca_scaler.transform(val_df[feature_cols])\n",
    "    val_pca = pca.transform(val_scaled)\n",
    "    test_scaled = pca_scaler.transform(test_df[feature_cols])\n",
    "    test_pca = pca.transform(test_scaled)\n",
    "\n",
    "    # PCA 컴포넌트를 DF에 붙이기\n",
    "    pca_cols = [f'PCA_{i+1}' for i in range(n_pca_components)]\n",
    "    for i, col in enumerate(pca_cols):\n",
    "        train_df[col] = train_pca[:, i]\n",
    "        val_df[col] = val_pca[:, i]\n",
    "        test_df[col] = test_pca[:, i]\n",
    "\n",
    "    # feature_cols 업데이트\n",
    "    feature_cols = feature_cols + pca_cols\n",
    "else:\n",
    "    # PCA 미적용 시\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "419fe41b-7e2c-4b2f-92c0-f6ecb22fdd46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. Scaling feature_cols\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_df[feature_cols])\n",
    "val_X = scaler.transform(val_df[feature_cols])\n",
    "test_X = scaler.transform(test_df[feature_cols])\n",
    "\n",
    "# 라벨, 리턴 추출\n",
    "train_y = train_df[label_col].values\n",
    "val_y = val_df[label_col].values\n",
    "test_y = test_df[label_col].values\n",
    "\n",
    "train_r = train_df[strategy_return_cols].values\n",
    "val_r = val_df[strategy_return_cols].values\n",
    "test_r = test_df[strategy_return_cols].values\n",
    "\n",
    "# 수익률 스케일링\n",
    "train_r, val_r, test_r = scale_returns(train_r, val_r, test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b3513b2a-5af7-47b3-9321-b51493cfbe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. create_sequences\n",
    "def create_sequences(X, y, returns, lookback=12):\n",
    "    X_seq, y_seq, ret_seq = [], [], []\n",
    "    for i in range(len(X)-lookback):\n",
    "        X_seq.append(X[i:i+lookback])\n",
    "        y_seq.append(y[i+lookback])\n",
    "        ret_seq.append(returns[i+lookback])\n",
    "    return np.array(X_seq), np.array(y_seq), np.array(ret_seq)\n",
    "\n",
    "train_X_seq, train_y_seq, train_ret_seq = create_sequences(train_X, train_y, train_r, lookback)\n",
    "val_X_seq, val_y_seq, val_ret_seq = create_sequences(val_X, val_y, val_r, lookback)\n",
    "test_X_seq, test_y_seq, test_ret_seq = create_sequences(test_X, test_y, test_r, lookback)\n",
    "\n",
    "# One-hot label\n",
    "train_y_cat = tf.keras.utils.to_categorical(train_y_seq, num_classes=num_classes)\n",
    "val_y_cat = tf.keras.utils.to_categorical(val_y_seq, num_classes=num_classes)\n",
    "test_y_cat = tf.keras.utils.to_categorical(test_y_seq, num_classes=num_classes)\n",
    "\n",
    "train_X_seq = train_X_seq.astype(np.float32)\n",
    "train_y_cat = train_y_cat.astype(np.float32)\n",
    "train_ret_seq = train_ret_seq.astype(np.float32)\n",
    "\n",
    "val_X_seq = val_X_seq.astype(np.float32)\n",
    "val_y_cat = val_y_cat.astype(np.float32)\n",
    "val_ret_seq = val_ret_seq.astype(np.float32)\n",
    "\n",
    "test_X_seq = test_X_seq.astype(np.float32)\n",
    "test_y_cat = test_y_cat.astype(np.float32)\n",
    "test_ret_seq = test_ret_seq.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dd9e48b9-d32c-46b0-aab9-ede7d907bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 오버샘플링 (if use_oversampling)\n",
    "if use_oversampling:\n",
    "    # ADASYN은 2D 데이터 필요 -> (samples, timesteps*features)로 변경\n",
    "    orig_shape = train_X_seq.shape\n",
    "    samples, timesteps, features = orig_shape\n",
    "    X_2d = train_X_seq.reshape(samples, timesteps*features)\n",
    "    y_int = np.argmax(train_y_cat, axis=1)  # One-hot -> int label\n",
    "\n",
    "    adasyn = ADASYN()\n",
    "    X_res, y_res = adasyn.fit_resample(X_2d, y_int)\n",
    "    # 다시 3D로 변환\n",
    "    new_samples = X_res.shape[0]\n",
    "    X_res_3d = X_res.reshape(new_samples, timesteps, features)\n",
    "    # returns도 oversampling?\n",
    "    # oversampling 라벨 개수 늘어났으니 return도 필요. \n",
    "    # 하지만 return은 라벨과 1:1이므로 y와 같이 oversample 해야함.\n",
    "    # y_res 인덱스를 활용하기 위해 인덱스 매핑 필요\n",
    "    # 이건 실제 구현 시 주의 필요. 여기서는 라벨과 동일 인덱스로 mapping된다고 가정불가.\n",
    "    # 간단히는 오버샘플링 전후 라벨 순서 유지 불가 -> ADASYN 후 y_res 인덱스로 train_ret_seq도 재배열 불가\n",
    "    # 실제론 y_res의 각 샘플이 기존 어떤 샘플에서 생성됐는지 추적 필요.\n",
    "    # 여기서는 단순 예시로 오버샘플링 시 returns는 적용하지 않고 pass(실무에서는 재설계 필요)\n",
    "    # 오버샘플링은 시계열에 부자연스러우므로 여기선 skip을 권장하지만, 요구사항이므로 예제만.\n",
    "    # 만약 return도 oversample하려면 같은 random_state로 ADASYN fitter를 사용해 \n",
    "    # 라벨별 인덱스 추적 후 returns 재배치를 해야함.\n",
    "    # 여기선 간략히 returns 재매핑 안함 -> 실제론 불일치 발생, 이건 구현상 한계\n",
    "    \n",
    "    # Warning: 아래 코드는 oversampling과 returns 일치성 문제 있음(단순히 same indexing이라 가정)\n",
    "    # 실제로는 returns도 fit_resample 해야 하나, ADASYN은 y 기반이므로 returns 다룰때 주의 필요.\n",
    "    # 여기서는 가상의 로직 (returns도 y와 동일 indexing이라 가정)\n",
    "    train_ret_seq = train_ret_seq[y_int.argsort()][y_res.argsort()] # 이건 가짜로 만든 예\n",
    "    # 이 부분 실제로는 별도 로직 필요. 여기선 단순히 형식 맞추기 어려움\n",
    "    # 실제로는 oversampling이 시계열에 부적절할 수 있음.\n",
    "\n",
    "    train_X_seq = X_res_3d\n",
    "    train_y_cat = tf.keras.utils.to_categorical(y_res, num_classes=num_classes)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3de8fb54-6028-445e-b75b-c110a5d7ed80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 7. 모델 정의\n",
    "model = Sequential()\n",
    "if use_gru:\n",
    "    model.add(GRU(units=unit, activation='elu', input_shape=(lookback, len(feature_cols))))\n",
    "else:\n",
    "    model.add(LSTM(units=unit, activation='elu', input_shape=(lookback, len(feature_cols))))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "19139851-59a9-4152-ba7e-7f3ddc05b762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.0628, Val Loss: 0.4881\n",
      "Epoch 2, Train Loss: 0.0676, Val Loss: 0.4914\n",
      "Epoch 3, Train Loss: 0.0660, Val Loss: 0.4897\n",
      "Epoch 4, Train Loss: 0.0593, Val Loss: 0.4895\n",
      "Epoch 5, Train Loss: 0.0634, Val Loss: 0.4903\n",
      "Epoch 6, Train Loss: 0.0564, Val Loss: 0.4913\n",
      "Epoch 7, Train Loss: 0.0601, Val Loss: 0.4931\n",
      "Epoch 8, Train Loss: 0.0638, Val Loss: 0.4944\n",
      "Epoch 9, Train Loss: 0.0609, Val Loss: 0.4960\n",
      "Epoch 10, Train Loss: 0.0617, Val Loss: 0.4990\n",
      "Epoch 11, Train Loss: 0.0585, Val Loss: 0.4992\n",
      "Epoch 12, Train Loss: 0.0632, Val Loss: 0.5005\n",
      "Epoch 13, Train Loss: 0.0598, Val Loss: 0.5009\n",
      "Epoch 14, Train Loss: 0.0575, Val Loss: 0.5015\n",
      "Epoch 15, Train Loss: 0.0615, Val Loss: 0.5033\n",
      "Epoch 16, Train Loss: 0.0569, Val Loss: 0.5028\n",
      "Epoch 17, Train Loss: 0.0613, Val Loss: 0.5038\n",
      "Epoch 18, Train Loss: 0.0596, Val Loss: 0.5057\n",
      "Epoch 19, Train Loss: 0.0563, Val Loss: 0.5080\n",
      "Epoch 20, Train Loss: 0.0583, Val Loss: 0.5117\n",
      "Epoch 21, Train Loss: 0.0592, Val Loss: 0.5157\n",
      "Epoch 22, Train Loss: 0.0576, Val Loss: 0.5189\n",
      "Epoch 23, Train Loss: 0.0519, Val Loss: 0.5219\n",
      "Epoch 24, Train Loss: 0.0550, Val Loss: 0.5254\n",
      "Epoch 25, Train Loss: 0.0560, Val Loss: 0.5284\n",
      "Epoch 26, Train Loss: 0.0570, Val Loss: 0.5317\n",
      "Epoch 27, Train Loss: 0.0556, Val Loss: 0.5344\n",
      "Epoch 28, Train Loss: 0.0546, Val Loss: 0.5368\n",
      "Epoch 29, Train Loss: 0.0507, Val Loss: 0.5364\n",
      "Epoch 30, Train Loss: 0.0579, Val Loss: 0.5380\n",
      "Epoch 31, Train Loss: 0.0546, Val Loss: 0.5373\n",
      "Epoch 32, Train Loss: 0.0539, Val Loss: 0.5367\n",
      "Epoch 33, Train Loss: 0.0544, Val Loss: 0.5359\n",
      "Epoch 34, Train Loss: 0.0506, Val Loss: 0.5351\n",
      "Epoch 35, Train Loss: 0.0518, Val Loss: 0.5350\n",
      "Epoch 36, Train Loss: 0.0510, Val Loss: 0.5358\n",
      "Epoch 37, Train Loss: 0.0502, Val Loss: 0.5353\n",
      "Epoch 38, Train Loss: 0.0528, Val Loss: 0.5348\n",
      "Epoch 39, Train Loss: 0.0561, Val Loss: 0.5319\n",
      "Epoch 40, Train Loss: 0.0516, Val Loss: 0.5282\n",
      "Epoch 41, Train Loss: 0.0520, Val Loss: 0.5241\n",
      "Epoch 42, Train Loss: 0.0514, Val Loss: 0.5208\n",
      "Epoch 43, Train Loss: 0.0483, Val Loss: 0.5190\n",
      "Epoch 44, Train Loss: 0.0492, Val Loss: 0.5172\n",
      "Epoch 45, Train Loss: 0.0483, Val Loss: 0.5181\n",
      "Epoch 46, Train Loss: 0.0448, Val Loss: 0.5194\n",
      "Epoch 47, Train Loss: 0.0471, Val Loss: 0.5202\n",
      "Epoch 48, Train Loss: 0.0443, Val Loss: 0.5221\n",
      "Epoch 49, Train Loss: 0.0457, Val Loss: 0.5243\n",
      "Epoch 50, Train Loss: 0.0477, Val Loss: 0.5274\n",
      "Epoch 51, Train Loss: 0.0447, Val Loss: 0.5313\n",
      "Epoch 52, Train Loss: 0.0450, Val Loss: 0.5320\n",
      "Epoch 53, Train Loss: 0.0467, Val Loss: 0.5317\n",
      "Epoch 54, Train Loss: 0.0433, Val Loss: 0.5295\n",
      "Epoch 55, Train Loss: 0.0458, Val Loss: 0.5271\n",
      "Epoch 56, Train Loss: 0.0441, Val Loss: 0.5248\n",
      "Epoch 57, Train Loss: 0.0477, Val Loss: 0.5217\n",
      "Epoch 58, Train Loss: 0.0430, Val Loss: 0.5171\n",
      "Epoch 59, Train Loss: 0.0459, Val Loss: 0.5120\n",
      "Epoch 60, Train Loss: 0.0468, Val Loss: 0.5053\n",
      "Epoch 61, Train Loss: 0.0423, Val Loss: 0.4973\n",
      "Epoch 62, Train Loss: 0.0418, Val Loss: 0.4920\n",
      "Epoch 63, Train Loss: 0.0419, Val Loss: 0.4874\n",
      "Epoch 64, Train Loss: 0.0386, Val Loss: 0.4814\n",
      "Epoch 65, Train Loss: 0.0419, Val Loss: 0.4778\n",
      "Epoch 66, Train Loss: 0.0424, Val Loss: 0.4743\n",
      "Epoch 67, Train Loss: 0.0419, Val Loss: 0.4762\n",
      "Epoch 68, Train Loss: 0.0372, Val Loss: 0.4786\n",
      "Epoch 69, Train Loss: 0.0396, Val Loss: 0.4788\n",
      "Epoch 70, Train Loss: 0.0402, Val Loss: 0.4787\n",
      "Epoch 71, Train Loss: 0.0386, Val Loss: 0.4770\n",
      "Epoch 72, Train Loss: 0.0367, Val Loss: 0.4726\n",
      "Epoch 73, Train Loss: 0.0387, Val Loss: 0.4718\n",
      "Epoch 74, Train Loss: 0.0368, Val Loss: 0.4699\n",
      "Epoch 75, Train Loss: 0.0391, Val Loss: 0.4656\n",
      "Epoch 76, Train Loss: 0.0367, Val Loss: 0.4616\n",
      "Epoch 77, Train Loss: 0.0387, Val Loss: 0.4558\n",
      "Epoch 78, Train Loss: 0.0371, Val Loss: 0.4477\n",
      "Epoch 79, Train Loss: 0.0397, Val Loss: 0.4400\n",
      "Epoch 80, Train Loss: 0.0386, Val Loss: 0.4339\n"
     ]
    }
   ],
   "source": [
    "# 8. Dataset 준비\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_X_seq, train_y_cat, train_ret_seq)).shuffle(1024).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_X_seq, val_y_cat, val_ret_seq)).batch(batch_size)\n",
    "\n",
    "# 여기서 더미 인퍼런스 한 번 실행 (train_dataset에서 하나 추출)\n",
    "# Creating variables on a non-first call to a function decorated with tf.function 에러 방지용\n",
    "x_dummy, y_dummy, r_dummy = next(iter(train_dataset))\n",
    "model(x_dummy)  # 이렇게 한 번 호출해서 변수 생성 완료\n",
    "\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    for x_batch, y_batch, r_batch in train_dataset:\n",
    "        loss_value = train_step(model, optimizer, x_batch, y_batch, r_batch)\n",
    "        train_losses.append(loss_value.numpy())\n",
    "\n",
    "    val_losses = []\n",
    "    for x_batch, y_batch, r_batch in val_dataset:\n",
    "        val_loss_value, _ = val_step(model, x_batch, y_batch, r_batch)\n",
    "        val_losses.append(val_loss_value.numpy())\n",
    "\n",
    "    val_loss_mean = np.mean(val_losses)\n",
    "    train_loss_mean = np.mean(train_losses)\n",
    "    # if epoch%10==0:\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss_mean:.4f}, Val Loss: {val_loss_mean:.4f}\")\n",
    "\n",
    "    if val_loss_mean < best_val_loss:\n",
    "        best_val_loss = val_loss_mean\n",
    "        model.save('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc398f30-febd-4785-9654-5a48286e9331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
