{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc41eba-35c1-4218-a08e-6de2a7fd7edb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['GDPC1']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['UNRATE']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['CPIAUCSL']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_GDP</th>\n",
       "      <th>US_Unemployment</th>\n",
       "      <th>US_Inflation</th>\n",
       "      <th>KRW_USD_Exchange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-11-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>919.479980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>926.359985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>941.219971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>937.840027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>992.280029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1383.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1336.569946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1309.300049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1378.569946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1394.640015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            US_GDP  US_Unemployment  US_Inflation  KRW_USD_Exchange\n",
       "Date                                                               \n",
       "2007-11-30     NaN              NaN           NaN        919.479980\n",
       "2007-12-31     NaN              NaN           NaN        926.359985\n",
       "2008-01-31     NaN              NaN           NaN        941.219971\n",
       "2008-02-29     NaN              NaN           NaN        937.840027\n",
       "2008-03-31     NaN              NaN           NaN        992.280029\n",
       "...            ...              ...           ...               ...\n",
       "2024-07-31     NaN              NaN           NaN       1383.500000\n",
       "2024-08-31     NaN              NaN           NaN       1336.569946\n",
       "2024-09-30     NaN              NaN           NaN       1309.300049\n",
       "2024-10-31     NaN              NaN           NaN       1378.569946\n",
       "2024-11-30     NaN              NaN           NaN       1394.640015\n",
       "\n",
       "[205 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# 수집할 지표의 티커(symbol) 목록\n",
    "tickers = {\n",
    "    'US_GDP': 'GDPC1',          # 미국 GDP\n",
    "    'US_Unemployment': 'UNRATE', # 미국 실업률\n",
    "    'US_Inflation': 'CPIAUCSL',  # 미국 소비자물가지수\n",
    "    'KRW_USD_Exchange': 'KRW=X', # 원/달러 환율\n",
    "    # 추가적인 지표를 여기에 추가\n",
    "}\n",
    "\n",
    "# 데이터프레임을 저장할 딕셔너리\n",
    "data = {}\n",
    "\n",
    "# 각 티커에 대해 데이터 다운로드\n",
    "for name, ticker in tickers.items():\n",
    "    # 데이터 다운로드\n",
    "    df = yf.download(ticker, start='2007-10-31', end='2024-12-01', interval='1mo')\n",
    "    # 월말 데이터로 리샘플링\n",
    "    df = df.resample('M').last()\n",
    "    # 필요한 열만 선택\n",
    "    df = df[['Adj Close']]\n",
    "    # 열 이름 변경\n",
    "    df.columns = [name]\n",
    "    # 딕셔너리에 저장\n",
    "    data[name] = df\n",
    "\n",
    "# 모든 데이터를 하나의 데이터프레임으로 병합\n",
    "result = pd.concat(data.values(), axis=1)\n",
    "\n",
    "# 결과 출력\n",
    "result                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64657c3-f098-4eab-9c40-bf899ba7b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 팩터 전략별로 필요한 데이터를 계산하여 monthly_merged_df에 추가합니다.\n",
    "\n",
    "if 'monthly_merged_df' not in globals():\n",
    "    monthly_merged_df = pd.read_csv(\n",
    "        'data/merged_df_monthly_preprocessing.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6328d54-d6a3-419b-9a36-a97435953b07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CSV 부르기 및 기본적인 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa522af-a990-4a33-b348-445c51e6c468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 통합한 월별 데이터 파일이 존재합니다. 해당 CSV를 불러옵니다.\n",
      "월별 CSV를 불러왔습니다.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame을 저장할 리스트 생성\n",
    "df_list = []\n",
    "\n",
    "# 1. 'data' 폴더 내에 'KSIF'가 포함된 CSV 파일 목록 가져오기\n",
    "file_list = glob.glob('data/*KSIF*.csv')\n",
    "\n",
    "# 파일이 존재하는지 확인\n",
    "if not file_list:\n",
    "    print(\"패턴에 맞는 파일을 찾을 수 없습니다.\")\n",
    "elif os.path.exists('data/merged_df_monthly.csv'):\n",
    "    print(\"이미 통합한 월별 데이터 파일이 존재합니다. 해당 CSV를 불러옵니다.\")\n",
    "    merged_df_backup = pd.read_csv(\n",
    "        'data/merged_df_monthly.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "        parse_dates=True  # 인덱스를 datetime으로 파싱\n",
    "    )\n",
    "    print(\"월별 CSV를 불러왔습니다.\")\n",
    "elif os.path.exists('data/merged_data.csv'):\n",
    "    print(\"이미 통합한 일별 데이터 파일이 존재합니다. 해당 CSV를 월별로 전환합니다.\")\n",
    "    merged_df_backup = pd.read_csv(\n",
    "        'data/merged_data.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "    # 인덱스를 datetime으로 변환\n",
    "    merged_df_backup.index = pd.to_datetime(merged_df_backup.index, errors='coerce')\n",
    "    \n",
    "    # 월별 리샘플링\n",
    "    merged_df_backup = merged_df_backup.resample('M').last()\n",
    "    \n",
    "    # 월별 데이터 저장\n",
    "    merged_df_backup.to_csv('data/merged_df_monthly.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"월별 리샘플링된 데이터가 'merged_df_monthly.csv'로 저장되었습니다.\")\n",
    "    print(\"월별 CSV를 불러왔습니다.\")\n",
    "else:\n",
    "    # tqdm을 사용하여 진행 상황 표시\n",
    "    for file_path in tqdm(file_list, desc=\"파일 처리 중\"):\n",
    "        # 각 CSV 파일 읽기 (적절한 인코딩과 인덱스 설정)\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                skiprows=8,\n",
    "                header=[0, 1, 2, 3, 4, 5],\n",
    "                index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "                encoding='cp949',\n",
    "                parse_dates=True\n",
    "            )\n",
    "        except UnicodeDecodeError:\n",
    "            # 'cp949' 인코딩이 안 될 경우 'euc-kr'로 시도\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                skiprows=8,\n",
    "                header=[0, 1, 2, 3, 4, 5],\n",
    "                index_col=0,\n",
    "                encoding='euc-kr',\n",
    "                parse_dates=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"파일 {file_path}를 로드하는 중 에러 발생: {e}\")\n",
    "            continue  # 에러 발생 시 다음 파일로 넘어감\n",
    "        \n",
    "        # 멀티인덱스 컬럼에 이름 지정\n",
    "        df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "        \n",
    "        # 인덱스 이름 지정 ('Date'로 설정)\n",
    "        df.index.name = 'Date'\n",
    "        \n",
    "        # 인덱스를 datetime으로 변환\n",
    "        df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "        \n",
    "        # 'Kind', 'Frequency' 레벨 제거하여 필요한 컬럼만 남김\n",
    "        df.columns = df.columns.droplevel(['Kind', 'Frequency'])\n",
    "        \n",
    "        # 리스트에 DataFrame 추가\n",
    "        df_list.append(df)\n",
    "    \n",
    "    # 2. 모든 DataFrame을 수평적으로 병합\n",
    "    print(\"DataFrame 병합 중...\")\n",
    "    merged_df_backup = pd.concat(df_list, axis=1)\n",
    "    del df_list  # 리스트 메모리에서 삭제\n",
    "    gc.collect()  # 가비지 컬렉션 실행\n",
    "    \n",
    "    # 월별 리샘플링\n",
    "    print(\"월별 리샘플링 중...\")\n",
    "    merged_df_backup = merged_df_backup.resample('M').last()\n",
    "    \n",
    "    # 월별 데이터 저장\n",
    "    merged_df_backup.to_csv('data/merged_df_monthly.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"월별 리샘플링된 데이터가 'merged_df_monthly.csv'로 저장되었습니다.\")\n",
    "    \n",
    "    # 필요에 따라 일별 데이터를 저장하려면 아래 주석을 해제하세요.\n",
    "    # merged_df_backup.to_csv('data/merged_data.csv', encoding='utf-8-sig')\n",
    "    # print(\"모든 CSV 파일을 병합하여 'merged_data.csv'로 저장했습니다.\")\n",
    "\n",
    "    # 메모리 관리\n",
    "    del merged_df_backup\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993372a2-821d-46b6-b494-f828a95d8281",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m issues\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 점검 실행\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mcheck_dataframe_issues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#여기서 인덱스 2번이 뜨는 이유는 얘가 하루 더 있거등요 ㅇㅇ\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mcheck_dataframe_issues\u001b[1;34m(df_list)\u001b[0m\n\u001b[0;32m     10\u001b[0m issues \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_unique_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmismatched_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 기준 인덱스는 첫 번째 데이터프레임의 인덱스로 설정\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m base_index \u001b[38;5;241m=\u001b[39m \u001b[43mdf_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 각 데이터프레임 점검\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_list):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 1. 고유하지 않은 인덱스 확인\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def check_dataframe_issues(df_list):\n",
    "    \"\"\"\n",
    "    점검 함수: 데이터프레임 리스트에서 고유하지 않은 인덱스와 기준 인덱스 불일치 확인\n",
    "    Args:\n",
    "        df_list (list): pandas 데이터프레임들의 리스트\n",
    "    Returns:\n",
    "        dict: 문제를 가진 데이터프레임의 인덱스 (non_unique_index, mismatched_index)\n",
    "    \"\"\"\n",
    "    # 결과 저장용 딕셔너리\n",
    "    issues = {\"non_unique_index\": [], \"mismatched_index\": []}\n",
    "    \n",
    "    # 기준 인덱스는 첫 번째 데이터프레임의 인덱스로 설정\n",
    "    base_index = df_list[0].index\n",
    "\n",
    "    # 각 데이터프레임 점검\n",
    "    for i, df in enumerate(df_list):\n",
    "        # 1. 고유하지 않은 인덱스 확인\n",
    "        if not df.index.is_unique:\n",
    "            issues[\"non_unique_index\"].append(i)\n",
    "        \n",
    "        # 2. 기준 인덱스와 불일치 확인\n",
    "        if not base_index.equals(df.index):\n",
    "            issues[\"mismatched_index\"].append(i)\n",
    "\n",
    "    return issues\n",
    "\n",
    "# 점검 실행\n",
    "check_dataframe_issues(df_list)#여기서 인덱스 2번이 뜨는 이유는 얘가 하루 더 있거등요 ㅇㅇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f466bdd7-d688-49ec-8d17-d66b687424ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['수정주가(원)', 'PER(보통)(배)', 'PER(직전4분기)(배)', 'PER(보통,자사주차감)(배)',\n",
       "       'BPS(발표기준기말주식수)(원)', 'BPS(자사주차감)(원)', '상장주식수(주)', '시가총액 (평균)(원)',\n",
       "       '상장주식수 (보통)(주)', '매출총이익(원)', '총자산(원)', '유동자산(원)', '현금및현금성자산(원)',\n",
       "       '유동부채(원)', '단기차입금(원)', '이연법인세부채(원)', '거래대금(원)', '관리종목지정사유', '기타포괄손익(원)',\n",
       "       '베타 (M,3Yr)', '베타 (D,1Yr)', '보통주자본금(원)', '수익률(%)', '수익률 (1개월)(%)',\n",
       "       '수정주가 (52주 최고)(원)', '유무형자산상각비(원)', '이익잉여금(원)', 'Unnamed: 3182_level_4',\n",
       "       '이익잉여금(천원)'],\n",
       "      dtype='object', name='item Name')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_backup.columns.get_level_values(3).unique()#우리 데이터 뭐있나 함 볼까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24f2a1-46a7-4777-bd42-1f82fb9cf369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 월별 데이터로 작업할 merged_df 생성\n",
    "merged_df = merged_df_backup.copy()\n",
    "\n",
    "# 1. \"(원)\"으로 끝나는 컬럼 처리\n",
    "# 'item Name'이 '(원)'으로 끝나는 컬럼 선택\n",
    "won_mask = merged_df.columns.get_level_values('item Name').str.endswith('(원)')\n",
    "\n",
    "# 쉼표 제거 및 숫자 변환을 벡터화된 연산으로 수행\n",
    "# 문자열 'None', 'nan', '', 'N/A' 등을 NaN으로 변환\n",
    "merged_df.loc[:, won_mask] = (\n",
    "    merged_df.loc[:, won_mask]\n",
    "    .astype(str)  # 모든 데이터를 문자열로 변환\n",
    "    .replace(',', '', regex=True)  # 쉼표 제거\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A'], np.nan)  # 비정상적인 값들을 NaN으로 변환\n",
    "    .apply(pd.to_numeric, errors='coerce')  # 숫자로 변환 (변환 불가 시 NaN)\n",
    ")\n",
    "\n",
    "print(\"'(원)' 컬럼의 문자열 변환 및 숫자 변환 완료\")\n",
    "\n",
    "# 2. '홀딩스', '지주', '스펙'으로 끝나는 종목 제거\n",
    "pattern = ('홀딩스', '지주', '스펙', '스팩')\n",
    "symbol_names = merged_df.columns.get_level_values('Symbol Name')\n",
    "mask = symbol_names.str.endswith(pattern)\n",
    "merged_df = merged_df.loc[:, ~mask]\n",
    "\n",
    "# 3. '관리종목지정사유' 처리\n",
    "# '관리종목지정사유'가 있는 종목 추출\n",
    "management_mask = merged_df.columns.get_level_values('item Name') == '관리종목지정사유'\n",
    "management_df = merged_df.loc[:, management_mask]\n",
    "\n",
    "# 인덱스를 datetime 형태로 변환\n",
    "merged_df.index = pd.to_datetime(merged_df.index, errors='coerce')\n",
    "\n",
    "# 각 종목별로 처리\n",
    "for symbol in management_df.columns.get_level_values('Symbol').unique():\n",
    "    symbol_management = management_df.loc[:, management_df.columns.get_level_values('Symbol') == symbol]\n",
    "    \n",
    "    # NaN이 아닌 첫 번째 날짜 찾기\n",
    "    dates_with_issue = symbol_management[symbol_management.notna().any(axis=1)].index\n",
    "    \n",
    "    if not dates_with_issue.empty:\n",
    "        try:\n",
    "            # 이슈 발생 날짜\n",
    "            issue_date = dates_with_issue[0]\n",
    "            \n",
    "            # 해당 Symbol의 데이터를 처리\n",
    "            symbol_mask = merged_df.columns.get_level_values('Symbol') == symbol\n",
    "            price_mask = merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "            other_mask = symbol_mask & ~price_mask\n",
    "            \n",
    "            # 이슈 발생 월부터 이후 데이터에 대해 NaN으로 설정 (수정주가는 제외)\n",
    "            merged_df.loc[merged_df.index >= issue_date, other_mask] = np.nan\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing symbol: {symbol}, issue_date: {issue_date}, Error: {e}\")\n",
    "\n",
    "print('관리종목 포트폴리오 정상화')\n",
    "\n",
    "# 4. '거래대금(원)' 기반 종목 제거\n",
    "trading_value_mask = merged_df.columns.get_level_values('item Name') == '거래대금(원)'\n",
    "trading_value_df = merged_df.loc[:, trading_value_mask]\n",
    "\n",
    "# 인덱스를 datetime으로 변환\n",
    "trading_value_df.index = pd.to_datetime(trading_value_df.index)\n",
    "\n",
    "# 2014년 이후 데이터 선택\n",
    "trading_value_df = trading_value_df[trading_value_df.index >= '2014-01-31']\n",
    "\n",
    "# 문자열을 숫자로 변환 (오류 발생 시 NaN 처리)\n",
    "trading_value_df = trading_value_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 거래대금이 4천만원 이하인 경우 True, NaN은 False로 처리\n",
    "low_trading_value = (trading_value_df <= 40000000).fillna(False)\n",
    "\n",
    "# 각 Symbol마다 거래대금이 4천만원 이하인 달이 하나라도 있는지 확인\n",
    "symbols_to_remove = low_trading_value.any(axis=0)\n",
    "symbols_to_remove = symbols_to_remove[symbols_to_remove].index.get_level_values('Symbol').unique().tolist()\n",
    "\n",
    "# 해당 Symbol 제거\n",
    "symbol_mask = merged_df.columns.get_level_values('Symbol').isin(symbols_to_remove)\n",
    "merged_df = merged_df.loc[:, ~symbol_mask]\n",
    "\n",
    "print('market impact 조정 완료')\n",
    "\n",
    "# 5. 수정주가 기반 1개월 수익률 계산\n",
    "# 인덱스를 datetime으로 변환\n",
    "merged_df.index = pd.to_datetime(merged_df.index)\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = merged_df.loc[:, price_mask]\n",
    "\n",
    "# 월별 수익률 계산\n",
    "returns_df = price_df.pct_change()\n",
    "\n",
    "# 'item Name'을 '1개월 수익률(계산)'으로 변경\n",
    "returns_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, item, '1개월 수익률(계산)') for symbol, symbol_name, item in zip(\n",
    "        returns_df.columns.get_level_values('Symbol'),\n",
    "        returns_df.columns.get_level_values('Symbol Name'),\n",
    "        returns_df.columns.get_level_values('item')\n",
    "    )],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 수익률 데이터를 merged_df에 추가\n",
    "merged_df = pd.concat([merged_df, returns_df], axis=1)\n",
    "\n",
    "print('1개월 수익률 계산 완료')\n",
    "\n",
    "# 6. 결측치를 직전 값으로 대체\n",
    "merged_df = merged_df.fillna(method='ffill')\n",
    "\n",
    "print(\"전처리 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba780af-3c56-4772-b5c9-50d29dbc54ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('data/merged_df_monthly_preprocessing.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483dc094-5740-457f-9e86-f6022005d452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol   Symbol Name  item        item Name       \n",
       "A000660  SK하이닉스       S410000700  수정주가(원)               int64\n",
       "                      6000701101  PER(보통)(배)          float64\n",
       "                      6000701007  PER(직전4분기)(배)       float64\n",
       "                      6000701006  PER(보통,자사주차감)(배)    float64\n",
       "A373220  LG에너지솔루션     S410000700  수정주가(원)             float64\n",
       "                                                       ...   \n",
       "A900030  연합과기         S410000700  1개월 수익률(계산)         float64\n",
       "A900060  중국식품포장       S410000700  1개월 수익률(계산)         float64\n",
       "A900150  성융광전투자       S410000700  1개월 수익률(계산)         float64\n",
       "A950030  네프로아이티       S410000700  1개월 수익률(계산)         float64\n",
       "A950070  중국고섬         S410000700  1개월 수익률(계산)         float64\n",
       "Length: 58059, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_backup.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4290465-1b88-424e-9971-8e99a319a7a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 팩터값 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ee2c22-003a-4f71-8acd-265d6781415f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 팩터 전략별로 필요한 데이터를 계산하여 monthly_merged_df에 추가합니다.\n",
    "\n",
    "if 'monthly_merged_df' not in globals():\n",
    "    monthly_merged_df = pd.read_csv(\n",
    "        'data/merged_df_monthly_preprocessing.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "424f8216-865c-4d17-a2ac-66bacc9a1025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_high_pe_ratio.csv' 파일이 저장되었습니다.\n",
      "(206, 2052)\n",
      "'factor_high_pe_ratio_large_industry.csv' 파일이 저장되었습니다.\n",
      "'factor_high_pe_ratio_medium_industry.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 1: High P/E Ratio =====\n",
    "# 상위 20% 종목에 롱 포지션, 하위 20% 종목에 숏 포지션을 취하는 전략\n",
    "\n",
    "# 'PER(직전4분기)(배)' 데이터 추출\n",
    "per_mask = monthly_merged_df.columns.get_level_values('item Name') == 'PER(보통,자사주차감)(배)'\n",
    "per_df = monthly_merged_df.loc[:, per_mask]\n",
    "per_df.columns = per_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 결측치 처리 전에 per_df의 데이터를 float 타입으로 변환\n",
    "per_df = per_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 결측치 처리\n",
    "per_df = per_df.replace(0, np.nan)\n",
    "per_df = per_df.replace(np.inf, np.nan)\n",
    "per_df = per_df.fillna(method='ffill')\n",
    "\n",
    "# 전체 종목에 대해 z-score 계산\n",
    "per_zscore = -per_df.apply(lambda x: (x - x.mean()) / x.std(), axis=1)\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore.to_csv('factor_high_pe_ratio.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 산업 분류 데이터 불러오기\n",
    "try:\n",
    "    industry_df = pd.read_csv(\n",
    "        'data/industry.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    industry_df = pd.read_csv(\n",
    "        'data/industry.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "        encoding='cp949',\n",
    "        parse_dates=True  # 인덱스를 datetime으로 파싱\n",
    "    )\n",
    "    \n",
    "# 멀티인덱스 설정\n",
    "industry_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "industry_df.index.name = 'Date'\n",
    "\n",
    "# '한국표준산업분류10차(대분류)', '한국표준산업분류10차(중분류)' 데이터 추출\n",
    "industry_large_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(대분류)'\n",
    "industry_medium_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(중분류)'\n",
    "\n",
    "industry_large_df = industry_df.loc[:, industry_large_mask]\n",
    "industry_large_df.columns = industry_large_df.columns.droplevel(['item', 'item Name'])\n",
    "industry_medium_df = industry_df.loc[:, industry_medium_mask]\n",
    "industry_medium_df.columns = industry_medium_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# PER 데이터와 산업 분류 데이터의 인덱스 및 컬럼 정렬\n",
    "per_df, industry_large_df = per_df.align(industry_large_df, join='inner', axis=1)\n",
    "per_df, industry_medium_df = per_df.align(industry_medium_df, join='inner', axis=1)\n",
    "\n",
    "# 디버깅 출력을 위한 함수\n",
    "def debug_print(message, df=None):\n",
    "    print(message)\n",
    "    if df is not None:\n",
    "        print(df.head())\n",
    "        print(df.shape)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# 산업별로 z-score 계산\n",
    "def industry_zscore(per_series, industry_series):\n",
    "    df = pd.DataFrame({'PER': per_series, 'Industry': industry_series})\n",
    "    # NaN 값이 있는 행 제거\n",
    "    df = df.dropna()\n",
    "    # 산업별 그룹화 및 z-score 계산\n",
    "    grouped = df.groupby('Industry')\n",
    "    z_scores = grouped['PER'].transform(lambda x: -(x - x.mean()) / x.std() if x.std() != 0 else 0)\n",
    "    return z_scores\n",
    "\n",
    "# 대분류 산업별 z-score\n",
    "per_zscore_large = per_df.copy()\n",
    "print(per_zscore_large.shape)\n",
    "for date in per_zscore_large.index:\n",
    "    per_zscore_large.loc[date] = industry_zscore(per_df.loc[date], industry_large_df.loc[date])\n",
    "    # 디버깅 출력\n",
    "    # debug_print(f\"[Large Industry] Date: {date}\", per_zscore_large.loc[[date]])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "per_zscore_large.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'PER_zscore_large', 'PER_zscore_large') for symbol, symbol_name in per_zscore_large.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore_large.to_csv('factor_high_pe_ratio_large_industry.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio_large_industry.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 중분류 산업별 z-score\n",
    "per_zscore_medium = per_df.copy()\n",
    "for date in per_zscore_medium.index:\n",
    "    per_zscore_medium.loc[date] = industry_zscore(per_df.loc[date], industry_medium_df.loc[date])\n",
    "    # 디버깅 출력\n",
    "    # debug_print(f\"[Medium Industry] Date: {date}\", per_zscore_medium.loc[[date]])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "per_zscore_medium.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'PER_large', 'PER_large') for symbol, symbol_name in per_zscore_medium.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "# 팩터 값 저장\n",
    "per_zscore_medium.to_csv('factor_high_pe_ratio_medium_industry.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio_medium_industry.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore.to_csv('factor_high_pe_ratio.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b1ba1e-178a-436f-b550-6a1fa21dd198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_hml.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 2: HML (Kang, 2013) =====\n",
    "# Book-to-Market Ratio 계산 (BPS / 주가)\n",
    "\n",
    "# 'BPS(자사주차감)(원)' 데이터 추출\n",
    "bps_mask = monthly_merged_df.columns.get_level_values('item Name') == 'BPS(자사주차감)(원)'\n",
    "bps_df = monthly_merged_df.loc[:, bps_mask]\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = monthly_merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = monthly_merged_df.loc[:, price_mask]\n",
    "\n",
    "# 컬럼 레벨 중 'item'과 'item Name'을 제거하여 컬럼 정렬\n",
    "bps_df.columns = bps_df.columns.droplevel(['item', 'item Name'])\n",
    "price_df.columns = price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "bps_df, price_df = bps_df.align(price_df, join='inner', axis=0)\n",
    "bps_df, price_df = bps_df.align(price_df, join='inner', axis=1)\n",
    "\n",
    "# 계산 전에 데이터 타입 변환\n",
    "bps_df = bps_df.apply(pd.to_numeric, errors='coerce')\n",
    "price_df = price_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Book-to-Market Ratio 계산\n",
    "bm_ratio_df = bps_df / price_df\n",
    "\n",
    "# 결측치 처리\n",
    "bm_ratio_df = bm_ratio_df.replace([np.inf, -np.inf], np.nan)\n",
    "bm_ratio_df = bm_ratio_df.fillna(method='ffill')\n",
    "\n",
    "# 멀티레벨 컬럼 구조 재설정\n",
    "bm_ratio_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'BM Ratio', 'BM Ratio') for symbol, symbol_name in bm_ratio_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "bm_ratio_df.to_csv('factor_hml.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_hml.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e451f8b-6323-46bf-aa1c-ae95be7984ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_momentum.csv', 'factor_momentum_zscore.csv', 'factor_momentum_large_industry.csv', 'factor_momentum_medium_industry.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 5: Momentum 전략 =====\n",
    "# 지난 12-1개월 수익률 계산 (직전 1개월은 제외)\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = monthly_merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = monthly_merged_df.loc[:, price_mask]\n",
    "price_df.columns = price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 타입 변환\n",
    "price_df = price_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "price_df = price_df.sort_index()\n",
    "\n",
    "# 결측치 처리\n",
    "price_df = price_df.fillna(method='ffill')\n",
    "\n",
    "# 12개월 전 가격과 1개월 전 가격 추출\n",
    "price_12m_ago = price_df.shift(12)\n",
    "price_1m_ago = price_df.shift(1)\n",
    "\n",
    "# 모멘텀 계산\n",
    "momentum_df = (price_1m_ago - price_12m_ago) / price_12m_ago\n",
    "\n",
    "# 결측치 처리\n",
    "momentum_df = momentum_df.replace([np.inf, -np.inf], np.nan)\n",
    "momentum_df = momentum_df.fillna(method='ffill')\n",
    "\n",
    "# 전체 종목에 대해 z-score 계산\n",
    "momentum_zscore = momentum_df.apply(lambda x: (x - x.mean()) / x.std(), axis=1)\n",
    "\n",
    "# 산업 분류 데이터 불러오기 (이미 불러온 industry_df 사용)\n",
    "# '한국표준산업분류11차(대분류)', '한국표준산업분류11차(중분류)' 데이터 추출\n",
    "industry_large_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(대분류)'\n",
    "industry_medium_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(중분류)'\n",
    "\n",
    "industry_large_df = industry_df.loc[:, industry_large_mask]\n",
    "industry_large_df.columns = industry_large_df.columns.droplevel(['item', 'item Name'])\n",
    "industry_medium_df = industry_df.loc[:, industry_medium_mask]\n",
    "industry_medium_df.columns = industry_medium_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 산업별로 z-score 계산\n",
    "def industry_zscore(per_series, industry_series):\n",
    "    df = pd.DataFrame({'PER': per_series, 'Industry': industry_series})\n",
    "    # NaN 값이 있는 행 제거\n",
    "    df = df.dropna()\n",
    "    # 산업별 그룹화 및 z-score 계산\n",
    "    grouped = df.groupby('Industry')\n",
    "    z_scores = grouped['PER'].transform(lambda x: -(x - x.mean()) / x.std() if x.std() != 0 else 0)\n",
    "    return z_scores\n",
    "\n",
    "\n",
    "# 대분류 산업별 z-score\n",
    "momentum_zscore_large = momentum_df.copy()\n",
    "for date in momentum_zscore_large.index:\n",
    "    momentum_zscore_large.loc[date] = industry_zscore(momentum_df.loc[date], industry_large_df.loc[date])\n",
    "\n",
    "# 중분류 산업별 z-score\n",
    "momentum_zscore_medium = momentum_df.copy()\n",
    "for date in momentum_zscore_medium.index:\n",
    "    momentum_zscore_medium.loc[date] = industry_zscore(momentum_df.loc[date], industry_medium_df.loc[date])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "# 원래의 컬럼 정보를 사용하여 멀티인덱스 생성\n",
    "momentum_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum', 'Momentum') for symbol, symbol_name in momentum_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_zscore', 'Momentum_zscore') for symbol, symbol_name in momentum_zscore.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore_large.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_large', 'Momentum_large') for symbol, symbol_name in momentum_zscore_large.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore_medium.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_medium', 'Momentum_medium') for symbol, symbol_name in momentum_zscore_medium.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "momentum_df.to_csv('factor_momentum.csv', encoding='utf-8-sig')\n",
    "momentum_zscore.to_csv('factor_momentum_zscore.csv', encoding='utf-8-sig')\n",
    "momentum_zscore_large.to_csv('factor_momentum_large_industry.csv', encoding='utf-8-sig')\n",
    "momentum_zscore_medium.to_csv('factor_momentum_medium_industry.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(\"'factor_momentum.csv', 'factor_momentum_zscore.csv', 'factor_momentum_large_industry.csv', 'factor_momentum_medium_industry.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f0bebdf-f11c-4477-9e8a-e2385681d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_retained_earnings.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 6: Retained Earnings and Market-to-Book =====\n",
    "# 이익잉여금(원) / 시가총액 계산\n",
    "\n",
    "# '이익잉여금(원)' 데이터 추출\n",
    "retained_earnings_mask = monthly_merged_df.columns.get_level_values('item Name') == '이익잉여금(원)'\n",
    "retained_earnings_df = monthly_merged_df.loc[:, retained_earnings_mask]\n",
    "\n",
    "# '시가총액 (평균)(원)' 데이터 추출\n",
    "market_cap_mask = monthly_merged_df.columns.get_level_values('item Name') == '시가총액 (평균)(원)'\n",
    "market_cap_df = monthly_merged_df.loc[:, market_cap_mask]\n",
    "\n",
    "# 컬럼 레벨 중 'item'과 'item Name'을 제거하여 컬럼 정렬\n",
    "retained_earnings_df.columns = retained_earnings_df.columns.droplevel(['item', 'item Name'])\n",
    "market_cap_df.columns = market_cap_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "retained_earnings_df, market_cap_df = retained_earnings_df.align(market_cap_df, join='inner', axis=0)\n",
    "retained_earnings_df, market_cap_df = retained_earnings_df.align(market_cap_df, join='inner', axis=1)\n",
    "\n",
    "# 데이터 타입 변환\n",
    "retained_earnings_df = retained_earnings_df.apply(pd.to_numeric, errors='coerce')\n",
    "market_cap_df = market_cap_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 이익잉여금 / 시가총액 계산\n",
    "re_mc_ratio_df = retained_earnings_df / market_cap_df\n",
    "\n",
    "# 결측치 처리\n",
    "re_mc_ratio_df = re_mc_ratio_df.replace([np.inf, -np.inf], np.nan)\n",
    "re_mc_ratio_df = re_mc_ratio_df.fillna(method='ffill')\n",
    "\n",
    "# 멀티레벨 컬럼 구조 재설정\n",
    "re_mc_ratio_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'RE/MC Ratio', 'RE/MC Ratio') for symbol, symbol_name in re_mc_ratio_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "re_mc_ratio_df.to_csv('factor_retained_earnings.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_retained_earnings.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ec265dd-fffe-4dda-a358-760292967329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 종목 수: 2053\n",
      "필터링된 종목 수: 2052\n",
      "일별 가격 데이터 타입 확인:\n",
      "[dtype('int64') dtype('float64')]\n",
      "일별 수익률 계산 완료. 종목 수: 2053\n",
      "시장 수익률 데이터 기간: 2007-10-21 00:00:00 ~ 2024-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "베타 계산 중: 100%|██████████████████████████████████████████████████████████████████| 206/206 [09:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_betting_against_beta.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 10: Betting Against Beta =====\n",
    "# 베타를 직접 계산하여 역수를 팩터 값으로 사용\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 전처리된 월별 데이터에서 종목 리스트와 기간 추출\n",
    "symbols = monthly_merged_df.columns.get_level_values('Symbol').unique()\n",
    "dates = monthly_merged_df.index.unique()\n",
    "\n",
    "# 각 종목별로 시작 날짜 추출\n",
    "symbol_start_dates = {}\n",
    "for symbol in symbols:\n",
    "    # 해당 종목의 컬럼 선택\n",
    "    symbol_cols = monthly_merged_df.loc[:, monthly_merged_df.columns.get_level_values('Symbol') == symbol]\n",
    "    # 해당 종목의 데이터가 있는 날짜 추출\n",
    "    symbol_data = symbol_cols.dropna(how='all')\n",
    "    # 데이터가 있는 경우\n",
    "    if not symbol_data.empty:\n",
    "        start_date = symbol_data.index.min()\n",
    "        # 시작 날짜에서 30일을 뺌\n",
    "        adjusted_start_date = start_date - pd.Timedelta(days=30)\n",
    "        # daily_df의 시작 날짜와 비교하여 실제 시작 날짜 결정\n",
    "        symbol_start_dates[symbol] = adjusted_start_date\n",
    "    else:\n",
    "        # 데이터가 없는 경우 최소 날짜 설정\n",
    "        symbol_start_dates[symbol] = pd.to_datetime('2000-01-01')  # 필요에 따라 최소 날짜 설정\n",
    "\n",
    "print(f\"전처리된 종목 수: {len(symbols)}\")\n",
    "\n",
    "# 2. 일별 데이터 로드 (data/KSIF_1.csv 파일)\n",
    "file_path = 'data/KSIF_1.csv'\n",
    "\n",
    "try:\n",
    "    daily_df = pd.read_csv(\n",
    "        file_path,\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='cp949',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    daily_df = pd.read_csv(\n",
    "        file_path,\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='euc-kr',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"파일 {file_path}를 로드하는 중 에러 발생: {e}\")\n",
    "    raise e  # 에러 발생 시 종료\n",
    "\n",
    "# 멀티인덱스 컬럼 이름 지정\n",
    "daily_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "daily_df.index.name = 'Date'\n",
    "\n",
    "# 'Kind', 'Frequency' 레벨 제거\n",
    "daily_df.columns = daily_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "# 필요한 종목(Symbol)만 선택\n",
    "symbol_mask = daily_df.columns.get_level_values('Symbol').isin(symbols)\n",
    "daily_df = daily_df.loc[:, symbol_mask]\n",
    "\n",
    "print(f\"필터링된 종목 수: {len(daily_df.columns.get_level_values('Symbol').unique())}\")\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = daily_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "daily_price_df = daily_df.loc[:, price_mask]\n",
    "daily_price_df.columns = daily_price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "daily_price_df = (\n",
    "    daily_price_df\n",
    "    .astype(str)  # 모든 데이터를 문자열로 변환\n",
    "    .replace(',', '', regex=True)  # 쉼표 제거\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)  # 비정상적인 값들을 NaN으로 변환\n",
    "    .apply(pd.to_numeric, errors='coerce')  # 숫자로 변환 (변환 불가 시 NaN)\n",
    ")\n",
    "\n",
    "# 데이터 타입 확인\n",
    "print(\"일별 가격 데이터 타입 확인:\")\n",
    "print(daily_price_df.dtypes.unique())\n",
    "\n",
    "# 종목별 일별 수익률 계산\n",
    "daily_returns_dict = {}\n",
    "for symbol in symbols:\n",
    "    if symbol in daily_price_df.columns:\n",
    "        symbol_price = daily_price_df[symbol]\n",
    "        if not symbol_price.empty:\n",
    "            # 해당 종목의 시작 날짜 계산\n",
    "            start_date = symbol_start_dates[symbol]\n",
    "            # 시작 날짜부터 데이터 선택\n",
    "            symbol_price = symbol_price.loc[start_date:]\n",
    "            # 수익률 계산\n",
    "            symbol_returns = symbol_price.pct_change().dropna()\n",
    "            daily_returns_dict[symbol] = symbol_returns\n",
    "        else:\n",
    "            # 해당 종목의 데이터가 없는 경우\n",
    "            daily_returns_dict[symbol] = pd.Series(dtype=float)\n",
    "    else:\n",
    "        daily_returns_dict[symbol] = pd.Series(dtype=float)\n",
    "\n",
    "print(f\"일별 수익률 계산 완료. 종목 수: {len(daily_returns_dict)}\")\n",
    "\n",
    "# 시장 수익률 계산 (종가지수(포인트) 기반)\n",
    "try:\n",
    "    market_df = pd.read_csv(\n",
    "        'data/kor_market.csv',\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='cp949',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    market_df = pd.read_csv(\n",
    "        'data/kor_market.csv',\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='euc-kr',\n",
    "        parse_dates=True\n",
    "    )\n",
    "\n",
    "# 멀티인덱스 컬럼 이름 지정\n",
    "market_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "market_df.index.name = 'Date'\n",
    "\n",
    "# 'Kind', 'Frequency' 레벨 제거\n",
    "market_df.columns = market_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "# '종가지수(포인트)' 데이터 추출\n",
    "index_mask = market_df.columns.get_level_values('item Name') == '종가지수(포인트)'\n",
    "index_df = market_df.loc[:, index_mask]\n",
    "\n",
    "# '코스피'와 '코스닥' 지수만 선택\n",
    "symbol_names = index_df.columns.get_level_values('Symbol Name')\n",
    "kospi_kosdaq_mask = (symbol_names == '코스피') | (symbol_names == '코스닥')\n",
    "kospi_kosdaq_indices = index_df.loc[:, kospi_kosdaq_mask]\n",
    "kospi_kosdaq_indices.columns = kospi_kosdaq_indices.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "kospi_kosdaq_indices = (\n",
    "    kospi_kosdaq_indices\n",
    "    .astype(str)\n",
    "    .replace(',', '', regex=True)\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)\n",
    "    .apply(pd.to_numeric, errors='coerce')\n",
    ")\n",
    "\n",
    "# 코스피와 코스닥 지수의 일별 수익률 계산\n",
    "market_returns = kospi_kosdaq_indices.mean(axis=1).pct_change().dropna()\n",
    "\n",
    "# 시장 수익률 데이터 기간 확인\n",
    "print(f\"시장 수익률 데이터 기간: {market_returns.index.min()} ~ {market_returns.index.max()}\")\n",
    "\n",
    "# 3. 베타 계산 함수 정의 및 계산\n",
    "def calculate_beta(stock_returns, market_returns, window=365):\n",
    "    # 결측치 제거\n",
    "    combined = pd.concat([stock_returns, market_returns], axis=1).dropna()\n",
    "    if len(combined) < 30:\n",
    "        return np.nan\n",
    "    else:\n",
    "        stock_ret = combined.iloc[:, 0]\n",
    "        market_ret = combined.iloc[:, 1]\n",
    "        cov = stock_ret.cov(market_ret)\n",
    "        var = market_ret.var()\n",
    "        beta = cov / var if var != 0 else np.nan\n",
    "        return beta\n",
    "\n",
    "# 베타 값을 저장할 데이터프레임 생성\n",
    "beta_df = pd.DataFrame(index=dates, columns=symbols)\n",
    "\n",
    "for date in tqdm(dates, desc='베타 계산 중'):\n",
    "    for symbol in symbols:\n",
    "        # 해당 종목의 일별 수익률 시리즈\n",
    "        stock_returns = daily_returns_dict[symbol]\n",
    "        # 해당 날짜까지의 데이터 사용\n",
    "        stock_returns = stock_returns[stock_returns.index <= date]\n",
    "        market_returns_up_to_date = market_returns[market_returns.index <= date]\n",
    "        # 최근 window 기간의 데이터 추출\n",
    "        stock_returns = stock_returns.iloc[-365:]\n",
    "        market_returns_up_to_date = market_returns_up_to_date.iloc[-365:]\n",
    "        # 베타 계산\n",
    "        beta = calculate_beta(stock_returns, market_returns_up_to_date)\n",
    "        beta_df.at[date, symbol] = beta\n",
    "\n",
    "# 베타의 역수를 팩터 값으로 사용\n",
    "inv_beta_df = (1 / beta_df.astype(float)).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "inv_beta_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, monthly_merged_df.columns.get_level_values('Symbol Name')[monthly_merged_df.columns.get_level_values('Symbol') == symbol][0], 'Inverse Beta', 'Inverse Beta') for symbol in inv_beta_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "inv_beta_df.index.name = 'Date'\n",
    "\n",
    "# 팩터 값 저장\n",
    "inv_beta_df.to_csv('factor_betting_against_beta.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(\"'factor_betting_against_beta.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96caf0fc-2d5c-445e-be7d-6d5bee346662",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: factor_high_pe_ratio.csv\n",
      "  Loaded successfully. Shape: (206, 2067)\n",
      "  Max Missing Date: 2008-01-31 00:00:00\n",
      "  Max Missing Count: 1544\n",
      "  Total Columns: 2067\n",
      "  Max Missing Ratio (%): 74.70%\n",
      "Processing file: factor_high_pe_ratio_large_industry.csv\n",
      "  Error processing file factor_high_pe_ratio_large_industry.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_high_pe_ratio_medium_industry.csv\n",
      "  Error processing file factor_high_pe_ratio_medium_industry.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_hml.csv\n",
      "  Error processing file factor_hml.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_momentum.csv\n",
      "  Error processing file factor_momentum.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_retained_earnings.csv\n",
      "  Error processing file factor_retained_earnings.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_betting_against_beta.csv\n",
      "  Loaded successfully. Shape: (426005, 5)\n",
      "  Max Missing Date: 2008-01-31 00:00:00\n",
      "  Max Missing Count: 1\n",
      "  Total Columns: 5\n",
      "  Max Missing Ratio (%): 20.00%\n",
      "\n",
      "===== Missing Data Summary =====\n",
      "                       Factor File Max Missing Date  Max Missing Count  \\\n",
      "0         factor_high_pe_ratio.csv       2008-01-31               1544   \n",
      "1  factor_betting_against_beta.csv       2008-01-31                  1   \n",
      "\n",
      "   Total Columns  Max Missing Ratio (%)  \n",
      "0           2067              74.697629  \n",
      "1              5              20.000000  \n",
      "\n",
      "결측치 분석 결과가 'factor_missing_data_summary.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "#계산한 팩터값에 결측치 확인\n",
    "import pandas as pd\n",
    "\n",
    "# ===== 팩터 값 CSV 확인 및 결측치 분석 =====\n",
    "\n",
    "# 저장된 팩터 값 CSV 파일 목록\n",
    "factor_files = [\n",
    "    'factor_high_pe_ratio.csv',\n",
    "    'factor_high_pe_ratio_large_industry.csv',\n",
    "    'factor_high_pe_ratio_medium_industry.csv',\n",
    "    'factor_hml.csv',\n",
    "    'factor_momentum.csv',\n",
    "    'factor_retained_earnings.csv',\n",
    "    'factor_betting_against_beta.csv'\n",
    "]\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "missing_data_summary = []\n",
    "\n",
    "for file in factor_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    try:\n",
    "        # CSV 파일 로드\n",
    "        factor_df = pd.read_csv(file, \n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "        )\n",
    "\n",
    "        # 멀티인덱스 설정\n",
    "        factor_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "        factor_df.index.name = 'Date'\n",
    "        \n",
    "        print(f\"  Loaded successfully. Shape: {factor_df.shape}\")\n",
    "        \n",
    "        # 2008년 이후 데이터만 필터링\n",
    "        factor_df = factor_df.loc[factor_df.index >= '2008-01-01']\n",
    "        \n",
    "        # 결측치 분석\n",
    "        missing_summary = factor_df.isna().sum(axis=1)  # 각 날짜별 결측치 수\n",
    "        total_columns = factor_df.shape[1]  # 전체 컬럼 수\n",
    "        \n",
    "        # 가장 결측치가 많은 날짜와 해당 날짜의 결측치 비율\n",
    "        max_missing_date = missing_summary.idxmax()\n",
    "        max_missing_count = missing_summary.max()\n",
    "        max_missing_ratio = (max_missing_count / total_columns) * 100  # 결측치 비율\n",
    "        \n",
    "        # 결측치 요약 추가\n",
    "        missing_data_summary.append({\n",
    "            'Factor File': file,\n",
    "            'Max Missing Date': max_missing_date,\n",
    "            'Max Missing Count': max_missing_count,\n",
    "            'Total Columns': total_columns,\n",
    "            'Max Missing Ratio (%)': max_missing_ratio\n",
    "        })\n",
    "        \n",
    "        print(f\"  Max Missing Date: {max_missing_date}\")\n",
    "        print(f\"  Max Missing Count: {max_missing_count}\")\n",
    "        print(f\"  Total Columns: {total_columns}\")\n",
    "        print(f\"  Max Missing Ratio (%): {max_missing_ratio:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing file {file}: {e}\")\n",
    "\n",
    "# 결측치 분석 결과 DataFrame 생성\n",
    "missing_summary_df = pd.DataFrame(missing_data_summary)\n",
    "\n",
    "# 결측치 분석 결과 출력\n",
    "print(\"\\n===== Missing Data Summary =====\")\n",
    "print(missing_summary_df)\n",
    "\n",
    "# 결측치 분석 결과 저장\n",
    "missing_summary_df.to_csv('factor_missing_data_summary.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n결측치 분석 결과가 'factor_missing_data_summary.csv' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea0115-500f-4531-8c1c-bca6231d31c1",
   "metadata": {},
   "source": [
    "# 백테스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c477390-2308-4cae-b45a-ac661a5f9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(factor_csv, merged_df, rebalancing_period=1, long_only=True, threshold=0.2, cutoff=0.0, reversal=False, weighting_method='equal', start_date='2008-10-31'):\n",
    "    \"\"\"\n",
    "    백테스팅 함수를 구현합니다.\n",
    "\n",
    "    Parameters:\n",
    "    - factor_csv (str): 팩터값 CSV 파일의 경로\n",
    "    - merged_df (pd.DataFrame): 수익률 데이터가 포함된 데이터프레임\n",
    "    - rebalancing_period (int): 리밸런싱 주기 (1, 3, 6, 12 중 하나)\n",
    "    - long_only (bool): 롱 온리 전략 여부\n",
    "    - threshold (float): 포지션을 취할 상위/하위 퍼센트 (0 < threshold <= 1)\n",
    "    - cutoff (float): 포지션을 취할 시작 퍼센트 (0 <= cutoff < threshold)\n",
    "    - reversal (bool): 전략을 반대로 적용할지 여부\n",
    "    - weighting_method (str): 'equal' 또는 'value' 중 하나로, 동일가중 또는 가치가중을 결정\n",
    "    - start_date (str): 백테스트 시작 날짜 (예: '2008-10-31')\n",
    "\n",
    "    Returns:\n",
    "    - results_df (pd.DataFrame): 월별 포트폴리오 변동과 포지션을 포함한 데이터프레임\n",
    "    \"\"\"\n",
    "    # 팩터 데이터 불러오기\n",
    "    factor_df = pd.read_csv(factor_csv, index_col=0, header=[0, 1, 2, 3], parse_dates=True)\n",
    "    factor_df.index.name = 'Date'\n",
    "    factor_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "\n",
    "    # 팩터 데이터에서 'item'과 'item Name' 레벨을 제거하여 심볼과 종목명만 남김\n",
    "    factor_df.columns = factor_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "    # 팩터 데이터 날짜 필터링 (백테스트 시작일 이후 데이터만 사용)\n",
    "    factor_df = factor_df[factor_df.index >= start_date]\n",
    "\n",
    "    # 수익률 데이터 추출 ('1개월 수익률(계산)')\n",
    "    returns_mask = merged_df.columns.get_level_values('item Name') == '1개월 수익률(계산)'\n",
    "    returns_df = merged_df.loc[:, returns_mask]\n",
    "    returns_df.columns = returns_df.columns.droplevel(['item', 'item Name'])\n",
    "    returns_df.columns.names = ['Symbol', 'Symbol Name']\n",
    "\n",
    "    # 수익률 데이터 날짜 필터링 (백테스트 시작일 이후 데이터만 사용)\n",
    "    returns_df = returns_df[returns_df.index >= start_date]\n",
    "\n",
    "    # 월말 기준으로 데이터 리샘플링\n",
    "    factor_df = factor_df.resample('M').last()\n",
    "    returns_df = returns_df.resample('M').last()\n",
    "\n",
    "    # 팩터 데이터와 수익률 데이터의 공통 심볼(Symbol)만 사용\n",
    "    common_symbols = factor_df.columns.intersection(returns_df.columns)\n",
    "    factor_df = factor_df[common_symbols]\n",
    "    returns_df = returns_df[common_symbols]\n",
    "\n",
    "    # 팩터 데이터와 수익률 데이터를 날짜와 심볼 기준으로 정렬\n",
    "    factor_df = factor_df.sort_index().sort_index(axis=1)\n",
    "    returns_df = returns_df.sort_index().sort_index(axis=1)\n",
    "\n",
    "    # 리밸런싱 날짜 설정\n",
    "    rebalancing_dates = factor_df.index[::rebalancing_period]\n",
    "\n",
    "    # 포트폴리오 초기화\n",
    "    portfolio = pd.DataFrame(index=returns_df.index, columns=['Portfolio Value', 'Monthly Return', 'Transaction Cost'])\n",
    "    portfolio['Portfolio Value'] = 1.0  # 초기 투자금 1로 설정\n",
    "    portfolio['Transaction Cost'] = 0.0  # 초기 거래 비용 0으로 설정\n",
    "\n",
    "    # 각 날짜의 포지션을 저장할 딕셔너리\n",
    "    positions = {}\n",
    "\n",
    "    # 거래 비용 비율 설정 (0.1%)\n",
    "    transaction_cost_rate = 0.001\n",
    "\n",
    "    # 백테스트 진행\n",
    "    for i, date in enumerate(returns_df.index):\n",
    "        # 이전 날짜 설정\n",
    "        if i > 0:\n",
    "            prev_date = returns_df.index[i - 1]\n",
    "        else:\n",
    "            prev_date = None\n",
    "\n",
    "        # 리밸런싱 시점인지 확인\n",
    "        if date in rebalancing_dates:\n",
    "            # 리밸런싱 시점에서는 새로운 포지션을 설정\n",
    "            factor = factor_df.loc[date].dropna()\n",
    "\n",
    "            # 종목 수 계산\n",
    "            num_assets = len(factor)\n",
    "            num_selected = int(num_assets * threshold)\n",
    "            num_cutoff = int(num_assets * cutoff)\n",
    "\n",
    "            if long_only:\n",
    "                # 롱 온리 전략\n",
    "                if reversal:\n",
    "                    # 하위 cutoff% ~ threshold% 종목을 선택\n",
    "                    selected_symbols = factor.nsmallest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                else:\n",
    "                    # 상위 cutoff% ~ threshold% 종목을 선택\n",
    "                    selected_symbols = factor.nlargest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "\n",
    "                # 가중치 계산\n",
    "                if weighting_method == 'equal':\n",
    "                    weights = pd.Series(1.0 / len(selected_symbols), index=selected_symbols)\n",
    "                elif weighting_method == 'value':\n",
    "                    weights = factor[selected_symbols] / factor[selected_symbols].abs().sum()\n",
    "                else:\n",
    "                    raise ValueError(\"weighting_method must be 'equal' or 'value'\")\n",
    "            else:\n",
    "                # 롱숏 전략\n",
    "                if reversal:\n",
    "                    # 하위 cutoff% ~ threshold% 종목을 롱, 상위 cutoff% ~ threshold% 종목을 숏\n",
    "                    long_symbols = factor.nsmallest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                    short_symbols = factor.nlargest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                else:\n",
    "                    # 상위 cutoff% ~ threshold% 종목을 롱, 하위 cutoff% ~ threshold% 종목을 숏\n",
    "                    long_symbols = factor.nlargest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                    short_symbols = factor.nsmallest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "\n",
    "                # 가중치 계산\n",
    "                if weighting_method == 'equal':\n",
    "                    long_weights = pd.Series(1.0 / len(long_symbols), index=long_symbols)\n",
    "                    short_weights = pd.Series(-1.0 / len(short_symbols), index=short_symbols)\n",
    "                elif weighting_method == 'value':\n",
    "                    long_weights = factor[long_symbols] / factor[long_symbols].abs().sum()\n",
    "                    short_weights = -factor[short_symbols] / factor[short_symbols].abs().sum()\n",
    "                else:\n",
    "                    raise ValueError(\"weighting_method must be 'equal' or 'value'\")\n",
    "\n",
    "                # 롱과 숏 포지션 합치기\n",
    "                weights = pd.concat([long_weights, short_weights])\n",
    "\n",
    "            # 거래 비용 계산 (포지션 변경에 따른)\n",
    "            if prev_date is not None and prev_date in positions:\n",
    "                prev_weights = positions[prev_date]\n",
    "                # 포지션 변경량 계산\n",
    "                weight_diff = weights.reindex(prev_weights.index).fillna(0) - prev_weights.reindex(weights.index).fillna(0)\n",
    "            else:\n",
    "                # 처음 포지션을 잡을 때는 전체 포지션이 신규 진입\n",
    "                weight_diff = weights\n",
    "\n",
    "            # 거래 비용 계산\n",
    "            transaction_cost = transaction_cost_rate * weight_diff.abs().sum()\n",
    "\n",
    "            # 현재 포지션 저장\n",
    "            positions[date] = weights\n",
    "\n",
    "        else:\n",
    "            # 리밸런싱 시점이 아니면 이전 포지션을 그대로 유지\n",
    "            if prev_date in positions:\n",
    "                positions[date] = positions[prev_date]\n",
    "                transaction_cost = 0.0  # 거래 비용 없음\n",
    "            else:\n",
    "                # 이전 포지션이 없으면 포지션 없음\n",
    "                positions[date] = pd.Series()\n",
    "                transaction_cost = 0.0  # 거래 비용 없음\n",
    "\n",
    "        # 수익률 계산 (선행 편향 방지를 위해 이전 포지션 사용)\n",
    "        if prev_date in positions and not positions[prev_date].empty:\n",
    "            weights = positions[prev_date]\n",
    "\n",
    "            # 해당 월의 수익률 계산\n",
    "            returns = returns_df.loc[date]\n",
    "            # 포지션에 해당하는 종목의 수익률만 선택\n",
    "            aligned_returns = returns.reindex(weights.index).fillna(0)\n",
    "            # 포트폴리오 수익률 계산 (벡터화 연산)\n",
    "            portfolio_return = (weights * aligned_returns).sum()\n",
    "        else:\n",
    "            # 포지션이 없으면 수익률 0\n",
    "            portfolio_return = 0.0\n",
    "\n",
    "        # 거래 비용을 수익률에 반영\n",
    "        net_return = portfolio_return - transaction_cost\n",
    "\n",
    "        # 포트폴리오 가치 업데이트\n",
    "        if i > 0:\n",
    "            portfolio.loc[date, 'Monthly Return'] = net_return\n",
    "            portfolio.loc[date, 'Transaction Cost'] = transaction_cost\n",
    "            portfolio.loc[date, 'Portfolio Value'] = portfolio.iloc[i - 1]['Portfolio Value'] * (1 + net_return)\n",
    "        else:\n",
    "            # 첫 번째 기간은 수익률 계산하지 않음\n",
    "            portfolio.loc[date, 'Monthly Return'] = 0.0\n",
    "            portfolio.loc[date, 'Transaction Cost'] = 0.0\n",
    "\n",
    "    # 포지션 정보를 데이터프레임으로 변환\n",
    "    positions_df = pd.DataFrame.from_dict(positions, orient='index')\n",
    "    positions_df.index.name = 'Date'\n",
    "\n",
    "    # 결과 합치기\n",
    "    results_df = portfolio.join(positions_df, how='left')\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9279f865-95d8-43a9-a8da-d6e60a76eb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [16:49<00:00, 100.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# 'factor'라는 글자가 포함된 모든 CSV 파일 목록을 가져옵니다.\n",
    "factor_files = glob.glob('*factor*.csv')\n",
    "\n",
    "# 백테스팅에 사용할 파라미터 그리드 설정\n",
    "rebalancing_periods = [1, 3, 6]        # 리밸런싱 주기\n",
    "thresholds = [0.1, 0.2, 0.3]           # 상위/하위 퍼센트\n",
    "cutoffs = [0, 0.05, 0.1]               # 시작 퍼센트\n",
    "weighting_methods = ['equal', 'value'] # 가중치 방법\n",
    "start_date = '2008-10-31'              # 백테스트 시작일\n",
    "\n",
    "# 모든 팩터 파일에 대해 백테스팅 수행\n",
    "for factor_csv in tqdm(factor_files):\n",
    "    # print(f\"백테스팅 시작: {factor_csv}\")\n",
    "    \n",
    "    # 팩터 파일명에서 확장자를 제거하여 폴더명을 생성합니다.\n",
    "    factor_name = os.path.splitext(factor_csv)[0]\n",
    "    \n",
    "    # 팩터별 폴더 생성 (이미 존재하면 생략)\n",
    "    if not os.path.exists(factor_name):\n",
    "        os.makedirs(factor_name)\n",
    "    \n",
    "    # 모든 파라미터 조합에 대해 백테스팅 수행\n",
    "    for rebalancing_period, threshold, cutoff, weighting_method in itertools.product(\n",
    "        rebalancing_periods, thresholds, cutoffs, weighting_methods):\n",
    "        \n",
    "        # cutoff는 threshold보다 작아야 합니다.\n",
    "        if cutoff >= threshold:\n",
    "            continue\n",
    "        \n",
    "        # 백테스팅 함수 호출\n",
    "        try:\n",
    "            results_df = backtest_strategy(\n",
    "                factor_csv=factor_csv,\n",
    "                merged_df=monthly_merged_df,  # 수익률 데이터가 포함된 데이터프레임 (사전에 정의되어 있어야 합니다)\n",
    "                rebalancing_period=rebalancing_period,\n",
    "                long_only=True,  # Long-only 전략\n",
    "                threshold=threshold,\n",
    "                cutoff=cutoff,\n",
    "                reversal=False,  # 기본값\n",
    "                weighting_method=weighting_method,\n",
    "                start_date=start_date\n",
    "            )\n",
    "            \n",
    "            # 파일명 생성 (스네이크 케이스로 파라미터 명명)\n",
    "            file_name = f\"rebalancing_{rebalancing_period}_threshold_{threshold}_cutoff_{cutoff}_weighting_{weighting_method}\"\n",
    "            file_name = file_name.replace('.', '_')  # 파일명에 있는 점을 언더스코어로 변경\n",
    "            \n",
    "            # 결과 저장 경로 생성\n",
    "            save_path = os.path.join(factor_name, file_name)\n",
    "            \n",
    "            # 백테스팅 결과를 CSV 파일로 저장\n",
    "            results_df.to_csv(save_path+'.csv', encoding='utf-8-sig')\n",
    "            \n",
    "            # print(f\"완료: {factor_csv}, 리밸런싱 주기: {rebalancing_period}, threshold: {threshold}, cutoff: {cutoff}, 가중치 방법: {weighting_method}\")\n",
    "            # print(f\"저장 위치: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"에러 발생: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a04c59-303c-4701-80b2-8ada777d821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "각 팩터별로 Sharpe Ratio가 가장 높은 파일 목록:\n",
      "factor_betting_against_beta\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
      "factor_high_pe_ratio\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
      "factor_high_pe_ratio_large_industry\\rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_high_pe_ratio_medium_industry\\rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal.csv\n",
      "factor_hml\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum_large_industry\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum_medium_industry\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
      "factor_momentum_zscore\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_retained_earnings\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 시장 수익률 계산 (종가지수(포인트) 기반)\n",
    "def get_risk_free_rate():\n",
    "    \"\"\"\n",
    "    위험 무시 수익률(rf)을 계산하는 함수입니다.\n",
    "    코스피와 코스닥 지수의 일별 수익률을 평균하여 사용합니다.\n",
    "    월별 수익률로 변환하여 반환합니다.\n",
    "    \n",
    "    Returns:\n",
    "    - rf_monthly_returns (pd.Series): 월별 위험 무시 수익률 시리즈\n",
    "    \"\"\"\n",
    "    # 시장 데이터 로드\n",
    "    try:\n",
    "        market_df = pd.read_csv(\n",
    "            'data/kor_market.csv',\n",
    "            skiprows=8,\n",
    "            header=[0, 1, 2, 3, 4, 5],\n",
    "            index_col=0,\n",
    "            encoding='cp949',\n",
    "            parse_dates=True\n",
    "        )\n",
    "    except UnicodeDecodeError:\n",
    "        market_df = pd.read_csv(\n",
    "            'data/kor_market.csv',\n",
    "            skiprows=8,\n",
    "            header=[0, 1, 2, 3, 4, 5],\n",
    "            index_col=0,\n",
    "            encoding='euc-kr',\n",
    "            parse_dates=True\n",
    "        )\n",
    "\n",
    "    # 멀티인덱스 컬럼 이름 지정\n",
    "    market_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "    market_df.index.name = 'Date'\n",
    "\n",
    "    # 'Kind', 'Frequency' 레벨 제거\n",
    "    market_df.columns = market_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "    # '종가지수(포인트)' 데이터 추출\n",
    "    index_mask = market_df.columns.get_level_values('item Name') == '종가지수(포인트)'\n",
    "    index_df = market_df.loc[:, index_mask]\n",
    "\n",
    "    # '코스피'와 '코스닥' 지수만 선택\n",
    "    symbol_names = index_df.columns.get_level_values('Symbol Name')\n",
    "    kospi_kosdaq_mask = (symbol_names == '코스피') | (symbol_names == '코스닥')\n",
    "    kospi_kosdaq_indices = index_df.loc[:, kospi_kosdaq_mask]\n",
    "    kospi_kosdaq_indices.columns = kospi_kosdaq_indices.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "    # 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "    kospi_kosdaq_indices = (\n",
    "        kospi_kosdaq_indices\n",
    "        .astype(str)\n",
    "        .replace(',', '', regex=True)\n",
    "        .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)\n",
    "        .apply(pd.to_numeric, errors='coerce')\n",
    "    )\n",
    "\n",
    "    # 코스피와 코스닥 지수의 일별 수익률 계산\n",
    "    market_returns = kospi_kosdaq_indices.mean(axis=1).pct_change().dropna()\n",
    "\n",
    "    # 월별 수익률로 변환\n",
    "    rf_monthly_returns = market_returns.resample('M').apply(lambda x: (1 + x).prod() - 1)\n",
    "    rf_monthly_returns.name = 'Risk-Free Rate'\n",
    "\n",
    "    return rf_monthly_returns\n",
    "\n",
    "# 위험 무시 수익률(rf) 시리즈 가져오기\n",
    "rf_returns = get_risk_free_rate()\n",
    "\n",
    "# Sharpe Ratio를 계산하는 함수 정의\n",
    "def calculate_sharpe_ratio(returns_series, rf_series, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Sharpe Ratio를 계산하는 함수입니다.\n",
    "    \n",
    "    Parameters:\n",
    "    - returns_series (pd.Series): 월별 수익률 시리즈\n",
    "    - rf_series (pd.Series): 월별 위험 무시 수익률 시리즈\n",
    "    - start_date (str): Sharpe Ratio 계산에 사용할 시작 날짜 (예: '2008-10-31')\n",
    "    - end_date (str): Sharpe Ratio 계산에 사용할 종료 날짜 (예: '2018-09-30')\n",
    "    \n",
    "    Returns:\n",
    "    - sharpe_ratio (float): Sharpe Ratio 값\n",
    "    \"\"\"\n",
    "    # 지정된 기간으로 데이터 필터링\n",
    "    returns_series = returns_series.loc[start_date:end_date]\n",
    "    rf_series = rf_series.loc[start_date:end_date]\n",
    "\n",
    "    # 수익률과 위험 무시 수익률의 교집합 날짜 선택\n",
    "    common_index = returns_series.index.intersection(rf_series.index)\n",
    "    returns = returns_series.loc[common_index].dropna()\n",
    "    rf = rf_series.loc[common_index].dropna()\n",
    "\n",
    "    # 위험 프리미엄 계산 (초과 수익률)\n",
    "    excess_returns = returns - rf\n",
    "\n",
    "    # 결측치 제거\n",
    "    excess_returns = excess_returns.dropna()\n",
    "\n",
    "    # 월별 초과 수익률의 평균과 표준편차 계산\n",
    "    mean_excess_return = excess_returns.mean()\n",
    "    std_excess_return = excess_returns.std()\n",
    "\n",
    "    # Sharpe Ratio 계산 (연율화)\n",
    "    if std_excess_return != 0:\n",
    "        sharpe_ratio = (mean_excess_return / std_excess_return) * np.sqrt(12)\n",
    "    else:\n",
    "        sharpe_ratio = np.nan\n",
    "    return sharpe_ratio\n",
    "\n",
    "# 'factor'로 시작하는 모든 폴더 목록을 가져옵니다.\n",
    "factor_folders = [folder for folder in glob.glob('factor*') if os.path.isdir(folder)]\n",
    "\n",
    "# 각 팩터별로 Sharpe Ratio가 가장 높은 파일명을 저장할 리스트 초기화\n",
    "best_results = []\n",
    "\n",
    "# Training 데이터 기간 설정\n",
    "training_start_date = '2008-10-31'\n",
    "training_end_date = '2018-09-30'\n",
    "\n",
    "# 각 팩터 폴더에 대해 반복\n",
    "for folder in tqdm(factor_folders):\n",
    "    # print(f\"폴더 처리 중: {folder}\")\n",
    "    # 폴더 내의 모든 CSV 파일 목록 가져오기\n",
    "    csv_files = glob.glob(os.path.join(folder, '*.csv'))\n",
    "    \n",
    "    # Sharpe Ratio를 저장할 딕셔너리 초기화\n",
    "    sharpe_ratios = {}\n",
    "    \n",
    "    # 각 CSV 파일에 대해 반복\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            # CSV 파일 읽기\n",
    "            df = pd.read_csv(csv_file, index_col=0, parse_dates=True)\n",
    "            # 'Monthly Return' 컬럼이 존재하는지 확인\n",
    "            if 'Monthly Return' in df.columns:\n",
    "                # Sharpe Ratio 계산\n",
    "                sharpe_ratio = calculate_sharpe_ratio(df['Monthly Return'], rf_returns, training_start_date, training_end_date)\n",
    "                # Sharpe Ratio 저장\n",
    "                sharpe_ratios[csv_file] = sharpe_ratio\n",
    "            else:\n",
    "                print(f\"'Monthly Return' 컬럼이 없습니다: {csv_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"에러 발생: {csv_file}, 에러 내용: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 해당 팩터 폴더에서 Sharpe Ratio가 가장 높은 파일 찾기\n",
    "    if sharpe_ratios:\n",
    "        # 최대 Sharpe Ratio를 가진 파일 찾기\n",
    "        best_file = max(sharpe_ratios, key=sharpe_ratios.get)\n",
    "        best_sharpe = sharpe_ratios[best_file]\n",
    "        # print(f\"최고 Sharpe Ratio: {best_sharpe:.4f}, 파일명: {best_file}\")\n",
    "        # 파일명을 리스트에 추가\n",
    "        best_results.append(best_file)\n",
    "    else:\n",
    "        print(f\"Sharpe Ratio를 계산할 수 있는 파일이 없습니다: {folder}\")\n",
    "\n",
    "# best_results 리스트를 'best_results.txt' 파일에 저장\n",
    "with open('best_results.txt', 'w', encoding='utf-8') as f:\n",
    "    for file_path in best_results:\n",
    "        f.write(file_path + '\\n')\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n각 팩터별로 Sharpe Ratio가 가장 높은 파일 목록:\")\n",
    "for best_file in best_results:\n",
    "    print(best_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5744af42-dcbb-4471-aff2-fb1ca63a67d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 최종 선택된 경주마 발표(시각화)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776e0c99-cbaa-46da-a3a7-61832b68fc8a",
   "metadata": {},
   "source": [
    "factor_betting_against_beta\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
    "factor_high_pe_ratio\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
    "factor_high_pe_ratio_large_industry\\rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_high_pe_ratio_medium_industry\\rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal.csv\n",
    "factor_hml\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
    "factor_momentum\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_momentum_large_industry\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_momentum_medium_industry\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
    "factor_momentum_zscore\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_retained_earnings\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2402dd4c-2f82-409b-9469-3338925232bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import os\n",
    "\n",
    "# Plotly 렌더러 설정: 브라우저에서 그래프를 표시하도록 설정\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "# Training 데이터 기간 설정\n",
    "training_start_date = '2008-10-31'\n",
    "training_end_date = '2018-09-30'\n",
    "\n",
    "# 그래프의 트레이스를 저장할 리스트 초기화\n",
    "traces = []\n",
    "\n",
    "# Sharpe Ratio를 저장할 리스트 초기화\n",
    "sharpe_ratio_list = []\n",
    "\n",
    "# Sharpe Ratio 계산 함수 (이미 정의되어 있다고 가정)\n",
    "def calculate_sharpe_ratio(returns_series, rf_series, start_date, end_date):\n",
    "    # 지정된 기간으로 데이터 필터링\n",
    "    returns_series = returns_series.loc[start_date:end_date]\n",
    "    rf_series = rf_series.loc[start_date:end_date]\n",
    "\n",
    "    # 수익률과 위험 무시 수익률의 교집합 날짜 선택\n",
    "    common_index = returns_series.index.intersection(rf_series.index)\n",
    "    returns = returns_series.loc[common_index].dropna()\n",
    "    rf = rf_series.loc[common_index].dropna()\n",
    "\n",
    "    # 위험 프리미엄 계산 (초과 수익률)\n",
    "    excess_returns = returns - rf\n",
    "\n",
    "    # 결측치 제거\n",
    "    excess_returns = excess_returns.dropna()\n",
    "\n",
    "    # 월별 초과 수익률의 평균과 표준편차 계산\n",
    "    mean_excess_return = excess_returns.mean()\n",
    "    std_excess_return = excess_returns.std()\n",
    "\n",
    "    # Sharpe Ratio 계산 (연율화)\n",
    "    if std_excess_return != 0:\n",
    "        sharpe_ratio = (mean_excess_return / std_excess_return) * np.sqrt(12)\n",
    "    else:\n",
    "        sharpe_ratio = np.nan\n",
    "    return sharpe_ratio\n",
    "\n",
    "# 위험 무시 수익률(rf) 시리즈 가져오기 (이미 정의되어 있다고 가정)\n",
    "# rf_returns = get_risk_free_rate()\n",
    "\n",
    "# best_results 리스트에 담긴 CSV 파일들을 순회하면서 차트 생성 및 Sharpe Ratio 계산\n",
    "for csv_file in best_results:\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(csv_file, index_col=0, parse_dates=True)\n",
    "\n",
    "    # 기간 필터링 (Sharpe Ratio 계산 기간과 동일)\n",
    "    df_period = df.loc[training_start_date:training_end_date]\n",
    "\n",
    "    # 포트폴리오 가치와 월별 수익률이 존재하는지 확인\n",
    "    if 'Portfolio Value' in df_period.columns and 'Monthly Return' in df_period.columns:\n",
    "        # 포트폴리오 가치 시계열 데이터 준비\n",
    "        portfolio_values = df_period['Portfolio Value']\n",
    "\n",
    "        # 전략 이름 생성 (팩터 이름과 전략 정보 결합)\n",
    "        folder_name, file_name = os.path.split(csv_file)\n",
    "        factor_name = folder_name\n",
    "        strategy_info = file_name.replace('.csv', '')\n",
    "        strategy_name = f\"{factor_name} - {strategy_info}\"\n",
    "\n",
    "        # 그래프의 트레이스 생성 및 추가\n",
    "        trace = go.Scatter(\n",
    "            x=portfolio_values.index,\n",
    "            y=portfolio_values.values,\n",
    "            mode='lines',\n",
    "            name=strategy_name\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "        # Sharpe Ratio 계산\n",
    "        sharpe_ratio = calculate_sharpe_ratio(df_period['Monthly Return'], rf_returns, training_start_date, training_end_date)\n",
    "\n",
    "        # Sharpe Ratio를 리스트에 저장\n",
    "        sharpe_ratio_list.append({\n",
    "            'Strategy': strategy_name,\n",
    "            'Sharpe Ratio': sharpe_ratio\n",
    "        })\n",
    "    else:\n",
    "        print(f\"'Portfolio Value' 또는 'Monthly Return' 컬럼이 없습니다: {csv_file}\")\n",
    "\n",
    "# 그래프 레이아웃 설정\n",
    "layout = go.Layout(\n",
    "    title='최적의 전략별 포트폴리오 가치 비교 (2008-10-31 ~ 2018-09-30)',\n",
    "    xaxis=dict(title='날짜'),\n",
    "    yaxis=dict(title='포트폴리오 가치'),\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "# 그래프 생성 및 출력\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()\n",
    "\n",
    "# Sharpe Ratio를 데이터프레임으로 생성 및 출력\n",
    "sharpe_ratio_df = pd.DataFrame(sharpe_ratio_list)\n",
    "# print(\"\\n각 전략의 연율화 Sharpe Ratio:\")\n",
    "# print(sharpe_ratio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2649d5-c7ac-4a14-811b-37cbbbdcbdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factor_betting_against_beta - rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.331351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>factor_high_pe_ratio - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal</td>\n",
       "      <td>1.724515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>factor_high_pe_ratio_large_industry - rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>1.643497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>factor_high_pe_ratio_medium_industry - rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal</td>\n",
       "      <td>1.595004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factor_hml - rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal</td>\n",
       "      <td>1.320375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>factor_momentum - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>1.086129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>factor_momentum_large_industry - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.997482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>factor_momentum_medium_industry - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal</td>\n",
       "      <td>0.941031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>factor_momentum_zscore - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>1.086129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>factor_retained_earnings - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal</td>\n",
       "      <td>1.673971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         Strategy  \\\n",
       "0            factor_betting_against_beta - rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal   \n",
       "1                  factor_high_pe_ratio - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal   \n",
       "2    factor_high_pe_ratio_large_industry - rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "3  factor_high_pe_ratio_medium_industry - rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal   \n",
       "4                             factor_hml - rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal   \n",
       "5                        factor_momentum - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "6         factor_momentum_large_industry - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "7       factor_momentum_medium_industry - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal   \n",
       "8                 factor_momentum_zscore - rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "9              factor_retained_earnings - rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal   \n",
       "\n",
       "   Sharpe Ratio  \n",
       "0      0.331351  \n",
       "1      1.724515  \n",
       "2      1.643497  \n",
       "3      1.595004  \n",
       "4      1.320375  \n",
       "5      1.086129  \n",
       "6      0.997482  \n",
       "7      0.941031  \n",
       "8      1.086129  \n",
       "9      1.673971  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한 열에 표시되는 최대 문자 수 늘리기 (긴 문자열 표시)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "sharpe_ratio_df.to_csv('picked_strategy.csv', encoding='utf-8-sig')\n",
    "sharpe_ratio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "090e226c-2c8d-43e6-8598-4b1443d6244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c3802-5e5c-4264-aa1c-9e2aa89b81ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ML/AI 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529cc767-cfae-45f1-bf4a-2f102c621703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 백테스팅 CSV 파일 목록:\n",
      "factor_betting_against_beta\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
      "factor_high_pe_ratio\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
      "factor_high_pe_ratio_large_industry\\rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_high_pe_ratio_medium_industry\\rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal.csv\n",
      "factor_hml\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum_large_industry\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_momentum_medium_industry\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
      "factor_momentum_zscore\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "factor_retained_earnings\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n"
     ]
    }
   ],
   "source": [
    "# 'best_results.txt' 파일을 읽어서 best_results 리스트를 생성\n",
    "with open('best_results.txt', 'r', encoding='utf-8') as f:\n",
    "    best_results = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"선택된 백테스팅 CSV 파일 목록:\")\n",
    "for file_path in best_results:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cf1d262-0b84-47e0-99b6-13b1824d8f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "합쳐진 데이터프레임의 일부:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor_betting_against_beta_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Return</th>\n",
       "      <th>factor_betting_against_beta_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Value</th>\n",
       "      <th>factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return</th>\n",
       "      <th>factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value</th>\n",
       "      <th>factor_high_pe_ratio_large_industry_rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal_Return</th>\n",
       "      <th>factor_high_pe_ratio_large_industry_rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal_Value</th>\n",
       "      <th>factor_high_pe_ratio_medium_industry_rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal_Return</th>\n",
       "      <th>factor_high_pe_ratio_medium_industry_rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal_Value</th>\n",
       "      <th>factor_hml_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Return</th>\n",
       "      <th>factor_hml_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Value</th>\n",
       "      <th>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</th>\n",
       "      <th>factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value</th>\n",
       "      <th>factor_momentum_large_industry_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</th>\n",
       "      <th>factor_momentum_large_industry_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value</th>\n",
       "      <th>factor_momentum_medium_industry_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return</th>\n",
       "      <th>factor_momentum_medium_industry_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value</th>\n",
       "      <th>factor_momentum_zscore_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</th>\n",
       "      <th>factor_momentum_zscore_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value</th>\n",
       "      <th>factor_retained_earnings_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return</th>\n",
       "      <th>factor_retained_earnings_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-10-31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-30</th>\n",
       "      <td>0.021417</td>\n",
       "      <td>1.021417</td>\n",
       "      <td>0.018912</td>\n",
       "      <td>1.018912</td>\n",
       "      <td>0.033013</td>\n",
       "      <td>1.033013</td>\n",
       "      <td>-0.005787</td>\n",
       "      <td>0.994213</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>1.036158</td>\n",
       "      <td>-0.005663</td>\n",
       "      <td>0.994337</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>1.001145</td>\n",
       "      <td>0.045649</td>\n",
       "      <td>1.045649</td>\n",
       "      <td>-0.005663</td>\n",
       "      <td>0.994337</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>1.015206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-31</th>\n",
       "      <td>0.067172</td>\n",
       "      <td>1.090027</td>\n",
       "      <td>0.121680</td>\n",
       "      <td>1.142893</td>\n",
       "      <td>0.100885</td>\n",
       "      <td>1.137228</td>\n",
       "      <td>0.096314</td>\n",
       "      <td>1.089969</td>\n",
       "      <td>0.082849</td>\n",
       "      <td>1.122002</td>\n",
       "      <td>0.030436</td>\n",
       "      <td>1.024600</td>\n",
       "      <td>0.029115</td>\n",
       "      <td>1.030293</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>1.083323</td>\n",
       "      <td>0.030436</td>\n",
       "      <td>1.024600</td>\n",
       "      <td>0.116215</td>\n",
       "      <td>1.133189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-31</th>\n",
       "      <td>0.079528</td>\n",
       "      <td>1.176714</td>\n",
       "      <td>0.095259</td>\n",
       "      <td>1.251764</td>\n",
       "      <td>0.062318</td>\n",
       "      <td>1.208097</td>\n",
       "      <td>0.110474</td>\n",
       "      <td>1.210382</td>\n",
       "      <td>0.078950</td>\n",
       "      <td>1.210585</td>\n",
       "      <td>0.036154</td>\n",
       "      <td>1.061643</td>\n",
       "      <td>0.038832</td>\n",
       "      <td>1.070301</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>1.098305</td>\n",
       "      <td>0.036154</td>\n",
       "      <td>1.061643</td>\n",
       "      <td>0.089377</td>\n",
       "      <td>1.234470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02-28</th>\n",
       "      <td>0.000868</td>\n",
       "      <td>1.177735</td>\n",
       "      <td>0.007765</td>\n",
       "      <td>1.261484</td>\n",
       "      <td>-0.007253</td>\n",
       "      <td>1.199335</td>\n",
       "      <td>-0.010453</td>\n",
       "      <td>1.197730</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>1.228871</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>1.073745</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>1.064432</td>\n",
       "      <td>-0.010493</td>\n",
       "      <td>1.086780</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>1.073745</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>1.252300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            factor_betting_against_beta_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Return  \\\n",
       "Date                                                                                                    \n",
       "2008-10-31                                                                                   0.000000   \n",
       "2008-11-30                                                                                   0.021417   \n",
       "2008-12-31                                                                                   0.067172   \n",
       "2009-01-31                                                                                   0.079528   \n",
       "2009-02-28                                                                                   0.000868   \n",
       "\n",
       "            factor_betting_against_beta_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Value  \\\n",
       "Date                                                                                                   \n",
       "2008-10-31                                                                                  1.000000   \n",
       "2008-11-30                                                                                  1.021417   \n",
       "2008-12-31                                                                                  1.090027   \n",
       "2009-01-31                                                                                  1.176714   \n",
       "2009-02-28                                                                                  1.177735   \n",
       "\n",
       "            factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return  \\\n",
       "Date                                                                                              \n",
       "2008-10-31                                                                             0.000000   \n",
       "2008-11-30                                                                             0.018912   \n",
       "2008-12-31                                                                             0.121680   \n",
       "2009-01-31                                                                             0.095259   \n",
       "2009-02-28                                                                             0.007765   \n",
       "\n",
       "            factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value  \\\n",
       "Date                                                                                             \n",
       "2008-10-31                                                                            1.000000   \n",
       "2008-11-30                                                                            1.018912   \n",
       "2008-12-31                                                                            1.142893   \n",
       "2009-01-31                                                                            1.251764   \n",
       "2009-02-28                                                                            1.261484   \n",
       "\n",
       "            factor_high_pe_ratio_large_industry_rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal_Return  \\\n",
       "Date                                                                                                            \n",
       "2008-10-31                                                                                           0.000000   \n",
       "2008-11-30                                                                                           0.033013   \n",
       "2008-12-31                                                                                           0.100885   \n",
       "2009-01-31                                                                                           0.062318   \n",
       "2009-02-28                                                                                          -0.007253   \n",
       "\n",
       "            factor_high_pe_ratio_large_industry_rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal_Value  \\\n",
       "Date                                                                                                           \n",
       "2008-10-31                                                                                          1.000000   \n",
       "2008-11-30                                                                                          1.033013   \n",
       "2008-12-31                                                                                          1.137228   \n",
       "2009-01-31                                                                                          1.208097   \n",
       "2009-02-28                                                                                          1.199335   \n",
       "\n",
       "            factor_high_pe_ratio_medium_industry_rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal_Return  \\\n",
       "Date                                                                                                              \n",
       "2008-10-31                                                                                             0.000000   \n",
       "2008-11-30                                                                                            -0.005787   \n",
       "2008-12-31                                                                                             0.096314   \n",
       "2009-01-31                                                                                             0.110474   \n",
       "2009-02-28                                                                                            -0.010453   \n",
       "\n",
       "            factor_high_pe_ratio_medium_industry_rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal_Value  \\\n",
       "Date                                                                                                             \n",
       "2008-10-31                                                                                            1.000000   \n",
       "2008-11-30                                                                                            0.994213   \n",
       "2008-12-31                                                                                            1.089969   \n",
       "2009-01-31                                                                                            1.210382   \n",
       "2009-02-28                                                                                            1.197730   \n",
       "\n",
       "            factor_hml_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Return  \\\n",
       "Date                                                                                   \n",
       "2008-10-31                                                                  0.000000   \n",
       "2008-11-30                                                                  0.036158   \n",
       "2008-12-31                                                                  0.082849   \n",
       "2009-01-31                                                                  0.078950   \n",
       "2009-02-28                                                                  0.015106   \n",
       "\n",
       "            factor_hml_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Value  \\\n",
       "Date                                                                                  \n",
       "2008-10-31                                                                 1.000000   \n",
       "2008-11-30                                                                 1.036158   \n",
       "2008-12-31                                                                 1.122002   \n",
       "2009-01-31                                                                 1.210585   \n",
       "2009-02-28                                                                 1.228871   \n",
       "\n",
       "            factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return  \\\n",
       "Date                                                                                        \n",
       "2008-10-31                                                                       0.000000   \n",
       "2008-11-30                                                                      -0.005663   \n",
       "2008-12-31                                                                       0.030436   \n",
       "2009-01-31                                                                       0.036154   \n",
       "2009-02-28                                                                       0.011399   \n",
       "\n",
       "            factor_momentum_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value  \\\n",
       "Date                                                                                       \n",
       "2008-10-31                                                                      1.000000   \n",
       "2008-11-30                                                                      0.994337   \n",
       "2008-12-31                                                                      1.024600   \n",
       "2009-01-31                                                                      1.061643   \n",
       "2009-02-28                                                                      1.073745   \n",
       "\n",
       "            factor_momentum_large_industry_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return  \\\n",
       "Date                                                                                                       \n",
       "2008-10-31                                                                                      0.000000   \n",
       "2008-11-30                                                                                      0.001145   \n",
       "2008-12-31                                                                                      0.029115   \n",
       "2009-01-31                                                                                      0.038832   \n",
       "2009-02-28                                                                                     -0.005484   \n",
       "\n",
       "            factor_momentum_large_industry_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value  \\\n",
       "Date                                                                                                      \n",
       "2008-10-31                                                                                     1.000000   \n",
       "2008-11-30                                                                                     1.001145   \n",
       "2008-12-31                                                                                     1.030293   \n",
       "2009-01-31                                                                                     1.070301   \n",
       "2009-02-28                                                                                     1.064432   \n",
       "\n",
       "            factor_momentum_medium_industry_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return  \\\n",
       "Date                                                                                                         \n",
       "2008-10-31                                                                                        0.000000   \n",
       "2008-11-30                                                                                        0.045649   \n",
       "2008-12-31                                                                                        0.036029   \n",
       "2009-01-31                                                                                        0.013829   \n",
       "2009-02-28                                                                                       -0.010493   \n",
       "\n",
       "            factor_momentum_medium_industry_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value  \\\n",
       "Date                                                                                                        \n",
       "2008-10-31                                                                                       1.000000   \n",
       "2008-11-30                                                                                       1.045649   \n",
       "2008-12-31                                                                                       1.083323   \n",
       "2009-01-31                                                                                       1.098305   \n",
       "2009-02-28                                                                                       1.086780   \n",
       "\n",
       "            factor_momentum_zscore_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return  \\\n",
       "Date                                                                                               \n",
       "2008-10-31                                                                              0.000000   \n",
       "2008-11-30                                                                             -0.005663   \n",
       "2008-12-31                                                                              0.030436   \n",
       "2009-01-31                                                                              0.036154   \n",
       "2009-02-28                                                                              0.011399   \n",
       "\n",
       "            factor_momentum_zscore_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value  \\\n",
       "Date                                                                                              \n",
       "2008-10-31                                                                             1.000000   \n",
       "2008-11-30                                                                             0.994337   \n",
       "2008-12-31                                                                             1.024600   \n",
       "2009-01-31                                                                             1.061643   \n",
       "2009-02-28                                                                             1.073745   \n",
       "\n",
       "            factor_retained_earnings_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return  \\\n",
       "Date                                                                                                  \n",
       "2008-10-31                                                                                 0.000000   \n",
       "2008-11-30                                                                                 0.015206   \n",
       "2008-12-31                                                                                 0.116215   \n",
       "2009-01-31                                                                                 0.089377   \n",
       "2009-02-28                                                                                 0.014444   \n",
       "\n",
       "            factor_retained_earnings_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Value  \n",
       "Date                                                                                                \n",
       "2008-10-31                                                                                1.000000  \n",
       "2008-11-30                                                                                1.015206  \n",
       "2008-12-31                                                                                1.133189  \n",
       "2009-01-31                                                                                1.234470  \n",
       "2009-02-28                                                                                1.252300  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 전략의 월별 수익률과 포트폴리오 가치를 저장할 데이터프레임 리스트 초기화\n",
    "strategy_returns = []\n",
    "\n",
    "# 각 CSV 파일을 읽어서 데이터프레임 생성\n",
    "for csv_file in best_results:\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(csv_file, index_col=0, parse_dates=True)\n",
    "    \n",
    "    # 전략 이름 생성\n",
    "    folder_name, file_name = os.path.split(csv_file)\n",
    "    factor_name = folder_name\n",
    "    strategy_info = file_name.replace('.csv', '')\n",
    "    strategy_name = f\"{factor_name}_{strategy_info}\"\n",
    "    \n",
    "    # 'Monthly Return'과 'Portfolio Value' 컬럼 존재 여부 확인\n",
    "    if 'Monthly Return' in df.columns and 'Portfolio Value' in df.columns:\n",
    "        # 데이터프레임에 전략 이름을 접두사로 추가하여 컬럼 이름 변경\n",
    "        df = df[['Monthly Return', 'Portfolio Value']].copy()\n",
    "        df.columns = [f\"{strategy_name}_Return\", f\"{strategy_name}_Value\"]\n",
    "        \n",
    "        # 리스트에 추가\n",
    "        strategy_returns.append(df)\n",
    "    else:\n",
    "        print(f\"'Monthly Return' 또는 'Portfolio Value' 컬럼이 없습니다: {csv_file}\")\n",
    "\n",
    "# 모든 전략의 데이터프레임을 하나로 합치기\n",
    "combined_df = pd.concat(strategy_returns, axis=1)\n",
    "\n",
    "# 날짜로 정렬\n",
    "combined_df = combined_df.sort_index()\n",
    "\n",
    "# 결측치 처리 (앞 방향으로 채우기)\n",
    "combined_df = combined_df.fillna(method='ffill').dropna()\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\n합쳐진 데이터프레임의 일부:\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e15bf82-a76e-4e86-8e54-f208de69d4c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The given structure is not acyclic. Please review the following cycle: [('factor_betting_against_beta_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Return', 'factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return'), ('factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return', 'factor_betting_against_beta_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Return')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m sm \u001b[38;5;241m=\u001b[39m from_pandas(data_for_causal)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 베이지안 네트워크 생성\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m bn \u001b[38;5;241m=\u001b[39m \u001b[43mBayesianNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43msm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 결과 확인\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m인과 구조 학습 결과:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\causalnex_env\\lib\\site-packages\\causalnex\\network\\network.py:138\u001b[0m, in \u001b[0;36mBayesianNetwork.__init__\u001b[1;34m(self, structure)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mis_directed_acyclic_graph(structure):\n\u001b[0;32m    137\u001b[0m     cycle \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mfind_cycle(structure)\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe given structure is not acyclic. Please review the following cycle: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcycle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# _node_states is a Dict in the form `dict: {node: dict: {state: index}}`.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Underlying libraries expect all states to be integers from zero, and\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# thus this dict is used to convert from state -> idx, and then back from idx -> state as required\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_states \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# type: Dict[str: Dict[Hashable, int]]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The given structure is not acyclic. Please review the following cycle: [('factor_betting_against_beta_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Return', 'factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return'), ('factor_high_pe_ratio_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal_Return', 'factor_betting_against_beta_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal_Return')]"
     ]
    }
   ],
   "source": [
    "from causalnex.structure.notears import from_pandas\n",
    "from causalnex.network import BayesianNetwork\n",
    "\n",
    "# 수익률 컬럼 선택\n",
    "return_columns = [col for col in combined_df.columns if 'Return' in col]\n",
    "\n",
    "# 인과 구조 학습을 위한 데이터 준비\n",
    "data_for_causal = combined_df[return_columns]\n",
    "\n",
    "# 인과 구조 학습\n",
    "sm = from_pandas(data_for_causal)\n",
    "\n",
    "# 베이지안 네트워크 생성\n",
    "bn = BayesianNetwork(sm)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\n인과 구조 학습 결과:\")\n",
    "print(sm.edges(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da10947-7b42-4d0a-946e-770fa9c853ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.dr import DRLearner\n",
    "\n",
    "# 처치 변수와 결과 변수 설정\n",
    "# 여기서는 첫 번째 전략의 수익률을 결과 변수로, 나머지 전략의 수익률을 처치 변수로 사용합니다.\n",
    "outcome_variable = return_columns[0]\n",
    "treatment_variables = return_columns[1:]\n",
    "\n",
    "Y = combined_df[outcome_variable].values\n",
    "T = combined_df[treatment_variables].values\n",
    "X = combined_df.drop(columns=return_columns).values  # 다른 변수들 (없다면 None으로 설정)\n",
    "\n",
    "# EconML 모델 생성\n",
    "dr_learner = DRLearner()\n",
    "\n",
    "# 모델 학습\n",
    "dr_learner.fit(Y, T, X=X)\n",
    "\n",
    "# ITE 추정 및 새로운 특징 생성\n",
    "ite = dr_learner.effect(X)\n",
    "\n",
    "# 새로운 특징을 데이터프레임에 추가\n",
    "for i, col in enumerate(treatment_variables):\n",
    "    combined_df[f\"ITE_{col}_to_{outcome_variable}\"] = ite[:, i]\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\nEconML을 사용하여 추정한 ITE를 추가한 데이터프레임의 일부:\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66a521a8-ecca-453e-8494-9865f0cc7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "\n",
    "# 데이터 준비\n",
    "data = combined_df.reset_index()\n",
    "data['Date'] = data['Date'].astype(str)  # DoWhy에서 날짜 형식 처리\n",
    "\n",
    "# DoWhy 모델 생성\n",
    "model = CausalModel(\n",
    "    data=data,\n",
    "    treatment=treatment_variables[0],  # 첫 번째 처치 변수\n",
    "    outcome=outcome_variable,\n",
    "    common_causes=[]  # 공통 원인 변수 (필요한 경우 지정)\n",
    ")\n",
    "\n",
    "# 인과 효과 추정\n",
    "identified_estimand = model.identify_effect()\n",
    "estimate = model.estimate_effect(identified_estimand, method_name=\"backdoor.propensity_score_matching\")\n",
    "\n",
    "# 추정된 효과를 데이터프레임에 추가\n",
    "combined_df[f\"DoWhy_Effect_{treatment_variables[0]}_to_{outcome_variable}\"] = estimate.value\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\nDoWhy를 사용하여 추정한 인과 효과를 추가한 데이터프레임의 일부:\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180b87c-60f2-4212-b9d3-26cf560bab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 상관관계 분석\n",
    "corr_matrix = combined_df.corr()\n",
    "\n",
    "# 히트맵 그리기\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# PCA 적용을 위한 데이터 준비 (수익률 관련 컬럼만 선택)\n",
    "pca_columns = [col for col in combined_df.columns if 'Return' in col or 'ITE' in col or 'Effect' in col]\n",
    "pca_data = combined_df[pca_columns].dropna()\n",
    "\n",
    "# PCA 적용 (설명 분산의 95%를 유지하도록)\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(pca_data)\n",
    "\n",
    "# 변환된 데이터 생성\n",
    "pca_features = pca.transform(pca_data)\n",
    "\n",
    "# PCA 결과를 데이터프레임에 추가\n",
    "for i in range(pca_features.shape[1]):\n",
    "    combined_df[f'PCA_Feature_{i+1}'] = pca_features[:, i]\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\nPCA 적용 후 데이터프레임의 일부:\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de18b4a-c011-4b65-88ba-07b8b42748f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 시점마다 가장 높은 수익률을 보인 전략의 이름을 레이블로 생성\n",
    "return_columns = [col for col in combined_df.columns if 'Return' in col and 'MA' not in col and 'STD' not in col]\n",
    "combined_df['Best_Strategy'] = combined_df[return_columns].idxmax(axis=1)\n",
    "\n",
    "# 레이블 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "combined_df['Best_Strategy_Label'] = label_encoder.fit_transform(combined_df['Best_Strategy'])\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\n레이블이 추가된 데이터프레임의 일부:\")\n",
    "print(combined_df[['Best_Strategy', 'Best_Strategy_Label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbeccd-51fa-4526-8dc7-94bba7788e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 변수와 레이블 분리\n",
    "feature_columns = [col for col in combined_df.columns if 'PCA_Feature' in col]\n",
    "label_column = 'Best_Strategy_Label'\n",
    "\n",
    "# 데이터 정렬\n",
    "combined_df = combined_df.sort_index()\n",
    "\n",
    "# 시퀀스 길이 설정 (과거 12개월)\n",
    "sequence_length = 12\n",
    "\n",
    "# 입력 데이터와 레이블을 저장할 리스트 초기화\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# 시퀀스 데이터 생성\n",
    "for i in range(sequence_length, len(combined_df)):\n",
    "    # 과거 12개월의 입력 변수\n",
    "    X_seq = combined_df.iloc[i-sequence_length:i][feature_columns].values\n",
    "    # 현재 시점의 레이블\n",
    "    y_label = combined_df.iloc[i][label_column]\n",
    "    X.append(X_seq)\n",
    "    y.append(y_label)\n",
    "\n",
    "# numpy 배열로 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 데이터 크기 확인\n",
    "print(f\"\\n입력 데이터 형태: {X.shape}\")\n",
    "print(f\"레이블 데이터 형태: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023b825-85e2-493f-9a2b-092dd8d8aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스의 마지막 날짜를 기준으로 데이터 분할\n",
    "dates = combined_df.index[sequence_length:]\n",
    "\n",
    "# 날짜별로 인덱스 생성\n",
    "date_to_index = {date: idx for idx, date in enumerate(dates)}\n",
    "\n",
    "# 각 기간의 마지막 인덱스 계산\n",
    "train_end_date = pd.to_datetime('2018-09-30')\n",
    "val_end_date = pd.to_datetime('2021-09-30')\n",
    "\n",
    "train_indices = [i for i, date in enumerate(dates) if date <= train_end_date]\n",
    "val_indices = [i for i, date in enumerate(dates) if train_end_date < date <= val_end_date]\n",
    "test_indices = [i for i, date in enumerate(dates) if date > val_end_date]\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, y_train = X[train_indices], y[train_indices]\n",
    "X_val, y_val = X[val_indices], y[val_indices]\n",
    "X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "# 각 데이터 세트의 크기 확인\n",
    "print(\"\\n데이터 세트 크기:\")\n",
    "print(f\"Train 데이터: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation 데이터: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test 데이터: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd87c4a-733f-4f5f-88ff-01b239d5b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 각 특성별로 스케일러를 저장하기 위한 딕셔너리 초기화\n",
    "scalers = {}\n",
    "\n",
    "# 훈련 데이터의 입력 변수 형태: (샘플 수, 시퀀스 길이, 특성 수)\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "# 각 특성에 대해 스케일러를 적용\n",
    "for feature_idx in range(n_features):\n",
    "    scaler = StandardScaler()\n",
    "    # 훈련 데이터의 해당 특성에 대해 스케일러 학습\n",
    "    scaler.fit(X_train[:, :, feature_idx].reshape(-1, 1))\n",
    "    # 훈련, 검증, 테스트 데이터에 스케일러 적용\n",
    "    X_train[:, :, feature_idx] = scaler.transform(X_train[:, :, feature_idx].reshape(-1, 1)).reshape(X_train.shape[0], X_train.shape[1])\n",
    "    X_val[:, :, feature_idx] = scaler.transform(X_val[:, :, feature_idx].reshape(-1, 1)).reshape(X_val.shape[0], X_val.shape[1])\n",
    "    X_test[:, :, feature_idx] = scaler.transform(X_test[:, :, feature_idx].reshape(-1, 1)).reshape(X_test.shape[0], X_test.shape[1])\n",
    "    # 스케일러 저장\n",
    "    scalers[feature_idx] = scaler\n",
    "\n",
    "print(\"\\n스케일링이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf7185-24b7-4d34-addb-90c6e9246d57",
   "metadata": {},
   "source": [
    "여기서부터 인과추론 적용/미적용 A/B Test 시작\n",
    "\n",
    "모델 A (단순 딥러닝): 인과 추론을 적용하지 않은 원본 데이터 사용\n",
    "\n",
    "모델 B (인과 딥러닝): 인과 추론 결과를 포함한 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea43151-7773-44e2-b978-aa6dc3a0fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 A를 위한 데이터 (인과 추론 결과를 제외한 PCA 특징만 사용)\n",
    "feature_columns_A = [col for col in combined_df.columns if 'PCA_Feature' in col and 'ITE' not in col and 'Effect' not in col]\n",
    "\n",
    "# 시퀀스 데이터 생성\n",
    "X_A = []\n",
    "for i in range(sequence_length, len(combined_df)):\n",
    "    X_seq = combined_df.iloc[i-sequence_length:i][feature_columns_A].values\n",
    "    X_A.append(X_seq)\n",
    "\n",
    "X_A = np.array(X_A)\n",
    "\n",
    "# 데이터 분할\n",
    "X_A_train, X_A_val, X_A_test = X_A[train_indices], X_A[val_indices], X_A[test_indices]\n",
    "\n",
    "# 스케일링 적용 (모델 A용)\n",
    "scalers_A = {}\n",
    "n_features_A = X_A_train.shape[2]\n",
    "\n",
    "for feature_idx in range(n_features_A):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_A_train[:, :, feature_idx].reshape(-1, 1))\n",
    "    X_A_train[:, :, feature_idx] = scaler.transform(X_A_train[:, :, feature_idx].reshape(-1, 1)).reshape(X_A_train.shape[0], X_A_train.shape[1])\n",
    "    X_A_val[:, :, feature_idx] = scaler.transform(X_A_val[:, :, feature_idx].reshape(-1, 1)).reshape(X_A_val.shape[0], X_A_val.shape[1])\n",
    "    X_A_test[:, :, feature_idx] = scaler.transform(X_A_test[:, :, feature_idx].reshape(-1, 1)).reshape(X_A_test.shape[0], X_A_test.shape[1])\n",
    "    scalers_A[feature_idx] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7127d2-2e9a-4751-a8f8-cbfba2a26489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 B를 위한 데이터 (인과 추론 결과를 포함한 PCA 특징 사용)\n",
    "feature_columns_B = [col for col in combined_df.columns if 'PCA_Feature' in col]\n",
    "\n",
    "# 시퀀스 데이터 생성\n",
    "X_B = []\n",
    "for i in range(sequence_length, len(combined_df)):\n",
    "    X_seq = combined_df.iloc[i-sequence_length:i][feature_columns_B].values\n",
    "    X_B.append(X_seq)\n",
    "\n",
    "X_B = np.array(X_B)\n",
    "\n",
    "# 데이터 분할\n",
    "X_B_train, X_B_val, X_B_test = X_B[train_indices], X_B[val_indices], X_B[test_indices]\n",
    "\n",
    "# 스케일링 적용 (모델 B용)\n",
    "scalers_B = {}\n",
    "n_features_B = X_B_train.shape[2]\n",
    "\n",
    "for feature_idx in range(n_features_B):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_B_train[:, :, feature_idx].reshape(-1, 1))\n",
    "    X_B_train[:, :, feature_idx] = scaler.transform(X_B_train[:, :, feature_idx].reshape(-1, 1)).reshape(X_B_train.shape[0], X_B_train.shape[1])\n",
    "    X_B_val[:, :, feature_idx] = scaler.transform(X_B_val[:, :, feature_idx].reshape(-1, 1)).reshape(X_B_val.shape[0], X_B_val.shape[1])\n",
    "    X_B_test[:, :, feature_idx] = scaler.transform(X_B_test[:, :, feature_idx].reshape(-1, 1)).reshape(X_B_test.shape[0], X_B_test.shape[1])\n",
    "    scalers_B[feature_idx] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe90ea8-72d2-4565-8619-a1595b6fe2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (causalnex_env)",
   "language": "python",
   "name": "causalnex_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
