{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64657c3-f098-4eab-9c40-bf899ba7b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6328d54-d6a3-419b-9a36-a97435953b07",
   "metadata": {},
   "source": [
    "# CSV 부르기 및 기본적인 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa522af-a990-4a33-b348-445c51e6c468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 통합한 월별 데이터 파일이 존재합니다. 해당 CSV를 불러옵니다.\n",
      "월별 CSV를 불러왔습니다.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame을 저장할 리스트 생성\n",
    "df_list = []\n",
    "\n",
    "# 1. 'data' 폴더 내에 'KSIF'가 포함된 CSV 파일 목록 가져오기\n",
    "file_list = glob.glob('data/*KSIF*.csv')\n",
    "\n",
    "# 파일이 존재하는지 확인\n",
    "if not file_list:\n",
    "    print(\"패턴에 맞는 파일을 찾을 수 없습니다.\")\n",
    "elif os.path.exists('data/merged_df_monthly.csv'):\n",
    "    print(\"이미 통합한 월별 데이터 파일이 존재합니다. 해당 CSV를 불러옵니다.\")\n",
    "    merged_df_backup = pd.read_csv(\n",
    "        'data/merged_df_monthly.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "        parse_dates=True  # 인덱스를 datetime으로 파싱\n",
    "    )\n",
    "    print(\"월별 CSV를 불러왔습니다.\")\n",
    "elif os.path.exists('data/merged_data.csv'):\n",
    "    print(\"이미 통합한 일별 데이터 파일이 존재합니다. 해당 CSV를 월별로 전환합니다.\")\n",
    "    merged_df_backup = pd.read_csv(\n",
    "        'data/merged_data.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "    # 인덱스를 datetime으로 변환\n",
    "    merged_df_backup.index = pd.to_datetime(merged_df_backup.index, errors='coerce')\n",
    "    \n",
    "    # 월별 리샘플링\n",
    "    merged_df_backup = merged_df_backup.resample('M').last()\n",
    "    \n",
    "    # 월별 데이터 저장\n",
    "    merged_df_backup.to_csv('data/merged_df_monthly.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"월별 리샘플링된 데이터가 'merged_df_monthly.csv'로 저장되었습니다.\")\n",
    "    print(\"월별 CSV를 불러왔습니다.\")\n",
    "else:\n",
    "    # tqdm을 사용하여 진행 상황 표시\n",
    "    for file_path in tqdm(file_list, desc=\"파일 처리 중\"):\n",
    "        # 각 CSV 파일 읽기 (적절한 인코딩과 인덱스 설정)\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                skiprows=8,\n",
    "                header=[0, 1, 2, 3, 4, 5],\n",
    "                index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "                encoding='cp949',\n",
    "                parse_dates=True\n",
    "            )\n",
    "        except UnicodeDecodeError:\n",
    "            # 'cp949' 인코딩이 안 될 경우 'euc-kr'로 시도\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                skiprows=8,\n",
    "                header=[0, 1, 2, 3, 4, 5],\n",
    "                index_col=0,\n",
    "                encoding='euc-kr',\n",
    "                parse_dates=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"파일 {file_path}를 로드하는 중 에러 발생: {e}\")\n",
    "            continue  # 에러 발생 시 다음 파일로 넘어감\n",
    "        \n",
    "        # 멀티인덱스 컬럼에 이름 지정\n",
    "        df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "        \n",
    "        # 인덱스 이름 지정 ('Date'로 설정)\n",
    "        df.index.name = 'Date'\n",
    "        \n",
    "        # 인덱스를 datetime으로 변환\n",
    "        df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "        \n",
    "        # 'Kind', 'Frequency' 레벨 제거하여 필요한 컬럼만 남김\n",
    "        df.columns = df.columns.droplevel(['Kind', 'Frequency'])\n",
    "        \n",
    "        # 리스트에 DataFrame 추가\n",
    "        df_list.append(df)\n",
    "    \n",
    "    # 2. 모든 DataFrame을 수평적으로 병합\n",
    "    print(\"DataFrame 병합 중...\")\n",
    "    merged_df_backup = pd.concat(df_list, axis=1)\n",
    "    del df_list  # 리스트 메모리에서 삭제\n",
    "    gc.collect()  # 가비지 컬렉션 실행\n",
    "    \n",
    "    # 월별 리샘플링\n",
    "    print(\"월별 리샘플링 중...\")\n",
    "    merged_df_backup = merged_df_backup.resample('M').last()\n",
    "    \n",
    "    # 월별 데이터 저장\n",
    "    merged_df_backup.to_csv('data/merged_df_monthly.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"월별 리샘플링된 데이터가 'merged_df_monthly.csv'로 저장되었습니다.\")\n",
    "    \n",
    "    # 필요에 따라 일별 데이터를 저장하려면 아래 주석을 해제하세요.\n",
    "    # merged_df_backup.to_csv('data/merged_data.csv', encoding='utf-8-sig')\n",
    "    # print(\"모든 CSV 파일을 병합하여 'merged_data.csv'로 저장했습니다.\")\n",
    "\n",
    "    # 메모리 관리\n",
    "    del merged_df_backup\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993372a2-821d-46b6-b494-f828a95d8281",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m issues\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 점검 실행\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mcheck_dataframe_issues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#여기서 인덱스 2번이 뜨는 이유는 얘가 하루 더 있거등요 ㅇㅇ\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mcheck_dataframe_issues\u001b[1;34m(df_list)\u001b[0m\n\u001b[0;32m     10\u001b[0m issues \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_unique_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmismatched_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 기준 인덱스는 첫 번째 데이터프레임의 인덱스로 설정\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m base_index \u001b[38;5;241m=\u001b[39m \u001b[43mdf_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 각 데이터프레임 점검\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_list):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 1. 고유하지 않은 인덱스 확인\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def check_dataframe_issues(df_list):\n",
    "    \"\"\"\n",
    "    점검 함수: 데이터프레임 리스트에서 고유하지 않은 인덱스와 기준 인덱스 불일치 확인\n",
    "    Args:\n",
    "        df_list (list): pandas 데이터프레임들의 리스트\n",
    "    Returns:\n",
    "        dict: 문제를 가진 데이터프레임의 인덱스 (non_unique_index, mismatched_index)\n",
    "    \"\"\"\n",
    "    # 결과 저장용 딕셔너리\n",
    "    issues = {\"non_unique_index\": [], \"mismatched_index\": []}\n",
    "    \n",
    "    # 기준 인덱스는 첫 번째 데이터프레임의 인덱스로 설정\n",
    "    base_index = df_list[0].index\n",
    "\n",
    "    # 각 데이터프레임 점검\n",
    "    for i, df in enumerate(df_list):\n",
    "        # 1. 고유하지 않은 인덱스 확인\n",
    "        if not df.index.is_unique:\n",
    "            issues[\"non_unique_index\"].append(i)\n",
    "        \n",
    "        # 2. 기준 인덱스와 불일치 확인\n",
    "        if not base_index.equals(df.index):\n",
    "            issues[\"mismatched_index\"].append(i)\n",
    "\n",
    "    return issues\n",
    "\n",
    "# 점검 실행\n",
    "check_dataframe_issues(df_list)#여기서 인덱스 2번이 뜨는 이유는 얘가 하루 더 있거등요 ㅇㅇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f466bdd7-d688-49ec-8d17-d66b687424ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['수정주가(원)', 'PER(보통)(배)', 'PER(직전4분기)(배)', 'PER(보통,자사주차감)(배)',\n",
       "       'BPS(발표기준기말주식수)(원)', 'BPS(자사주차감)(원)', '상장주식수(주)', '시가총액 (평균)(원)',\n",
       "       '상장주식수 (보통)(주)', '매출총이익(원)', '총자산(원)', '유동자산(원)', '현금및현금성자산(원)',\n",
       "       '유동부채(원)', '단기차입금(원)', '이연법인세부채(원)', '거래대금(원)', '관리종목지정사유', '기타포괄손익(원)',\n",
       "       '베타 (M,3Yr)', '베타 (D,1Yr)', '보통주자본금(원)', '수익률(%)', '수익률 (1개월)(%)',\n",
       "       '수정주가 (52주 최고)(원)', '유무형자산상각비(원)', '이익잉여금(원)', 'Unnamed: 3182_level_4',\n",
       "       '이익잉여금(천원)'],\n",
       "      dtype='object', name='item Name')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_backup.columns.get_level_values(3).unique()#우리 데이터 뭐있나 함 볼까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24f2a1-46a7-4777-bd42-1f82fb9cf369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 월별 데이터로 작업할 merged_df 생성\n",
    "merged_df = merged_df_backup.copy()\n",
    "\n",
    "# 1. \"(원)\"으로 끝나는 컬럼 처리\n",
    "# 'item Name'이 '(원)'으로 끝나는 컬럼 선택\n",
    "won_mask = merged_df.columns.get_level_values('item Name').str.endswith('(원)')\n",
    "\n",
    "# 쉼표 제거 및 숫자 변환을 벡터화된 연산으로 수행\n",
    "# 문자열 'None', 'nan', '', 'N/A' 등을 NaN으로 변환\n",
    "merged_df.loc[:, won_mask] = (\n",
    "    merged_df.loc[:, won_mask]\n",
    "    .astype(str)  # 모든 데이터를 문자열로 변환\n",
    "    .replace(',', '', regex=True)  # 쉼표 제거\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A'], np.nan)  # 비정상적인 값들을 NaN으로 변환\n",
    "    .apply(pd.to_numeric, errors='coerce')  # 숫자로 변환 (변환 불가 시 NaN)\n",
    ")\n",
    "\n",
    "print(\"'(원)' 컬럼의 문자열 변환 및 숫자 변환 완료\")\n",
    "\n",
    "# 2. '홀딩스', '지주', '스펙'으로 끝나는 종목 제거\n",
    "pattern = ('홀딩스', '지주', '스펙', '스팩')\n",
    "symbol_names = merged_df.columns.get_level_values('Symbol Name')\n",
    "mask = symbol_names.str.endswith(pattern)\n",
    "merged_df = merged_df.loc[:, ~mask]\n",
    "\n",
    "# 3. '관리종목지정사유' 처리\n",
    "# '관리종목지정사유'가 있는 종목 추출\n",
    "management_mask = merged_df.columns.get_level_values('item Name') == '관리종목지정사유'\n",
    "management_df = merged_df.loc[:, management_mask]\n",
    "\n",
    "# 인덱스를 datetime 형태로 변환\n",
    "merged_df.index = pd.to_datetime(merged_df.index, errors='coerce')\n",
    "\n",
    "# 각 종목별로 처리\n",
    "for symbol in management_df.columns.get_level_values('Symbol').unique():\n",
    "    symbol_management = management_df.loc[:, management_df.columns.get_level_values('Symbol') == symbol]\n",
    "    \n",
    "    # NaN이 아닌 첫 번째 날짜 찾기\n",
    "    dates_with_issue = symbol_management[symbol_management.notna().any(axis=1)].index\n",
    "    \n",
    "    if not dates_with_issue.empty:\n",
    "        try:\n",
    "            # 이슈 발생 날짜\n",
    "            issue_date = dates_with_issue[0]\n",
    "            \n",
    "            # 해당 Symbol의 데이터를 처리\n",
    "            symbol_mask = merged_df.columns.get_level_values('Symbol') == symbol\n",
    "            price_mask = merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "            other_mask = symbol_mask & ~price_mask\n",
    "            \n",
    "            # 이슈 발생 월부터 이후 데이터에 대해 NaN으로 설정 (수정주가는 제외)\n",
    "            merged_df.loc[merged_df.index >= issue_date, other_mask] = np.nan\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing symbol: {symbol}, issue_date: {issue_date}, Error: {e}\")\n",
    "\n",
    "print('관리종목 포트폴리오 정상화')\n",
    "\n",
    "# 4. '거래대금(원)' 기반 종목 제거\n",
    "trading_value_mask = merged_df.columns.get_level_values('item Name') == '거래대금(원)'\n",
    "trading_value_df = merged_df.loc[:, trading_value_mask]\n",
    "\n",
    "# 인덱스를 datetime으로 변환\n",
    "trading_value_df.index = pd.to_datetime(trading_value_df.index)\n",
    "\n",
    "# 2014년 이후 데이터 선택\n",
    "trading_value_df = trading_value_df[trading_value_df.index >= '2014-01-31']\n",
    "\n",
    "# 문자열을 숫자로 변환 (오류 발생 시 NaN 처리)\n",
    "trading_value_df = trading_value_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 거래대금이 4천만원 이하인 경우 True, NaN은 False로 처리\n",
    "low_trading_value = (trading_value_df <= 40000000).fillna(False)\n",
    "\n",
    "# 각 Symbol마다 거래대금이 4천만원 이하인 달이 하나라도 있는지 확인\n",
    "symbols_to_remove = low_trading_value.any(axis=0)\n",
    "symbols_to_remove = symbols_to_remove[symbols_to_remove].index.get_level_values('Symbol').unique().tolist()\n",
    "\n",
    "# 해당 Symbol 제거\n",
    "symbol_mask = merged_df.columns.get_level_values('Symbol').isin(symbols_to_remove)\n",
    "merged_df = merged_df.loc[:, ~symbol_mask]\n",
    "\n",
    "print('market impact 조정 완료')\n",
    "\n",
    "# 5. 수정주가 기반 1개월 수익률 계산\n",
    "# 인덱스를 datetime으로 변환\n",
    "merged_df.index = pd.to_datetime(merged_df.index)\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = merged_df.loc[:, price_mask]\n",
    "\n",
    "# 월별 수익률 계산\n",
    "returns_df = price_df.pct_change()\n",
    "\n",
    "# 'item Name'을 '1개월 수익률(계산)'으로 변경\n",
    "returns_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, item, '1개월 수익률(계산)') for symbol, symbol_name, item in zip(\n",
    "        returns_df.columns.get_level_values('Symbol'),\n",
    "        returns_df.columns.get_level_values('Symbol Name'),\n",
    "        returns_df.columns.get_level_values('item')\n",
    "    )],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 수익률 데이터를 merged_df에 추가\n",
    "merged_df = pd.concat([merged_df, returns_df], axis=1)\n",
    "\n",
    "print('1개월 수익률 계산 완료')\n",
    "\n",
    "# 6. 결측치를 직전 값으로 대체\n",
    "merged_df = merged_df.fillna(method='ffill')\n",
    "\n",
    "print(\"전처리 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba780af-3c56-4772-b5c9-50d29dbc54ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('data/merged_df_monthly_preprocessing.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483dc094-5740-457f-9e86-f6022005d452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol   Symbol Name  item        item Name       \n",
       "A000660  SK하이닉스       S410000700  수정주가(원)               int64\n",
       "                      6000701101  PER(보통)(배)          float64\n",
       "                      6000701007  PER(직전4분기)(배)       float64\n",
       "                      6000701006  PER(보통,자사주차감)(배)    float64\n",
       "A373220  LG에너지솔루션     S410000700  수정주가(원)             float64\n",
       "                                                       ...   \n",
       "A900030  연합과기         S410000700  1개월 수익률(계산)         float64\n",
       "A900060  중국식품포장       S410000700  1개월 수익률(계산)         float64\n",
       "A900150  성융광전투자       S410000700  1개월 수익률(계산)         float64\n",
       "A950030  네프로아이티       S410000700  1개월 수익률(계산)         float64\n",
       "A950070  중국고섬         S410000700  1개월 수익률(계산)         float64\n",
       "Length: 58059, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_backup.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4290465-1b88-424e-9971-8e99a319a7a7",
   "metadata": {},
   "source": [
    "# 팩터값 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ee2c22-003a-4f71-8acd-265d6781415f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 팩터 전략별로 필요한 데이터를 계산하여 monthly_merged_df에 추가합니다.\n",
    "\n",
    "if 'monthly_merged_df' not in globals():\n",
    "    monthly_merged_df = pd.read_csv(\n",
    "        'data/merged_df_monthly_preprocessing.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "424f8216-865c-4d17-a2ac-66bacc9a1025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206, 2067)\n",
      "'factor_high_pe_ratio_large_industry.csv' 파일이 저장되었습니다.\n",
      "'factor_high_pe_ratio_medium_industry.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 1: High P/E Ratio =====\n",
    "# 상위 20% 종목에 롱 포지션, 하위 20% 종목에 숏 포지션을 취하는 전략\n",
    "\n",
    "# 'PER(직전4분기)(배)' 데이터 추출\n",
    "per_mask = monthly_merged_df.columns.get_level_values('item Name') == 'PER(보통,자사주차감)(배)'\n",
    "per_df = monthly_merged_df.loc[:, per_mask]\n",
    "per_df.columns = per_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 결측치 처리 전에 per_df의 데이터를 float 타입으로 변환\n",
    "per_df = per_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 결측치 처리\n",
    "per_df = per_df.replace(0, np.nan)\n",
    "per_df = per_df.replace(np.inf, np.nan)\n",
    "per_df = per_df.fillna(method='ffill')\n",
    "\n",
    "# 전체 종목에 대해 z-score 계산\n",
    "per_zscore = -per_df.apply(lambda x: (x - x.mean()) / x.std(), axis=1)\n",
    "\n",
    "# 산업 분류 데이터 불러오기\n",
    "try:\n",
    "    industry_df = pd.read_csv(\n",
    "        'data/industry.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    industry_df = pd.read_csv(\n",
    "        'data/industry.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "        encoding='cp949',\n",
    "        parse_dates=True  # 인덱스를 datetime으로 파싱\n",
    "    )\n",
    "    \n",
    "# 멀티인덱스 설정\n",
    "industry_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "industry_df.index.name = 'Date'\n",
    "\n",
    "# '한국표준산업분류10차(대분류)', '한국표준산업분류10차(중분류)' 데이터 추출\n",
    "industry_large_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(대분류)'\n",
    "industry_medium_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(중분류)'\n",
    "\n",
    "industry_large_df = industry_df.loc[:, industry_large_mask]\n",
    "industry_large_df.columns = industry_large_df.columns.droplevel(['item', 'item Name'])\n",
    "industry_medium_df = industry_df.loc[:, industry_medium_mask]\n",
    "industry_medium_df.columns = industry_medium_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# PER 데이터와 산업 분류 데이터의 인덱스 및 컬럼 정렬\n",
    "# per_df, industry_large_df = per_df.align(industry_large_df, join='inner', axis=1)\n",
    "# per_df, industry_medium_df = per_df.align(industry_medium_df, join='inner', axis=1)\n",
    "\n",
    "# 디버깅 출력을 위한 함수\n",
    "def debug_print(message, df=None):\n",
    "    print(message)\n",
    "    if df is not None:\n",
    "        print(df.head())\n",
    "        print(df.shape)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# 산업별로 z-score 계산\n",
    "def industry_zscore(per_series, industry_series):\n",
    "    df = pd.DataFrame({'PER': per_series, 'Industry': industry_series})\n",
    "    return df.groupby('Industry')['PER'].transform(lambda x: -(x - x.mean()) / x.std())\n",
    "\n",
    "# 대분류 산업별 z-score\n",
    "per_zscore_large = per_df.copy()\n",
    "print(per_zscore_large.shape)\n",
    "for date in per_zscore_large.index:\n",
    "    per_zscore_large.loc[date] = industry_zscore(per_df.loc[date], industry_large_df.loc[date])\n",
    "    # 디버깅 출력\n",
    "    # debug_print(f\"[Large Industry] Date: {date}\", per_zscore_large.loc[[date]])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "per_zscore_large.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'PER_large', 'PER_large') for symbol, symbol_name in per_zscore_large.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore_large.to_csv('factor_high_pe_ratio_large_industry.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio_large_industry.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 중분류 산업별 z-score\n",
    "per_zscore_medium = per_df.copy()\n",
    "for date in per_zscore_medium.index:\n",
    "    per_zscore_medium.loc[date] = industry_zscore(per_df.loc[date], industry_medium_df.loc[date])\n",
    "    # 디버깅 출력\n",
    "    # debug_print(f\"[Medium Industry] Date: {date}\", per_zscore_medium.loc[[date]])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "per_zscore_medium.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'PER_large', 'PER_large') for symbol, symbol_name in per_zscore_medium.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "# 팩터 값 저장\n",
    "per_zscore_medium.to_csv('factor_high_pe_ratio_medium_industry.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio_medium_industry.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore.to_csv('factor_high_pe_ratio.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0b1ba1e-178a-436f-b550-6a1fa21dd198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_hml.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 2: HML (Kang, 2013) =====\n",
    "# Book-to-Market Ratio 계산 (BPS / 주가)\n",
    "\n",
    "# 'BPS(자사주차감)(원)' 데이터 추출\n",
    "bps_mask = monthly_merged_df.columns.get_level_values('item Name') == 'BPS(자사주차감)(원)'\n",
    "bps_df = monthly_merged_df.loc[:, bps_mask]\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = monthly_merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = monthly_merged_df.loc[:, price_mask]\n",
    "\n",
    "# 컬럼 레벨 중 'item'과 'item Name'을 제거하여 컬럼 정렬\n",
    "bps_df.columns = bps_df.columns.droplevel(['item', 'item Name'])\n",
    "price_df.columns = price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "bps_df, price_df = bps_df.align(price_df, join='inner', axis=0)\n",
    "bps_df, price_df = bps_df.align(price_df, join='inner', axis=1)\n",
    "\n",
    "# 계산 전에 데이터 타입 변환\n",
    "bps_df = bps_df.apply(pd.to_numeric, errors='coerce')\n",
    "price_df = price_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Book-to-Market Ratio 계산\n",
    "bm_ratio_df = bps_df / price_df\n",
    "\n",
    "# 결측치 처리\n",
    "bm_ratio_df = bm_ratio_df.replace([np.inf, -np.inf], np.nan)\n",
    "bm_ratio_df = bm_ratio_df.fillna(method='ffill')\n",
    "\n",
    "# 멀티레벨 컬럼 구조 재설정\n",
    "bm_ratio_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'BM Ratio', 'BM Ratio') for symbol, symbol_name in bm_ratio_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "bm_ratio_df.to_csv('factor_hml.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_hml.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e451f8b-6323-46bf-aa1c-ae95be7984ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_momentum.csv', 'factor_momentum_zscore.csv', 'factor_momentum_large_industry.csv', 'factor_momentum_medium_industry.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 5: Momentum 전략 =====\n",
    "# 지난 12-1개월 수익률 계산 (직전 1개월은 제외)\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = monthly_merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = monthly_merged_df.loc[:, price_mask]\n",
    "price_df.columns = price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 타입 변환\n",
    "price_df = price_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "price_df = price_df.sort_index()\n",
    "\n",
    "# 결측치 처리\n",
    "price_df = price_df.fillna(method='ffill')\n",
    "\n",
    "# 12개월 전 가격과 1개월 전 가격 추출\n",
    "price_12m_ago = price_df.shift(12)\n",
    "price_1m_ago = price_df.shift(1)\n",
    "\n",
    "# 모멘텀 계산\n",
    "momentum_df = (price_1m_ago - price_12m_ago) / price_12m_ago\n",
    "\n",
    "# 결측치 처리\n",
    "momentum_df = momentum_df.replace([np.inf, -np.inf], np.nan)\n",
    "momentum_df = momentum_df.fillna(method='ffill')\n",
    "\n",
    "# 전체 종목에 대해 z-score 계산\n",
    "momentum_zscore = momentum_df.apply(lambda x: (x - x.mean()) / x.std(), axis=1)\n",
    "\n",
    "# 산업 분류 데이터 불러오기 (이미 불러온 industry_df 사용)\n",
    "# '한국표준산업분류11차(대분류)', '한국표준산업분류11차(중분류)' 데이터 추출\n",
    "industry_large_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(대분류)'\n",
    "industry_medium_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(중분류)'\n",
    "\n",
    "industry_large_df = industry_df.loc[:, industry_large_mask]\n",
    "industry_large_df.columns = industry_large_df.columns.droplevel(['item', 'item Name'])\n",
    "industry_medium_df = industry_df.loc[:, industry_medium_mask]\n",
    "industry_medium_df.columns = industry_medium_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 산업별로 z-score 계산 함수 재사용\n",
    "def industry_zscore(momentum_series, industry_series):\n",
    "    df = pd.DataFrame({'Momentum': momentum_series, 'Industry': industry_series})\n",
    "    return df.groupby('Industry')['Momentum'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# 대분류 산업별 z-score\n",
    "momentum_zscore_large = momentum_df.copy()\n",
    "for date in momentum_zscore_large.index:\n",
    "    momentum_zscore_large.loc[date] = industry_zscore(momentum_df.loc[date], industry_large_df.loc[date])\n",
    "\n",
    "# 중분류 산업별 z-score\n",
    "momentum_zscore_medium = momentum_df.copy()\n",
    "for date in momentum_zscore_medium.index:\n",
    "    momentum_zscore_medium.loc[date] = industry_zscore(momentum_df.loc[date], industry_medium_df.loc[date])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "# 원래의 컬럼 정보를 사용하여 멀티인덱스 생성\n",
    "momentum_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum', 'Momentum') for symbol, symbol_name in momentum_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_zscore', 'Momentum_zscore') for symbol, symbol_name in momentum_zscore.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore_large.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_large', 'Momentum_large') for symbol, symbol_name in momentum_zscore_large.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore_medium.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_medium', 'Momentum_medium') for symbol, symbol_name in momentum_zscore_medium.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "momentum_df.to_csv('factor_momentum.csv', encoding='utf-8-sig')\n",
    "momentum_zscore.to_csv('factor_momentum_zscore.csv', encoding='utf-8-sig')\n",
    "momentum_zscore_large.to_csv('factor_momentum_large_industry.csv', encoding='utf-8-sig')\n",
    "momentum_zscore_medium.to_csv('factor_momentum_medium_industry.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(\"'factor_momentum.csv', 'factor_momentum_zscore.csv', 'factor_momentum_large_industry.csv', 'factor_momentum_medium_industry.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f0bebdf-f11c-4477-9e8a-e2385681d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_retained_earnings.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 6: Retained Earnings and Market-to-Book =====\n",
    "# 이익잉여금(원) / 시가총액 계산\n",
    "\n",
    "# '이익잉여금(원)' 데이터 추출\n",
    "retained_earnings_mask = monthly_merged_df.columns.get_level_values('item Name') == '이익잉여금(원)'\n",
    "retained_earnings_df = monthly_merged_df.loc[:, retained_earnings_mask]\n",
    "\n",
    "# '시가총액 (평균)(원)' 데이터 추출\n",
    "market_cap_mask = monthly_merged_df.columns.get_level_values('item Name') == '시가총액 (평균)(원)'\n",
    "market_cap_df = monthly_merged_df.loc[:, market_cap_mask]\n",
    "\n",
    "# 컬럼 레벨 중 'item'과 'item Name'을 제거하여 컬럼 정렬\n",
    "retained_earnings_df.columns = retained_earnings_df.columns.droplevel(['item', 'item Name'])\n",
    "market_cap_df.columns = market_cap_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "retained_earnings_df, market_cap_df = retained_earnings_df.align(market_cap_df, join='inner', axis=0)\n",
    "retained_earnings_df, market_cap_df = retained_earnings_df.align(market_cap_df, join='inner', axis=1)\n",
    "\n",
    "# 데이터 타입 변환\n",
    "retained_earnings_df = retained_earnings_df.apply(pd.to_numeric, errors='coerce')\n",
    "market_cap_df = market_cap_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 이익잉여금 / 시가총액 계산\n",
    "re_mc_ratio_df = retained_earnings_df / market_cap_df\n",
    "\n",
    "# 결측치 처리\n",
    "re_mc_ratio_df = re_mc_ratio_df.replace([np.inf, -np.inf], np.nan)\n",
    "re_mc_ratio_df = re_mc_ratio_df.fillna(method='ffill')\n",
    "\n",
    "# 멀티레벨 컬럼 구조 재설정\n",
    "re_mc_ratio_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'RE/MC Ratio', 'RE/MC Ratio') for symbol, symbol_name in re_mc_ratio_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "re_mc_ratio_df.to_csv('factor_retained_earnings.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_retained_earnings.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec265dd-fffe-4dda-a358-760292967329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 종목 수: 2068\n",
      "필터링된 종목 수: 2067\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 10: Betting Against Beta =====\n",
    "# 베타를 직접 계산하여 역수를 팩터 값으로 사용\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 전처리된 월별 데이터에서 종목 리스트와 기간 추출\n",
    "symbols = monthly_merged_df.columns.get_level_values('Symbol').unique()\n",
    "dates = monthly_merged_df.index.unique()\n",
    "\n",
    "# 각 종목별로 시작 날짜 추출\n",
    "symbol_start_dates = {}\n",
    "for symbol in symbols:\n",
    "    # 해당 종목의 컬럼 선택\n",
    "    symbol_cols = monthly_merged_df.loc[:, monthly_merged_df.columns.get_level_values('Symbol') == symbol]\n",
    "    # 해당 종목의 데이터가 있는 날짜 추출\n",
    "    symbol_data = symbol_cols.dropna(how='all')\n",
    "    # 데이터가 있는 경우\n",
    "    if not symbol_data.empty:\n",
    "        start_date = symbol_data.index.min()\n",
    "        # 시작 날짜에서 30일을 뺌\n",
    "        adjusted_start_date = start_date - pd.Timedelta(days=30)\n",
    "        # daily_df의 시작 날짜와 비교하여 실제 시작 날짜 결정\n",
    "        symbol_start_dates[symbol] = adjusted_start_date\n",
    "    else:\n",
    "        # 데이터가 없는 경우 최소 날짜 설정\n",
    "        symbol_start_dates[symbol] = pd.to_datetime('2007-10-31')  # 필요에 따라 최소 날짜 설정\n",
    "\n",
    "print(f\"전처리된 종목 수: {len(symbols)}\")\n",
    "\n",
    "# 2. 일별 데이터 로드 (data/KSIF_1.csv 파일)\n",
    "file_path = 'data/KSIF_1.csv'\n",
    "\n",
    "try:\n",
    "    daily_df = pd.read_csv(\n",
    "        file_path,\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='cp949',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    daily_df = pd.read_csv(\n",
    "        file_path,\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='euc-kr',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"파일 {file_path}를 로드하는 중 에러 발생: {e}\")\n",
    "    raise e  # 에러 발생 시 종료\n",
    "\n",
    "# 멀티인덱스 컬럼 이름 지정\n",
    "daily_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "daily_df.index.name = 'Date'\n",
    "\n",
    "# 'Kind', 'Frequency' 레벨 제거\n",
    "daily_df.columns = daily_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "# 필요한 종목(Symbol)만 선택\n",
    "symbol_mask = daily_df.columns.get_level_values('Symbol').isin(symbols)\n",
    "daily_df = daily_df.loc[:, symbol_mask]\n",
    "\n",
    "print(f\"필터링된 종목 수: {len(daily_df.columns.get_level_values('Symbol').unique())}\")\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = daily_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "daily_price_df = daily_df.loc[:, price_mask]\n",
    "daily_price_df.columns = daily_price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "daily_price_df = (\n",
    "    daily_price_df\n",
    "    .astype(str)  # 모든 데이터를 문자열로 변환\n",
    "    .replace(',', '', regex=True)  # 쉼표 제거\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)  # 비정상적인 값들을 NaN으로 변환\n",
    "    .apply(pd.to_numeric, errors='coerce')  # 숫자로 변환 (변환 불가 시 NaN)\n",
    ")\n",
    "\n",
    "# 데이터 타입 확인\n",
    "print(\"일별 가격 데이터 타입 확인:\")\n",
    "print(daily_price_df.dtypes.unique())\n",
    "\n",
    "# 종목별 일별 수익률 계산\n",
    "daily_returns_dict = {}\n",
    "for symbol in symbols:\n",
    "    if symbol in daily_price_df.columns:\n",
    "        symbol_price = daily_price_df[symbol]\n",
    "        if not symbol_price.empty:\n",
    "            # 해당 종목의 시작 날짜 계산\n",
    "            start_date = symbol_start_dates[symbol]\n",
    "            # 시작 날짜부터 데이터 선택\n",
    "            symbol_price = symbol_price.loc[start_date:]\n",
    "            # 수익률 계산\n",
    "            symbol_returns = symbol_price.pct_change().dropna()\n",
    "            daily_returns_dict[symbol] = symbol_returns\n",
    "        else:\n",
    "            # 해당 종목의 데이터가 없는 경우\n",
    "            daily_returns_dict[symbol] = pd.Series(dtype=float)\n",
    "    else:\n",
    "        daily_returns_dict[symbol] = pd.Series(dtype=float)\n",
    "\n",
    "print(f\"일별 수익률 계산 완료. 종목 수: {len(daily_returns_dict)}\")\n",
    "\n",
    "# 시장 수익률 계산 (종가지수(포인트) 기반)\n",
    "try:\n",
    "    market_df = pd.read_csv(\n",
    "        'data/kor_market.csv',\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='cp949',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    market_df = pd.read_csv(\n",
    "        'data/kor_market.csv',\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='euc-kr',\n",
    "        parse_dates=True\n",
    "    )\n",
    "\n",
    "# 멀티인덱스 컬럼 이름 지정\n",
    "market_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "market_df.index.name = 'Date'\n",
    "\n",
    "# 'Kind', 'Frequency' 레벨 제거\n",
    "market_df.columns = market_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "# '종가지수(포인트)' 데이터 추출\n",
    "index_mask = market_df.columns.get_level_values('item Name') == '종가지수(포인트)'\n",
    "index_df = market_df.loc[:, index_mask]\n",
    "\n",
    "# '코스피'와 '코스닥' 지수만 선택\n",
    "symbol_names = index_df.columns.get_level_values('Symbol Name')\n",
    "kospi_kosdaq_mask = (symbol_names == '코스피') | (symbol_names == '코스닥')\n",
    "kospi_kosdaq_indices = index_df.loc[:, kospi_kosdaq_mask]\n",
    "kospi_kosdaq_indices.columns = kospi_kosdaq_indices.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "kospi_kosdaq_indices = (\n",
    "    kospi_kosdaq_indices\n",
    "    .astype(str)\n",
    "    .replace(',', '', regex=True)\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)\n",
    "    .apply(pd.to_numeric, errors='coerce')\n",
    ")\n",
    "\n",
    "# 코스피와 코스닥 지수의 일별 수익률 계산\n",
    "market_returns = kospi_kosdaq_indices.mean(axis=1).pct_change().dropna()\n",
    "\n",
    "# 시장 수익률 데이터 기간 확인\n",
    "print(f\"시장 수익률 데이터 기간: {market_returns.index.min()} ~ {market_returns.index.max()}\")\n",
    "\n",
    "# 3. 베타 계산 함수 정의 및 계산\n",
    "def calculate_beta(stock_returns, market_returns, window=365):\n",
    "    # 결측치 제거\n",
    "    combined = pd.concat([stock_returns, market_returns], axis=1).dropna()\n",
    "    if len(combined) < 30:\n",
    "        return np.nan\n",
    "    else:\n",
    "        stock_ret = combined.iloc[:, 0]\n",
    "        market_ret = combined.iloc[:, 1]\n",
    "        cov = stock_ret.cov(market_ret)\n",
    "        var = market_ret.var()\n",
    "        beta = cov / var if var != 0 else np.nan\n",
    "        return beta\n",
    "\n",
    "# 베타 값을 저장할 데이터프레임 생성\n",
    "beta_df = pd.DataFrame(index=dates, columns=symbols)\n",
    "\n",
    "for date in tqdm(dates, desc='베타 계산 중'):\n",
    "    for symbol in symbols:\n",
    "        # 해당 종목의 일별 수익률 시리즈\n",
    "        stock_returns = daily_returns_dict[symbol]\n",
    "        # 해당 날짜까지의 데이터 사용\n",
    "        stock_returns = stock_returns[stock_returns.index <= date]\n",
    "        market_returns_up_to_date = market_returns[market_returns.index <= date]\n",
    "        # 최근 window 기간의 데이터 추출\n",
    "        stock_returns = stock_returns.iloc[-365:]\n",
    "        market_returns_up_to_date = market_returns_up_to_date.iloc[-365:]\n",
    "        # 베타 계산\n",
    "        beta = calculate_beta(stock_returns, market_returns_up_to_date)\n",
    "        beta_df.at[date, symbol] = beta\n",
    "\n",
    "# 베타의 역수를 팩터 값으로 사용\n",
    "inv_beta_df = 1 / beta_df.astype(float)\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "inv_beta_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, monthly_merged_df.columns.get_level_values('Symbol Name')[monthly_merged_df.columns.get_level_values('Symbol') == symbol][0], 'Inverse Beta', 'Inverse Beta') for symbol in inv_beta_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "inv_beta_df.index.name = 'Date'\n",
    "\n",
    "# 팩터 값 저장\n",
    "inv_beta_df.to_csv('factor_betting_against_beta.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(\"'factor_betting_against_beta.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96caf0fc-2d5c-445e-be7d-6d5bee346662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: factor_high_pe_ratio.csv\n",
      "  Loaded successfully. Shape: (206, 2067)\n",
      "  Max Missing Date: 2008-01-31 00:00:00\n",
      "  Max Missing Count: 1544\n",
      "  Total Columns: 2067\n",
      "  Max Missing Ratio (%): 74.70%\n",
      "Processing file: factor_high_pe_ratio_large_industry.csv\n",
      "  Error processing file factor_high_pe_ratio_large_industry.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_high_pe_ratio_medium_industry.csv\n",
      "  Error processing file factor_high_pe_ratio_medium_industry.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_hml.csv\n",
      "  Error processing file factor_hml.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_momentum.csv\n",
      "  Error processing file factor_momentum.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_retained_earnings.csv\n",
      "  Error processing file factor_retained_earnings.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_betting_against_beta.csv\n",
      "  Loaded successfully. Shape: (426005, 5)\n",
      "  Max Missing Date: 2008-01-31 00:00:00\n",
      "  Max Missing Count: 1\n",
      "  Total Columns: 5\n",
      "  Max Missing Ratio (%): 20.00%\n",
      "\n",
      "===== Missing Data Summary =====\n",
      "                       Factor File Max Missing Date  Max Missing Count  \\\n",
      "0         factor_high_pe_ratio.csv       2008-01-31               1544   \n",
      "1  factor_betting_against_beta.csv       2008-01-31                  1   \n",
      "\n",
      "   Total Columns  Max Missing Ratio (%)  \n",
      "0           2067              74.697629  \n",
      "1              5              20.000000  \n",
      "\n",
      "결측치 분석 결과가 'factor_missing_data_summary.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "#계산한 팩터값에 결측치 확인\n",
    "import pandas as pd\n",
    "\n",
    "# ===== 팩터 값 CSV 확인 및 결측치 분석 =====\n",
    "\n",
    "# 저장된 팩터 값 CSV 파일 목록\n",
    "factor_files = [\n",
    "    'factor_high_pe_ratio.csv',\n",
    "    'factor_high_pe_ratio_large_industry.csv',\n",
    "    'factor_high_pe_ratio_medium_industry.csv',\n",
    "    'factor_hml.csv',\n",
    "    'factor_momentum.csv',\n",
    "    'factor_retained_earnings.csv',\n",
    "    'factor_betting_against_beta.csv'\n",
    "]\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "missing_data_summary = []\n",
    "\n",
    "for file in factor_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    try:\n",
    "        # CSV 파일 로드\n",
    "        factor_df = pd.read_csv(file, \n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "        )\n",
    "\n",
    "        # 멀티인덱스 설정\n",
    "        factor_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "        factor_df.index.name = 'Date'\n",
    "        \n",
    "        print(f\"  Loaded successfully. Shape: {factor_df.shape}\")\n",
    "        \n",
    "        # 2008년 이후 데이터만 필터링\n",
    "        factor_df = factor_df.loc[factor_df.index >= '2008-01-01']\n",
    "        \n",
    "        # 결측치 분석\n",
    "        missing_summary = factor_df.isna().sum(axis=1)  # 각 날짜별 결측치 수\n",
    "        total_columns = factor_df.shape[1]  # 전체 컬럼 수\n",
    "        \n",
    "        # 가장 결측치가 많은 날짜와 해당 날짜의 결측치 비율\n",
    "        max_missing_date = missing_summary.idxmax()\n",
    "        max_missing_count = missing_summary.max()\n",
    "        max_missing_ratio = (max_missing_count / total_columns) * 100  # 결측치 비율\n",
    "        \n",
    "        # 결측치 요약 추가\n",
    "        missing_data_summary.append({\n",
    "            'Factor File': file,\n",
    "            'Max Missing Date': max_missing_date,\n",
    "            'Max Missing Count': max_missing_count,\n",
    "            'Total Columns': total_columns,\n",
    "            'Max Missing Ratio (%)': max_missing_ratio\n",
    "        })\n",
    "        \n",
    "        print(f\"  Max Missing Date: {max_missing_date}\")\n",
    "        print(f\"  Max Missing Count: {max_missing_count}\")\n",
    "        print(f\"  Total Columns: {total_columns}\")\n",
    "        print(f\"  Max Missing Ratio (%): {max_missing_ratio:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing file {file}: {e}\")\n",
    "\n",
    "# 결측치 분석 결과 DataFrame 생성\n",
    "missing_summary_df = pd.DataFrame(missing_data_summary)\n",
    "\n",
    "# 결측치 분석 결과 출력\n",
    "print(\"\\n===== Missing Data Summary =====\")\n",
    "print(missing_summary_df)\n",
    "\n",
    "# 결측치 분석 결과 저장\n",
    "missing_summary_df.to_csv('factor_missing_data_summary.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n결측치 분석 결과가 'factor_missing_data_summary.csv' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea0115-500f-4531-8c1c-bca6231d31c1",
   "metadata": {},
   "source": [
    "# 백테스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c477390-2308-4cae-b45a-ac661a5f9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(factor_csv, merged_df, rebalancing_period=1, long_only=True, threshold=0.2, cutoff=0.0, reversal=False, weighting_method='equal'):\n",
    "    \"\"\"\n",
    "    백테스팅 함수를 구현합니다.\n",
    "\n",
    "    Parameters:\n",
    "    - factor_csv (str): 팩터값 CSV 파일의 경로\n",
    "    - merged_df (pd.DataFrame): 수익률 데이터가 포함된 데이터프레임\n",
    "    - rebalancing_period (int): 리밸런싱 주기 (1, 3, 6, 12 중 하나)\n",
    "    - long_only (bool): 롱 온리 전략 여부\n",
    "    - threshold (float): 포지션을 취할 상위/하위 퍼센트 (0 < threshold <= 1)\n",
    "    - cutoff (float): 포지션을 취할 시작 퍼센트 (0 <= cutoff < threshold)\n",
    "    - reversal (bool): 전략을 반대로 적용할지 여부\n",
    "    - weighting_method (str): 'equal' 또는 'value' 중 하나로, 동일가중 또는 가치가중을 결정\n",
    "\n",
    "    Returns:\n",
    "    - results_df (pd.DataFrame): 월별 포트폴리오 변동과 포지션을 포함한 데이터프레임\n",
    "    \"\"\"\n",
    "    # 팩터 데이터 불러오기\n",
    "    factor_df = pd.read_csv(factor_csv, index_col=0, parse_dates=True)\n",
    "    factor_df.index.name = 'Date'\n",
    "\n",
    "    # 월말 기준으로 데이터 정렬\n",
    "    factor_df = factor_df.resample('M').last()\n",
    "    merged_df = merged_df.resample('M').last()\n",
    "\n",
    "    # 수익률 데이터 추출 ('1개월 수익률(계산)')\n",
    "    returns_mask = merged_df.columns.get_level_values('item Name') == '1개월 수익률(계산)'\n",
    "    returns_df = merged_df.loc[:, returns_mask]\n",
    "    returns_df.columns = returns_df.columns.droplevel(['item', 'item Name'])\n",
    "    returns_df.columns.names = ['Symbol', 'Symbol Name']\n",
    "\n",
    "    # 팩터 데이터와 수익률 데이터의 공통 부분만 사용\n",
    "    common_symbols = factor_df.columns.intersection(returns_df.columns.get_level_values('Symbol'))\n",
    "    factor_df = factor_df[common_symbols]\n",
    "    returns_df = returns_df.loc[:, returns_df.columns.get_level_values('Symbol').isin(common_symbols)]\n",
    "\n",
    "    # 팩터 데이터와 수익률 데이터를 날짜와 심볼로 정렬\n",
    "    factor_df = factor_df.sort_index().sort_index(axis=1)\n",
    "    returns_df = returns_df.sort_index().sort_index(axis=1)\n",
    "\n",
    "    # 리밸런싱 날짜 설정\n",
    "    rebalancing_dates = factor_df.index[::rebalancing_period]\n",
    "\n",
    "    # 포트폴리오 초기화\n",
    "    portfolio = pd.DataFrame(index=returns_df.index, columns=['Portfolio Value', 'Monthly Return'])\n",
    "    portfolio['Portfolio Value'] = 1.0  # 초기 투자금 1로 설정\n",
    "\n",
    "    # 각 월별 보유 종목 정보 저장을 위한 딕셔너리\n",
    "    positions = {}\n",
    "\n",
    "    # 백테스트 진행\n",
    "    for i, date in enumerate(returns_df.index):\n",
    "        # 리밸런싱 시점인지 확인\n",
    "        if date in rebalancing_dates:\n",
    "            # 리밸런싱 날짜에서는 이전 포지션을 종료하고 새로운 포지션을 설정\n",
    "            factor = factor_df.loc[date].dropna()\n",
    "\n",
    "            # 팩터 값에 따라 종목 선택\n",
    "            num_assets = len(factor)\n",
    "            num_selected = int(num_assets * threshold)\n",
    "            num_cutoff = int(num_assets * cutoff)\n",
    "\n",
    "            if long_only:\n",
    "                # 상위 cutoff% ~ threshold% 종목을 롱\n",
    "                if reversal:\n",
    "                    # 하위 cutoff% ~ threshold% 종목을 롱\n",
    "                    selected_symbols = factor.nsmallest(num_selected).iloc[num_cutoff:].index\n",
    "                else:\n",
    "                    selected_symbols = factor.nlargest(num_selected).iloc[num_cutoff:].index\n",
    "\n",
    "                if weighting_method == 'equal':\n",
    "                    weights = pd.Series(1.0 / len(selected_symbols), index=selected_symbols)\n",
    "                elif weighting_method == 'value':\n",
    "                    weights = factor[selected_symbols] / factor[selected_symbols].sum()\n",
    "                else:\n",
    "                    raise ValueError(\"weighting_method must be 'equal' or 'value'\")\n",
    "            else:\n",
    "                # 롱숏 전략\n",
    "                if reversal:\n",
    "                    # 하위 cutoff% ~ threshold% 종목을 롱, 상위 cutoff% ~ threshold% 종목을 숏\n",
    "                    long_symbols = factor.nsmallest(num_selected).iloc[num_cutoff:].index\n",
    "                    short_symbols = factor.nlargest(num_selected).iloc[num_cutoff:].index\n",
    "                else:\n",
    "                    # 상위 cutoff% ~ threshold% 종목을 롱, 하위 cutoff% ~ threshold% 종목을 숏\n",
    "                    long_symbols = factor.nlargest(num_selected).iloc[num_cutoff:].index\n",
    "                    short_symbols = factor.nsmallest(num_selected).iloc[num_cutoff:].index\n",
    "\n",
    "                if weighting_method == 'equal':\n",
    "                    long_weights = pd.Series(1.0 / len(long_symbols), index=long_symbols)\n",
    "                    short_weights = pd.Series(-1.0 / len(short_symbols), index=short_symbols)\n",
    "                elif weighting_method == 'value':\n",
    "                    long_weights = factor[long_symbols] / factor[long_symbols].sum()\n",
    "                    short_weights = -factor[short_symbols] / factor[short_symbols].sum()\n",
    "                else:\n",
    "                    raise ValueError(\"weighting_method must be 'equal' or 'value'\")\n",
    "\n",
    "                weights = pd.concat([long_weights, short_weights])\n",
    "\n",
    "            # 현재 포지션 저장\n",
    "            positions[date] = weights\n",
    "\n",
    "        # 수익률 계산 시 선견편향 방지: 이전 포지션에 해당하는 수익률 사용\n",
    "        if i > 0:\n",
    "            prev_date = returns_df.index[i - 1]\n",
    "            if prev_date in positions:\n",
    "                weights = positions[prev_date]\n",
    "                # 해당 월의 수익률 계산\n",
    "                returns = returns_df.loc[date, returns_df.columns.get_level_values('Symbol').isin(weights.index)]\n",
    "                returns.index = returns.index.get_level_values('Symbol')\n",
    "                aligned_weights = weights.reindex(returns.index).fillna(0)\n",
    "                portfolio_return = (aligned_weights * returns).sum()\n",
    "            else:\n",
    "                # 포지션이 없으면 수익률 0\n",
    "                portfolio_return = 0\n",
    "            # 포트폴리오 가치 업데이트\n",
    "            portfolio.loc[date, 'Monthly Return'] = portfolio_return\n",
    "            portfolio.loc[date, 'Portfolio Value'] = portfolio.iloc[i - 1]['Portfolio Value'] * (1 + portfolio_return)\n",
    "        else:\n",
    "            # 첫 번째 기간은 수익률 계산하지 않음\n",
    "            portfolio.loc[date, 'Monthly Return'] = 0\n",
    "\n",
    "    # 포지션 정보를 데이터프레임으로 변환\n",
    "    positions_df = pd.DataFrame.from_dict(positions, orient='index')\n",
    "\n",
    "    # 결과 합치기\n",
    "    results_df = portfolio.join(positions_df, how='left')\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c8d6e6-b4df-4022-8590-96bbd4a21f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from causalnex.structure import StructureModel\n",
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
    "from IPython.display import Image\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'A': np.random.randint(0, 2, 1000),\n",
    "    'B': np.random.randint(0, 2, 1000),\n",
    "    'C': np.random.randint(0, 2, 1000),\n",
    "    'D': np.random.randint(0, 2, 1000)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b88c3db1-244d-4077-87ed-7c2316c55ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.structure.notears import from_pandas\n",
    "\n",
    "# 데이터로부터 구조 학습\n",
    "sm = from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8899f98-a55c-4551-9c54-7b37059e494a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The given structure is not acyclic. Please review the following cycle: [('treatment', 'feature'), ('feature', 'treatment')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 인과 구조 학습 및 베이지안 네트워크 구축\u001b[39;00m\n\u001b[0;32m     19\u001b[0m sm \u001b[38;5;241m=\u001b[39m from_pandas(data)\n\u001b[1;32m---> 20\u001b[0m bn \u001b[38;5;241m=\u001b[39m \u001b[43mBayesianNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43msm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m bn \u001b[38;5;241m=\u001b[39m bn\u001b[38;5;241m.\u001b[39mfit_node_states_and_cpds(data)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# PyTorch 모델 설계\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\causalnex_env\\lib\\site-packages\\causalnex\\network\\network.py:138\u001b[0m, in \u001b[0;36mBayesianNetwork.__init__\u001b[1;34m(self, structure)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mis_directed_acyclic_graph(structure):\n\u001b[0;32m    137\u001b[0m     cycle \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mfind_cycle(structure)\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe given structure is not acyclic. Please review the following cycle: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcycle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# _node_states is a Dict in the form `dict: {node: dict: {state: index}}`.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Underlying libraries expect all states to be integers from zero, and\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# thus this dict is used to convert from state -> idx, and then back from idx -> state as required\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_states \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# type: Dict[str: Dict[Hashable, int]]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The given structure is not acyclic. Please review the following cycle: [('treatment', 'feature'), ('feature', 'treatment')]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from causalnex.structure.notears import from_pandas\n",
    "from causalnex.network import BayesianNetwork\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'treatment': np.random.binomial(1, 0.5, 1000),   # 예: 처치 여부 (0 또는 1)\n",
    "    'feature': np.random.normal(0, 1, 1000),         # 예: 피처 변수\n",
    "    'outcome': np.random.normal(0, 1, 1000)          # 예: 결과 변수\n",
    "})\n",
    "\n",
    "# 인과 구조 학습 및 베이지안 네트워크 구축\n",
    "sm = from_pandas(data)\n",
    "bn = BayesianNetwork(sm)\n",
    "bn = bn.fit_node_states_and_cpds(data)\n",
    "\n",
    "# PyTorch 모델 설계\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 16)  # 입력 노드 수는 처치 변수와 피처 변수\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)   # 출력 노드는 outcome 값 예측\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 데이터를 PyTorch 텐서로 변환\n",
    "X = torch.tensor(data[['treatment', 'feature']].values, dtype=torch.float32)\n",
    "y = torch.tensor(data['outcome'].values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 데이터셋과 데이터로더 준비\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 모델 초기화\n",
    "model = SimpleNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_X)\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 개입 시나리오: 처치를 적용했을 때와 적용하지 않았을 때의 예측 비교\n",
    "with_treatment = torch.tensor([[1, 0.5]], dtype=torch.float32)  # 처치 적용 예시\n",
    "without_treatment = torch.tensor([[0, 0.5]], dtype=torch.float32)  # 처치 미적용 예시\n",
    "\n",
    "outcome_with_treatment = model(with_treatment)\n",
    "outcome_without_treatment = model(without_treatment)\n",
    "\n",
    "print(f\"\\n처치 적용 시 예상 'outcome': {outcome_with_treatment.item():.4f}\")\n",
    "print(f\"처치 미적용 시 예상 'outcome': {outcome_without_treatment.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbeccd-51fa-4526-8dc7-94bba7788e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (causalnex_env)",
   "language": "python",
   "name": "causalnex_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
