{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec2d55bc-9ba2-4a01-9351-81aff784df0c",
   "metadata": {},
   "source": [
    "- 시작 하기 전에\n",
    "\n",
    "처음부터 전부 작동시키면 하루정도 걸려야 다 돌아가니 가급적 제가드린 데이터파일(중간 세이브 파일 개념)을 사용해주세요.\n",
    "\n",
    "밑바닥부터 다 돌려보고 싶다면 dataguide에서 데이터 받아서 돌리시면 됩니다만 권장하진 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64657c3-f098-4eab-9c40-bf899ba7b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import hotshot as hs\n",
    "# import networkx as nx  # networkx 임포트\n",
    "# from causalnex.structure.notears import from_pandas\n",
    "# from causalnex.network import BayesianNetwork\n",
    "# from econml.dr import DRLearner\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 팩터 전략별로 필요한 데이터를 계산하여 monthly_merged_df에 추가합니다.\n",
    "\n",
    "if 'monthly_merged_df' not in globals():\n",
    "    monthly_merged_df = pd.read_csv(\n",
    "        'data/merged_df_monthly_preprocessing.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6328d54-d6a3-419b-9a36-a97435953b07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CSV 부르기 및 기본적인 전처리 : 돌릴 필요 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa522af-a990-4a33-b348-445c51e6c468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 통합한 월별 데이터 파일이 존재합니다. 해당 CSV를 불러옵니다.\n",
      "월별 CSV를 불러왔습니다.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame을 저장할 리스트 생성\n",
    "df_list = []\n",
    "\n",
    "# 1. 'data' 폴더 내에 'KSIF'가 포함된 CSV 파일 목록 가져오기\n",
    "file_list = glob.glob('data/*KSIF*.csv')\n",
    "\n",
    "# 파일이 존재하는지 확인\n",
    "if not file_list:\n",
    "    print(\"패턴에 맞는 파일을 찾을 수 없습니다.\")\n",
    "elif os.path.exists('data/merged_df_monthly.csv'):\n",
    "    print(\"이미 통합한 월별 데이터 파일이 존재합니다. 해당 CSV를 불러옵니다.\")\n",
    "    merged_df_backup = pd.read_csv(\n",
    "        'data/merged_df_monthly.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "        parse_dates=True  # 인덱스를 datetime으로 파싱\n",
    "    )\n",
    "    print(\"월별 CSV를 불러왔습니다.\")\n",
    "elif os.path.exists('data/merged_data.csv'):\n",
    "    print(\"이미 통합한 일별 데이터 파일이 존재합니다. 해당 CSV를 월별로 전환합니다.\")\n",
    "    merged_df_backup = pd.read_csv(\n",
    "        'data/merged_data.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "    # 인덱스를 datetime으로 변환\n",
    "    merged_df_backup.index = pd.to_datetime(merged_df_backup.index, errors='coerce')\n",
    "    \n",
    "    # 월별 리샘플링\n",
    "    merged_df_backup = merged_df_backup.resample('M').last()\n",
    "    \n",
    "    # 월별 데이터 저장\n",
    "    merged_df_backup.to_csv('data/merged_df_monthly.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"월별 리샘플링된 데이터가 'merged_df_monthly.csv'로 저장되었습니다.\")\n",
    "    print(\"월별 CSV를 불러왔습니다.\")\n",
    "else:\n",
    "    # tqdm을 사용하여 진행 상황 표시\n",
    "    for file_path in tqdm(file_list, desc=\"파일 처리 중\"):\n",
    "        # 각 CSV 파일 읽기 (적절한 인코딩과 인덱스 설정)\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                skiprows=8,\n",
    "                header=[0, 1, 2, 3, 4, 5],\n",
    "                index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "                encoding='cp949',\n",
    "                parse_dates=True\n",
    "            )\n",
    "        except UnicodeDecodeError:\n",
    "            # 'cp949' 인코딩이 안 될 경우 'euc-kr'로 시도\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                skiprows=8,\n",
    "                header=[0, 1, 2, 3, 4, 5],\n",
    "                index_col=0,\n",
    "                encoding='euc-kr',\n",
    "                parse_dates=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"파일 {file_path}를 로드하는 중 에러 발생: {e}\")\n",
    "            continue  # 에러 발생 시 다음 파일로 넘어감\n",
    "        \n",
    "        # 멀티인덱스 컬럼에 이름 지정\n",
    "        df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "        \n",
    "        # 인덱스 이름 지정 ('Date'로 설정)\n",
    "        df.index.name = 'Date'\n",
    "        \n",
    "        # 인덱스를 datetime으로 변환\n",
    "        df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "        \n",
    "        # 'Kind', 'Frequency' 레벨 제거하여 필요한 컬럼만 남김\n",
    "        df.columns = df.columns.droplevel(['Kind', 'Frequency'])\n",
    "        \n",
    "        # 리스트에 DataFrame 추가\n",
    "        df_list.append(df)\n",
    "    \n",
    "    # 2. 모든 DataFrame을 수평적으로 병합\n",
    "    print(\"DataFrame 병합 중...\")\n",
    "    merged_df_backup = pd.concat(df_list, axis=1)\n",
    "    del df_list  # 리스트 메모리에서 삭제\n",
    "    gc.collect()  # 가비지 컬렉션 실행\n",
    "    \n",
    "    # 월별 리샘플링\n",
    "    print(\"월별 리샘플링 중...\")\n",
    "    merged_df_backup = merged_df_backup.resample('M').last()\n",
    "    \n",
    "    # 월별 데이터 저장\n",
    "    merged_df_backup.to_csv('data/merged_df_monthly.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"월별 리샘플링된 데이터가 'merged_df_monthly.csv'로 저장되었습니다.\")\n",
    "    \n",
    "    # 필요에 따라 일별 데이터를 저장하려면 아래 주석을 해제하세요.\n",
    "    # merged_df_backup.to_csv('data/merged_data.csv', encoding='utf-8-sig')\n",
    "    # print(\"모든 CSV 파일을 병합하여 'merged_data.csv'로 저장했습니다.\")\n",
    "\n",
    "    # 메모리 관리\n",
    "    del merged_df_backup\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993372a2-821d-46b6-b494-f828a95d8281",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m issues\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 점검 실행\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mcheck_dataframe_issues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#여기서 인덱스 2번이 뜨는 이유는 얘가 하루 더 있거등요 ㅇㅇ\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mcheck_dataframe_issues\u001b[1;34m(df_list)\u001b[0m\n\u001b[0;32m     10\u001b[0m issues \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_unique_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmismatched_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 기준 인덱스는 첫 번째 데이터프레임의 인덱스로 설정\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m base_index \u001b[38;5;241m=\u001b[39m \u001b[43mdf_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 각 데이터프레임 점검\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_list):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 1. 고유하지 않은 인덱스 확인\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def check_dataframe_issues(df_list):\n",
    "    \"\"\"\n",
    "    점검 함수: 데이터프레임 리스트에서 고유하지 않은 인덱스와 기준 인덱스 불일치 확인\n",
    "    Args:\n",
    "        df_list (list): pandas 데이터프레임들의 리스트\n",
    "    Returns:\n",
    "        dict: 문제를 가진 데이터프레임의 인덱스 (non_unique_index, mismatched_index)\n",
    "    \"\"\"\n",
    "    # 결과 저장용 딕셔너리\n",
    "    issues = {\"non_unique_index\": [], \"mismatched_index\": []}\n",
    "    \n",
    "    # 기준 인덱스는 첫 번째 데이터프레임의 인덱스로 설정\n",
    "    base_index = df_list[0].index\n",
    "\n",
    "    # 각 데이터프레임 점검\n",
    "    for i, df in enumerate(df_list):\n",
    "        # 1. 고유하지 않은 인덱스 확인\n",
    "        if not df.index.is_unique:\n",
    "            issues[\"non_unique_index\"].append(i)\n",
    "        \n",
    "        # 2. 기준 인덱스와 불일치 확인\n",
    "        if not base_index.equals(df.index):\n",
    "            issues[\"mismatched_index\"].append(i)\n",
    "\n",
    "    return issues\n",
    "\n",
    "# 점검 실행\n",
    "check_dataframe_issues(df_list)#여기서 인덱스 2번이 뜨는 이유는 얘가 하루 더 있거등요 ㅇㅇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f466bdd7-d688-49ec-8d17-d66b687424ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['수정주가(원)', 'PER(보통)(배)', 'PER(직전4분기)(배)', 'PER(보통,자사주차감)(배)',\n",
       "       'BPS(발표기준기말주식수)(원)', 'BPS(자사주차감)(원)', '상장주식수(주)', '시가총액 (평균)(원)',\n",
       "       '상장주식수 (보통)(주)', '매출총이익(원)', '총자산(원)', '유동자산(원)', '현금및현금성자산(원)',\n",
       "       '유동부채(원)', '단기차입금(원)', '이연법인세부채(원)', '거래대금(원)', '관리종목지정사유', '기타포괄손익(원)',\n",
       "       '베타 (M,3Yr)', '베타 (D,1Yr)', '보통주자본금(원)', '수익률(%)', '수익률 (1개월)(%)',\n",
       "       '수정주가 (52주 최고)(원)', '유무형자산상각비(원)', '이익잉여금(원)', 'Unnamed: 3182_level_4',\n",
       "       '이익잉여금(천원)'],\n",
       "      dtype='object', name='item Name')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_backup.columns.get_level_values(3).unique()#우리 데이터 뭐있나 함 볼까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24f2a1-46a7-4777-bd42-1f82fb9cf369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 월별 데이터로 작업할 merged_df 생성\n",
    "merged_df = merged_df_backup.copy()\n",
    "\n",
    "# 1. \"(원)\"으로 끝나는 컬럼 처리\n",
    "# 'item Name'이 '(원)'으로 끝나는 컬럼 선택\n",
    "won_mask = merged_df.columns.get_level_values('item Name').str.endswith('(원)')\n",
    "\n",
    "# 쉼표 제거 및 숫자 변환을 벡터화된 연산으로 수행\n",
    "# 문자열 'None', 'nan', '', 'N/A' 등을 NaN으로 변환\n",
    "merged_df.loc[:, won_mask] = (\n",
    "    merged_df.loc[:, won_mask]\n",
    "    .astype(str)  # 모든 데이터를 문자열로 변환\n",
    "    .replace(',', '', regex=True)  # 쉼표 제거\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A'], np.nan)  # 비정상적인 값들을 NaN으로 변환\n",
    "    .apply(pd.to_numeric, errors='coerce')  # 숫자로 변환 (변환 불가 시 NaN)\n",
    ")\n",
    "\n",
    "print(\"'(원)' 컬럼의 문자열 변환 및 숫자 변환 완료\")\n",
    "\n",
    "# 2. '홀딩스', '지주', '스펙'으로 끝나는 종목 제거\n",
    "pattern = ('홀딩스', '지주', '스펙', '스팩')\n",
    "symbol_names = merged_df.columns.get_level_values('Symbol Name')\n",
    "mask = symbol_names.str.endswith(pattern)\n",
    "merged_df = merged_df.loc[:, ~mask]\n",
    "\n",
    "# 3. '관리종목지정사유' 처리\n",
    "# '관리종목지정사유'가 있는 종목 추출\n",
    "management_mask = merged_df.columns.get_level_values('item Name') == '관리종목지정사유'\n",
    "management_df = merged_df.loc[:, management_mask]\n",
    "\n",
    "# 인덱스를 datetime 형태로 변환\n",
    "merged_df.index = pd.to_datetime(merged_df.index, errors='coerce')\n",
    "\n",
    "# 각 종목별로 처리\n",
    "for symbol in management_df.columns.get_level_values('Symbol').unique():\n",
    "    symbol_management = management_df.loc[:, management_df.columns.get_level_values('Symbol') == symbol]\n",
    "    \n",
    "    # NaN이 아닌 첫 번째 날짜 찾기\n",
    "    dates_with_issue = symbol_management[symbol_management.notna().any(axis=1)].index\n",
    "    \n",
    "    if not dates_with_issue.empty:\n",
    "        try:\n",
    "            # 이슈 발생 날짜\n",
    "            issue_date = dates_with_issue[0]\n",
    "            \n",
    "            # 해당 Symbol의 데이터를 처리\n",
    "            symbol_mask = merged_df.columns.get_level_values('Symbol') == symbol\n",
    "            price_mask = merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "            other_mask = symbol_mask & ~price_mask\n",
    "            \n",
    "            # 이슈 발생 월부터 이후 데이터에 대해 NaN으로 설정 (수정주가는 제외)\n",
    "            merged_df.loc[merged_df.index >= issue_date, other_mask] = np.nan\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing symbol: {symbol}, issue_date: {issue_date}, Error: {e}\")\n",
    "\n",
    "print('관리종목 포트폴리오 정상화')\n",
    "\n",
    "# 4. '거래대금(원)' 기반 종목 제거\n",
    "trading_value_mask = merged_df.columns.get_level_values('item Name') == '거래대금(원)'\n",
    "trading_value_df = merged_df.loc[:, trading_value_mask]\n",
    "\n",
    "# 인덱스를 datetime으로 변환\n",
    "trading_value_df.index = pd.to_datetime(trading_value_df.index)\n",
    "\n",
    "# 2014년 이후 데이터 선택\n",
    "trading_value_df = trading_value_df[trading_value_df.index >= '2014-01-31']\n",
    "\n",
    "# 문자열을 숫자로 변환 (오류 발생 시 NaN 처리)\n",
    "trading_value_df = trading_value_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 거래대금이 4천만원 이하인 경우 True, NaN은 False로 처리\n",
    "low_trading_value = (trading_value_df <= 40000000).fillna(False)\n",
    "\n",
    "# 각 Symbol마다 거래대금이 4천만원 이하인 달이 하나라도 있는지 확인\n",
    "symbols_to_remove = low_trading_value.any(axis=0)\n",
    "symbols_to_remove = symbols_to_remove[symbols_to_remove].index.get_level_values('Symbol').unique().tolist()\n",
    "\n",
    "# 해당 Symbol 제거\n",
    "symbol_mask = merged_df.columns.get_level_values('Symbol').isin(symbols_to_remove)\n",
    "merged_df = merged_df.loc[:, ~symbol_mask]\n",
    "\n",
    "print('market impact 조정 완료')\n",
    "\n",
    "# 5. 수정주가 기반 1개월 수익률 계산\n",
    "# 인덱스를 datetime으로 변환\n",
    "merged_df.index = pd.to_datetime(merged_df.index)\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = merged_df.loc[:, price_mask]\n",
    "\n",
    "# 월별 수익률 계산\n",
    "returns_df = price_df.pct_change()\n",
    "\n",
    "# 'item Name'을 '1개월 수익률(계산)'으로 변경\n",
    "returns_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, item, '1개월 수익률(계산)') for symbol, symbol_name, item in zip(\n",
    "        returns_df.columns.get_level_values('Symbol'),\n",
    "        returns_df.columns.get_level_values('Symbol Name'),\n",
    "        returns_df.columns.get_level_values('item')\n",
    "    )],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 수익률 데이터를 merged_df에 추가\n",
    "merged_df = pd.concat([merged_df, returns_df], axis=1)\n",
    "\n",
    "print('1개월 수익률 계산 완료')\n",
    "\n",
    "# 6. 결측치를 직전 값으로 대체\n",
    "merged_df = merged_df.fillna(method='ffill')\n",
    "\n",
    "print(\"전처리 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba780af-3c56-4772-b5c9-50d29dbc54ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('data/merged_df_monthly_preprocessing.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483dc094-5740-457f-9e86-f6022005d452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol   Symbol Name  item        item Name       \n",
       "A000660  SK하이닉스       S410000700  수정주가(원)               int64\n",
       "                      6000701101  PER(보통)(배)          float64\n",
       "                      6000701007  PER(직전4분기)(배)       float64\n",
       "                      6000701006  PER(보통,자사주차감)(배)    float64\n",
       "A373220  LG에너지솔루션     S410000700  수정주가(원)             float64\n",
       "                                                       ...   \n",
       "A900030  연합과기         S410000700  1개월 수익률(계산)         float64\n",
       "A900060  중국식품포장       S410000700  1개월 수익률(계산)         float64\n",
       "A900150  성융광전투자       S410000700  1개월 수익률(계산)         float64\n",
       "A950030  네프로아이티       S410000700  1개월 수익률(계산)         float64\n",
       "A950070  중국고섬         S410000700  1개월 수익률(계산)         float64\n",
       "Length: 58059, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_backup.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4290465-1b88-424e-9971-8e99a319a7a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 팩터값 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ee2c22-003a-4f71-8acd-265d6781415f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 팩터 전략별로 필요한 데이터를 계산하여 monthly_merged_df에 추가합니다.\n",
    "\n",
    "if 'monthly_merged_df' not in globals():\n",
    "    monthly_merged_df = pd.read_csv(\n",
    "        'data/merged_df_monthly_preprocessing.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "424f8216-865c-4d17-a2ac-66bacc9a1025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_high_pe_ratio.csv' 파일이 저장되었습니다.\n",
      "(206, 2052)\n",
      "'factor_high_pe_ratio_large_industry.csv' 파일이 저장되었습니다.\n",
      "'factor_high_pe_ratio_medium_industry.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 1: High P/E Ratio =====\n",
    "# 상위 20% 종목에 롱 포지션, 하위 20% 종목에 숏 포지션을 취하는 전략\n",
    "\n",
    "# 'PER(직전4분기)(배)' 데이터 추출\n",
    "per_mask = monthly_merged_df.columns.get_level_values('item Name') == 'PER(보통,자사주차감)(배)'\n",
    "per_df = monthly_merged_df.loc[:, per_mask]\n",
    "per_df.columns = per_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 결측치 처리 전에 per_df의 데이터를 float 타입으로 변환\n",
    "per_df = per_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 결측치 처리\n",
    "per_df = per_df.replace(0, np.nan)\n",
    "per_df = per_df.replace(np.inf, np.nan)\n",
    "per_df = per_df.fillna(method='ffill')\n",
    "\n",
    "# 전체 종목에 대해 z-score 계산\n",
    "per_zscore = -per_df.apply(lambda x: (x - x.mean()) / x.std(), axis=1)\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore.to_csv('factor_high_pe_ratio.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 산업 분류 데이터 불러오기\n",
    "try:\n",
    "    industry_df = pd.read_csv(\n",
    "        'data/industry.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    industry_df = pd.read_csv(\n",
    "        'data/industry.csv',\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,  # 첫 번째 열을 인덱스로 사용\n",
    "        encoding='cp949',\n",
    "        parse_dates=True  # 인덱스를 datetime으로 파싱\n",
    "    )\n",
    "    \n",
    "# 멀티인덱스 설정\n",
    "industry_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "industry_df.index.name = 'Date'\n",
    "\n",
    "# '한국표준산업분류10차(대분류)', '한국표준산업분류10차(중분류)' 데이터 추출\n",
    "industry_large_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(대분류)'\n",
    "industry_medium_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(중분류)'\n",
    "\n",
    "industry_large_df = industry_df.loc[:, industry_large_mask]\n",
    "industry_large_df.columns = industry_large_df.columns.droplevel(['item', 'item Name'])\n",
    "industry_medium_df = industry_df.loc[:, industry_medium_mask]\n",
    "industry_medium_df.columns = industry_medium_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# PER 데이터와 산업 분류 데이터의 인덱스 및 컬럼 정렬\n",
    "per_df, industry_large_df = per_df.align(industry_large_df, join='inner', axis=1)\n",
    "per_df, industry_medium_df = per_df.align(industry_medium_df, join='inner', axis=1)\n",
    "\n",
    "# 디버깅 출력을 위한 함수\n",
    "def debug_print(message, df=None):\n",
    "    print(message)\n",
    "    if df is not None:\n",
    "        print(df.head())\n",
    "        print(df.shape)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# 산업별로 z-score 계산\n",
    "def industry_zscore(per_series, industry_series):\n",
    "    df = pd.DataFrame({'PER': per_series, 'Industry': industry_series})\n",
    "    # NaN 값이 있는 행 제거\n",
    "    df = df.dropna()\n",
    "    # 산업별 그룹화 및 z-score 계산\n",
    "    grouped = df.groupby('Industry')\n",
    "    z_scores = grouped['PER'].transform(lambda x: -(x - x.mean()) / x.std() if x.std() != 0 else 0)\n",
    "    return z_scores\n",
    "\n",
    "# 대분류 산업별 z-score\n",
    "per_zscore_large = per_df.copy()\n",
    "print(per_zscore_large.shape)\n",
    "for date in per_zscore_large.index:\n",
    "    per_zscore_large.loc[date] = industry_zscore(per_df.loc[date], industry_large_df.loc[date])\n",
    "    # 디버깅 출력\n",
    "    # debug_print(f\"[Large Industry] Date: {date}\", per_zscore_large.loc[[date]])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "per_zscore_large.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'PER_zscore_large', 'PER_zscore_large') for symbol, symbol_name in per_zscore_large.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore_large.to_csv('factor_high_pe_ratio_large_industry.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio_large_industry.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 중분류 산업별 z-score\n",
    "per_zscore_medium = per_df.copy()\n",
    "for date in per_zscore_medium.index:\n",
    "    per_zscore_medium.loc[date] = industry_zscore(per_df.loc[date], industry_medium_df.loc[date])\n",
    "    # 디버깅 출력\n",
    "    # debug_print(f\"[Medium Industry] Date: {date}\", per_zscore_medium.loc[[date]])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "per_zscore_medium.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'PER_large', 'PER_large') for symbol, symbol_name in per_zscore_medium.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "# 팩터 값 저장\n",
    "per_zscore_medium.to_csv('factor_high_pe_ratio_medium_industry.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_high_pe_ratio_medium_industry.csv' 파일이 저장되었습니다.\")\n",
    "\n",
    "# 팩터 값 저장\n",
    "per_zscore.to_csv('factor_high_pe_ratio.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b1ba1e-178a-436f-b550-6a1fa21dd198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_hml.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 2: HML (Kang, 2013) =====\n",
    "# Book-to-Market Ratio 계산 (BPS / 주가)\n",
    "\n",
    "# 'BPS(자사주차감)(원)' 데이터 추출\n",
    "bps_mask = monthly_merged_df.columns.get_level_values('item Name') == 'BPS(자사주차감)(원)'\n",
    "bps_df = monthly_merged_df.loc[:, bps_mask]\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = monthly_merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = monthly_merged_df.loc[:, price_mask]\n",
    "\n",
    "# 컬럼 레벨 중 'item'과 'item Name'을 제거하여 컬럼 정렬\n",
    "bps_df.columns = bps_df.columns.droplevel(['item', 'item Name'])\n",
    "price_df.columns = price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "bps_df, price_df = bps_df.align(price_df, join='inner', axis=0)\n",
    "bps_df, price_df = bps_df.align(price_df, join='inner', axis=1)\n",
    "\n",
    "# 계산 전에 데이터 타입 변환\n",
    "bps_df = bps_df.apply(pd.to_numeric, errors='coerce')\n",
    "price_df = price_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Book-to-Market Ratio 계산\n",
    "bm_ratio_df = bps_df / price_df\n",
    "\n",
    "# 결측치 처리\n",
    "bm_ratio_df = bm_ratio_df.replace([np.inf, -np.inf], np.nan)\n",
    "bm_ratio_df = bm_ratio_df.fillna(method='ffill')\n",
    "\n",
    "# 멀티레벨 컬럼 구조 재설정\n",
    "bm_ratio_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'BM Ratio', 'BM Ratio') for symbol, symbol_name in bm_ratio_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "bm_ratio_df.to_csv('factor_hml.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_hml.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e451f8b-6323-46bf-aa1c-ae95be7984ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_momentum.csv', 'factor_momentum_zscore.csv', 'factor_momentum_large_industry.csv', 'factor_momentum_medium_industry.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 5: Momentum 전략 =====\n",
    "# 지난 12-1개월 수익률 계산 (직전 1개월은 제외)\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = monthly_merged_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "price_df = monthly_merged_df.loc[:, price_mask]\n",
    "price_df.columns = price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 타입 변환\n",
    "price_df = price_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "price_df = price_df.sort_index()\n",
    "\n",
    "# 결측치 처리\n",
    "price_df = price_df.fillna(method='ffill')\n",
    "\n",
    "# 12개월 전 가격과 1개월 전 가격 추출\n",
    "price_12m_ago = price_df.shift(12)\n",
    "price_1m_ago = price_df.shift(1)\n",
    "\n",
    "# 모멘텀 계산\n",
    "momentum_df = (price_1m_ago - price_12m_ago) / price_12m_ago\n",
    "\n",
    "# 결측치 처리\n",
    "momentum_df = momentum_df.replace([np.inf, -np.inf], np.nan)\n",
    "momentum_df = momentum_df.fillna(method='ffill')\n",
    "\n",
    "# 전체 종목에 대해 z-score 계산\n",
    "momentum_zscore = momentum_df.apply(lambda x: (x - x.mean()) / x.std(), axis=1)\n",
    "\n",
    "# 산업 분류 데이터 불러오기 (이미 불러온 industry_df 사용)\n",
    "# '한국표준산업분류11차(대분류)', '한국표준산업분류11차(중분류)' 데이터 추출\n",
    "industry_large_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(대분류)'\n",
    "industry_medium_mask = industry_df.columns.get_level_values('item Name') == '한국표준산업분류11차(중분류)'\n",
    "\n",
    "industry_large_df = industry_df.loc[:, industry_large_mask]\n",
    "industry_large_df.columns = industry_large_df.columns.droplevel(['item', 'item Name'])\n",
    "industry_medium_df = industry_df.loc[:, industry_medium_mask]\n",
    "industry_medium_df.columns = industry_medium_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 산업별로 z-score 계산\n",
    "def industry_zscore(per_series, industry_series):\n",
    "    df = pd.DataFrame({'PER': per_series, 'Industry': industry_series})\n",
    "    # NaN 값이 있는 행 제거\n",
    "    df = df.dropna()\n",
    "    # 산업별 그룹화 및 z-score 계산\n",
    "    grouped = df.groupby('Industry')\n",
    "    z_scores = grouped['PER'].transform(lambda x: -(x - x.mean()) / x.std() if x.std() != 0 else 0)\n",
    "    return z_scores\n",
    "\n",
    "\n",
    "# 대분류 산업별 z-score\n",
    "momentum_zscore_large = momentum_df.copy()\n",
    "for date in momentum_zscore_large.index:\n",
    "    momentum_zscore_large.loc[date] = industry_zscore(momentum_df.loc[date], industry_large_df.loc[date])\n",
    "\n",
    "# 중분류 산업별 z-score\n",
    "momentum_zscore_medium = momentum_df.copy()\n",
    "for date in momentum_zscore_medium.index:\n",
    "    momentum_zscore_medium.loc[date] = industry_zscore(momentum_df.loc[date], industry_medium_df.loc[date])\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "# 원래의 컬럼 정보를 사용하여 멀티인덱스 생성\n",
    "momentum_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum', 'Momentum') for symbol, symbol_name in momentum_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_zscore', 'Momentum_zscore') for symbol, symbol_name in momentum_zscore.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore_large.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_large', 'Momentum_large') for symbol, symbol_name in momentum_zscore_large.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "momentum_zscore_medium.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'Momentum_medium', 'Momentum_medium') for symbol, symbol_name in momentum_zscore_medium.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "momentum_df.to_csv('factor_momentum.csv', encoding='utf-8-sig')\n",
    "momentum_zscore.to_csv('factor_momentum_zscore.csv', encoding='utf-8-sig')\n",
    "momentum_zscore_large.to_csv('factor_momentum_large_industry.csv', encoding='utf-8-sig')\n",
    "momentum_zscore_medium.to_csv('factor_momentum_medium_industry.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(\"'factor_momentum.csv', 'factor_momentum_zscore.csv', 'factor_momentum_large_industry.csv', 'factor_momentum_medium_industry.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f0bebdf-f11c-4477-9e8a-e2385681d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_retained_earnings.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 6: Retained Earnings and Market-to-Book =====\n",
    "# 이익잉여금(원) / 시가총액 계산\n",
    "\n",
    "# '이익잉여금(원)' 데이터 추출\n",
    "retained_earnings_mask = monthly_merged_df.columns.get_level_values('item Name') == '이익잉여금(원)'\n",
    "retained_earnings_df = monthly_merged_df.loc[:, retained_earnings_mask]\n",
    "\n",
    "# '시가총액 (평균)(원)' 데이터 추출\n",
    "market_cap_mask = monthly_merged_df.columns.get_level_values('item Name') == '시가총액 (평균)(원)'\n",
    "market_cap_df = monthly_merged_df.loc[:, market_cap_mask]\n",
    "\n",
    "# 컬럼 레벨 중 'item'과 'item Name'을 제거하여 컬럼 정렬\n",
    "retained_earnings_df.columns = retained_earnings_df.columns.droplevel(['item', 'item Name'])\n",
    "market_cap_df.columns = market_cap_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 인덱스 및 컬럼 정렬\n",
    "retained_earnings_df, market_cap_df = retained_earnings_df.align(market_cap_df, join='inner', axis=0)\n",
    "retained_earnings_df, market_cap_df = retained_earnings_df.align(market_cap_df, join='inner', axis=1)\n",
    "\n",
    "# 데이터 타입 변환\n",
    "retained_earnings_df = retained_earnings_df.apply(pd.to_numeric, errors='coerce')\n",
    "market_cap_df = market_cap_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 이익잉여금 / 시가총액 계산\n",
    "re_mc_ratio_df = retained_earnings_df / market_cap_df\n",
    "\n",
    "# 결측치 처리\n",
    "re_mc_ratio_df = re_mc_ratio_df.replace([np.inf, -np.inf], np.nan)\n",
    "re_mc_ratio_df = re_mc_ratio_df.fillna(method='ffill')\n",
    "\n",
    "# 멀티레벨 컬럼 구조 재설정\n",
    "re_mc_ratio_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, symbol_name, 'RE/MC Ratio', 'RE/MC Ratio') for symbol, symbol_name in re_mc_ratio_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "# 팩터 값 저장\n",
    "re_mc_ratio_df.to_csv('factor_retained_earnings.csv', encoding='utf-8-sig')\n",
    "print(\"'factor_retained_earnings.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ec265dd-fffe-4dda-a358-760292967329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 종목 수: 2053\n",
      "필터링된 종목 수: 2052\n",
      "일별 가격 데이터 타입 확인:\n",
      "[dtype('int64') dtype('float64')]\n",
      "일별 수익률 계산 완료. 종목 수: 2053\n",
      "시장 수익률 데이터 기간: 2007-10-21 00:00:00 ~ 2024-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "베타 계산 중: 100%|██████████████████████████████████████████████████████████████████| 206/206 [09:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'factor_betting_against_beta.csv' 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ===== 팩터 전략 10: Betting Against Beta =====\n",
    "# 베타를 직접 계산하여 역수를 팩터 값으로 사용\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 전처리된 월별 데이터에서 종목 리스트와 기간 추출\n",
    "symbols = monthly_merged_df.columns.get_level_values('Symbol').unique()\n",
    "dates = monthly_merged_df.index.unique()\n",
    "\n",
    "# 각 종목별로 시작 날짜 추출\n",
    "symbol_start_dates = {}\n",
    "for symbol in symbols:\n",
    "    # 해당 종목의 컬럼 선택\n",
    "    symbol_cols = monthly_merged_df.loc[:, monthly_merged_df.columns.get_level_values('Symbol') == symbol]\n",
    "    # 해당 종목의 데이터가 있는 날짜 추출\n",
    "    symbol_data = symbol_cols.dropna(how='all')\n",
    "    # 데이터가 있는 경우\n",
    "    if not symbol_data.empty:\n",
    "        start_date = symbol_data.index.min()\n",
    "        # 시작 날짜에서 30일을 뺌\n",
    "        adjusted_start_date = start_date - pd.Timedelta(days=30)\n",
    "        # daily_df의 시작 날짜와 비교하여 실제 시작 날짜 결정\n",
    "        symbol_start_dates[symbol] = adjusted_start_date\n",
    "    else:\n",
    "        # 데이터가 없는 경우 최소 날짜 설정\n",
    "        symbol_start_dates[symbol] = pd.to_datetime('2000-01-01')  # 필요에 따라 최소 날짜 설정\n",
    "\n",
    "print(f\"전처리된 종목 수: {len(symbols)}\")\n",
    "\n",
    "# 2. 일별 데이터 로드 (data/KSIF_1.csv 파일)\n",
    "file_path = 'data/KSIF_1.csv'\n",
    "\n",
    "try:\n",
    "    daily_df = pd.read_csv(\n",
    "        file_path,\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='cp949',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    daily_df = pd.read_csv(\n",
    "        file_path,\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='euc-kr',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"파일 {file_path}를 로드하는 중 에러 발생: {e}\")\n",
    "    raise e  # 에러 발생 시 종료\n",
    "\n",
    "# 멀티인덱스 컬럼 이름 지정\n",
    "daily_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "daily_df.index.name = 'Date'\n",
    "\n",
    "# 'Kind', 'Frequency' 레벨 제거\n",
    "daily_df.columns = daily_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "# 필요한 종목(Symbol)만 선택\n",
    "symbol_mask = daily_df.columns.get_level_values('Symbol').isin(symbols)\n",
    "daily_df = daily_df.loc[:, symbol_mask]\n",
    "\n",
    "print(f\"필터링된 종목 수: {len(daily_df.columns.get_level_values('Symbol').unique())}\")\n",
    "\n",
    "# '수정주가(원)' 데이터 추출\n",
    "price_mask = daily_df.columns.get_level_values('item Name') == '수정주가(원)'\n",
    "daily_price_df = daily_df.loc[:, price_mask]\n",
    "daily_price_df.columns = daily_price_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "daily_price_df = (\n",
    "    daily_price_df\n",
    "    .astype(str)  # 모든 데이터를 문자열로 변환\n",
    "    .replace(',', '', regex=True)  # 쉼표 제거\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)  # 비정상적인 값들을 NaN으로 변환\n",
    "    .apply(pd.to_numeric, errors='coerce')  # 숫자로 변환 (변환 불가 시 NaN)\n",
    ")\n",
    "\n",
    "# 데이터 타입 확인\n",
    "print(\"일별 가격 데이터 타입 확인:\")\n",
    "print(daily_price_df.dtypes.unique())\n",
    "\n",
    "# 종목별 일별 수익률 계산\n",
    "daily_returns_dict = {}\n",
    "for symbol in symbols:\n",
    "    if symbol in daily_price_df.columns:\n",
    "        symbol_price = daily_price_df[symbol]\n",
    "        if not symbol_price.empty:\n",
    "            # 해당 종목의 시작 날짜 계산\n",
    "            start_date = symbol_start_dates[symbol]\n",
    "            # 시작 날짜부터 데이터 선택\n",
    "            symbol_price = symbol_price.loc[start_date:]\n",
    "            # 수익률 계산\n",
    "            symbol_returns = symbol_price.pct_change().dropna()\n",
    "            daily_returns_dict[symbol] = symbol_returns\n",
    "        else:\n",
    "            # 해당 종목의 데이터가 없는 경우\n",
    "            daily_returns_dict[symbol] = pd.Series(dtype=float)\n",
    "    else:\n",
    "        daily_returns_dict[symbol] = pd.Series(dtype=float)\n",
    "\n",
    "print(f\"일별 수익률 계산 완료. 종목 수: {len(daily_returns_dict)}\")\n",
    "\n",
    "# 시장 수익률 계산 (종가지수(포인트) 기반)\n",
    "try:\n",
    "    market_df = pd.read_csv(\n",
    "        'data/kor_market.csv',\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='cp949',\n",
    "        parse_dates=True\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    market_df = pd.read_csv(\n",
    "        'data/kor_market.csv',\n",
    "        skiprows=8,\n",
    "        header=[0, 1, 2, 3, 4, 5],\n",
    "        index_col=0,\n",
    "        encoding='euc-kr',\n",
    "        parse_dates=True\n",
    "    )\n",
    "\n",
    "# 멀티인덱스 컬럼 이름 지정\n",
    "market_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "market_df.index.name = 'Date'\n",
    "\n",
    "# 'Kind', 'Frequency' 레벨 제거\n",
    "market_df.columns = market_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "# '종가지수(포인트)' 데이터 추출\n",
    "index_mask = market_df.columns.get_level_values('item Name') == '종가지수(포인트)'\n",
    "index_df = market_df.loc[:, index_mask]\n",
    "\n",
    "# '코스피'와 '코스닥' 지수만 선택\n",
    "symbol_names = index_df.columns.get_level_values('Symbol Name')\n",
    "kospi_kosdaq_mask = (symbol_names == '코스피') | (symbol_names == '코스닥')\n",
    "kospi_kosdaq_indices = index_df.loc[:, kospi_kosdaq_mask]\n",
    "kospi_kosdaq_indices.columns = kospi_kosdaq_indices.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "# 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "kospi_kosdaq_indices = (\n",
    "    kospi_kosdaq_indices\n",
    "    .astype(str)\n",
    "    .replace(',', '', regex=True)\n",
    "    .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)\n",
    "    .apply(pd.to_numeric, errors='coerce')\n",
    ")\n",
    "\n",
    "# 코스피와 코스닥 지수의 일별 수익률 계산\n",
    "market_returns = kospi_kosdaq_indices.mean(axis=1).pct_change().dropna()\n",
    "\n",
    "# 시장 수익률 데이터 기간 확인\n",
    "print(f\"시장 수익률 데이터 기간: {market_returns.index.min()} ~ {market_returns.index.max()}\")\n",
    "\n",
    "# 3. 베타 계산 함수 정의 및 계산\n",
    "def calculate_beta(stock_returns, market_returns, window=365):\n",
    "    # 결측치 제거\n",
    "    combined = pd.concat([stock_returns, market_returns], axis=1).dropna()\n",
    "    if len(combined) < 30:\n",
    "        return np.nan\n",
    "    else:\n",
    "        stock_ret = combined.iloc[:, 0]\n",
    "        market_ret = combined.iloc[:, 1]\n",
    "        cov = stock_ret.cov(market_ret)\n",
    "        var = market_ret.var()\n",
    "        beta = cov / var if var != 0 else np.nan\n",
    "        return beta\n",
    "\n",
    "# 베타 값을 저장할 데이터프레임 생성\n",
    "beta_df = pd.DataFrame(index=dates, columns=symbols)\n",
    "\n",
    "for date in tqdm(dates, desc='베타 계산 중'):\n",
    "    for symbol in symbols:\n",
    "        # 해당 종목의 일별 수익률 시리즈\n",
    "        stock_returns = daily_returns_dict[symbol]\n",
    "        # 해당 날짜까지의 데이터 사용\n",
    "        stock_returns = stock_returns[stock_returns.index <= date]\n",
    "        market_returns_up_to_date = market_returns[market_returns.index <= date]\n",
    "        # 최근 window 기간의 데이터 추출\n",
    "        stock_returns = stock_returns.iloc[-365:]\n",
    "        market_returns_up_to_date = market_returns_up_to_date.iloc[-365:]\n",
    "        # 베타 계산\n",
    "        beta = calculate_beta(stock_returns, market_returns_up_to_date)\n",
    "        beta_df.at[date, symbol] = beta\n",
    "\n",
    "# 베타의 역수를 팩터 값으로 사용\n",
    "inv_beta_df = (1 / beta_df.astype(float)).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 멀티레벨 컬럼 구조 설정\n",
    "inv_beta_df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(symbol, monthly_merged_df.columns.get_level_values('Symbol Name')[monthly_merged_df.columns.get_level_values('Symbol') == symbol][0], 'Inverse Beta', 'Inverse Beta') for symbol in inv_beta_df.columns],\n",
    "    names=['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    ")\n",
    "\n",
    "inv_beta_df.index.name = 'Date'\n",
    "\n",
    "# 팩터 값 저장\n",
    "inv_beta_df.to_csv('factor_betting_against_beta.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(\"'factor_betting_against_beta.csv' 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96caf0fc-2d5c-445e-be7d-6d5bee346662",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: factor_high_pe_ratio.csv\n",
      "  Loaded successfully. Shape: (206, 2067)\n",
      "  Max Missing Date: 2008-01-31 00:00:00\n",
      "  Max Missing Count: 1544\n",
      "  Total Columns: 2067\n",
      "  Max Missing Ratio (%): 74.70%\n",
      "Processing file: factor_high_pe_ratio_large_industry.csv\n",
      "  Error processing file factor_high_pe_ratio_large_industry.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_high_pe_ratio_medium_industry.csv\n",
      "  Error processing file factor_high_pe_ratio_medium_industry.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_hml.csv\n",
      "  Error processing file factor_hml.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_momentum.csv\n",
      "  Error processing file factor_momentum.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_retained_earnings.csv\n",
      "  Error processing file factor_retained_earnings.csv: Length of new names must be 1, got 4\n",
      "Processing file: factor_betting_against_beta.csv\n",
      "  Loaded successfully. Shape: (426005, 5)\n",
      "  Max Missing Date: 2008-01-31 00:00:00\n",
      "  Max Missing Count: 1\n",
      "  Total Columns: 5\n",
      "  Max Missing Ratio (%): 20.00%\n",
      "\n",
      "===== Missing Data Summary =====\n",
      "                       Factor File Max Missing Date  Max Missing Count  \\\n",
      "0         factor_high_pe_ratio.csv       2008-01-31               1544   \n",
      "1  factor_betting_against_beta.csv       2008-01-31                  1   \n",
      "\n",
      "   Total Columns  Max Missing Ratio (%)  \n",
      "0           2067              74.697629  \n",
      "1              5              20.000000  \n",
      "\n",
      "결측치 분석 결과가 'factor_missing_data_summary.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "#계산한 팩터값에 결측치 확인\n",
    "import pandas as pd\n",
    "\n",
    "# ===== 팩터 값 CSV 확인 및 결측치 분석 =====\n",
    "\n",
    "# 저장된 팩터 값 CSV 파일 목록\n",
    "factor_files = [\n",
    "    'factor_high_pe_ratio.csv',\n",
    "    'factor_high_pe_ratio_large_industry.csv',\n",
    "    'factor_high_pe_ratio_medium_industry.csv',\n",
    "    'factor_hml.csv',\n",
    "    'factor_momentum.csv',\n",
    "    'factor_retained_earnings.csv',\n",
    "    'factor_betting_against_beta.csv'\n",
    "]\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "missing_data_summary = []\n",
    "\n",
    "for file in factor_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    try:\n",
    "        # CSV 파일 로드\n",
    "        factor_df = pd.read_csv(file, \n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "        )\n",
    "\n",
    "        # 멀티인덱스 설정\n",
    "        factor_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "        factor_df.index.name = 'Date'\n",
    "        \n",
    "        print(f\"  Loaded successfully. Shape: {factor_df.shape}\")\n",
    "        \n",
    "        # 2008년 이후 데이터만 필터링\n",
    "        factor_df = factor_df.loc[factor_df.index >= '2008-01-01']\n",
    "        \n",
    "        # 결측치 분석\n",
    "        missing_summary = factor_df.isna().sum(axis=1)  # 각 날짜별 결측치 수\n",
    "        total_columns = factor_df.shape[1]  # 전체 컬럼 수\n",
    "        \n",
    "        # 가장 결측치가 많은 날짜와 해당 날짜의 결측치 비율\n",
    "        max_missing_date = missing_summary.idxmax()\n",
    "        max_missing_count = missing_summary.max()\n",
    "        max_missing_ratio = (max_missing_count / total_columns) * 100  # 결측치 비율\n",
    "        \n",
    "        # 결측치 요약 추가\n",
    "        missing_data_summary.append({\n",
    "            'Factor File': file,\n",
    "            'Max Missing Date': max_missing_date,\n",
    "            'Max Missing Count': max_missing_count,\n",
    "            'Total Columns': total_columns,\n",
    "            'Max Missing Ratio (%)': max_missing_ratio\n",
    "        })\n",
    "        \n",
    "        print(f\"  Max Missing Date: {max_missing_date}\")\n",
    "        print(f\"  Max Missing Count: {max_missing_count}\")\n",
    "        print(f\"  Total Columns: {total_columns}\")\n",
    "        print(f\"  Max Missing Ratio (%): {max_missing_ratio:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing file {file}: {e}\")\n",
    "\n",
    "# 결측치 분석 결과 DataFrame 생성\n",
    "missing_summary_df = pd.DataFrame(missing_data_summary)\n",
    "\n",
    "# 결측치 분석 결과 출력\n",
    "print(\"\\n===== Missing Data Summary =====\")\n",
    "print(missing_summary_df)\n",
    "\n",
    "# 결측치 분석 결과 저장\n",
    "missing_summary_df.to_csv('factor_missing_data_summary.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n결측치 분석 결과가 'factor_missing_data_summary.csv' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea0115-500f-4531-8c1c-bca6231d31c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 백테스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "733414aa-d911-44b3-b1b0-8e45babee5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy_daily(\n",
    "    factor_csv,\n",
    "    daily_return_csv, \n",
    "    rebalancing_period=1, \n",
    "    long_only=True, \n",
    "    threshold=0.2, \n",
    "    cutoff=0.0, \n",
    "    reversal=False, \n",
    "    weighting_method='equal', \n",
    "    start_date='2008-10-31'\n",
    "):\n",
    "    \"\"\"\n",
    "    일별 수익률 데이터를 이용한 백테스팅 함수.\n",
    "\n",
    "    Parameters:\n",
    "    - factor_csv (str): 팩터값 CSV 파일 경로\n",
    "    - daily_return_csv (pd.Dataframe): 종목별 영업일별 수익률 데이터프레임\n",
    "    - rebalancing_period (int): 리밸런싱 주기 (기본 1: 매월 리밸런싱)\n",
    "    - long_only (bool): 롱 온리 전략 여부\n",
    "    - threshold (float): 포지션을 취할 상위/하위 퍼센트 (0 < threshold <= 1)\n",
    "    - cutoff (float): 포지션을 취할 시작 퍼센트 (0 <= cutoff < threshold)\n",
    "    - reversal (bool): 전략을 반대로 적용할지 여부\n",
    "    - weighting_method (str): 'equal' 또는 'value' 중 하나\n",
    "    - start_date (str): 백테스트 시작 날짜 (예: '2008-10-31')\n",
    "\n",
    "    Returns:\n",
    "    - results_df (pd.DataFrame): 일별 포트폴리오 변동 및 포지션 정보\n",
    "    \"\"\"\n",
    "    # 팩터 데이터 불러오기\n",
    "    factor_df = pd.read_csv(factor_csv, index_col=0, header=[0, 1, 2, 3], parse_dates=True)\n",
    "    factor_df.index.name = 'Date'\n",
    "    factor_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "\n",
    "    # 팩터에서 레벨 제거 (심볼 및 종목명만 남김)\n",
    "    factor_df.columns = factor_df.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "    # 시작일 이후로 데이터 필터링\n",
    "    factor_df = factor_df[factor_df.index >= start_date]\n",
    "\n",
    "    # 영업일별 수익률 데이터 불러오기\n",
    "    # 여기서는 컬럼 구조가 Symbol / Symbol Name 레벨로 되어있다고 가정\n",
    "    # returns_df = pd.read_csv(daily_return_csv, index_col=0, header=[0, 1, 2, 3], parse_dates=True)\n",
    "    returns_df = daily_return_csv.copy()\n",
    "    returns_df = returns_df/100\n",
    "    returns_df.index.name = 'Date'\n",
    "    returns_df.columns.names = ['Symbol', 'Symbol Name', 'item', 'item Name']\n",
    "    \n",
    "    # 시작일 이후로 데이터 필터링\n",
    "    returns_df = returns_df[returns_df.index >= start_date]\n",
    "\n",
    "    #공통 심볼 맞추기용 멀티레벨 제거\n",
    "    returns_df.columns = returns_df.columns.droplevel(['item', 'item Name'])\n",
    "    \n",
    "    # 팩터와 수익률 공통 심볼\n",
    "    common_symbols = factor_df.columns.intersection(returns_df.columns)\n",
    "    factor_df = factor_df[common_symbols]\n",
    "    returns_df = returns_df[common_symbols]\n",
    "\n",
    "    # 정렬\n",
    "    factor_df = factor_df.sort_index().sort_index(axis=1)\n",
    "    returns_df = returns_df.sort_index().sort_index(axis=1)\n",
    "\n",
    "    # 월말 리밸런싱 날짜 산출\n",
    "    # factor_df를 월말 기준으로 리샘플 후 해당 날짜를 rebalancing_dates로 사용\n",
    "    monthly_factor = factor_df.resample('M').last()\n",
    "    rebalancing_dates = monthly_factor.index[::rebalancing_period]\n",
    "\n",
    "    # 포트폴리오 초기화\n",
    "    portfolio = pd.DataFrame(index=returns_df.index, columns=['Portfolio Value', 'Daily Return', 'Transaction Cost'])\n",
    "    portfolio['Portfolio Value'] = 1.0\n",
    "    portfolio['Transaction Cost'] = 0.0\n",
    "    portfolio['Daily Return'] = 0.0\n",
    "\n",
    "    # 포지션 딕셔너리\n",
    "    positions = {}\n",
    "\n",
    "    # 거래 비용 비율 (0.1%)\n",
    "    transaction_cost_rate = 0.001\n",
    "\n",
    "    # 백테스트 진행\n",
    "    for i, date in enumerate(returns_df.index):\n",
    "        # 이전 날짜\n",
    "        prev_date = returns_df.index[i - 1] if i > 0 else None\n",
    "\n",
    "        # 리밸런싱 시점인지 확인\n",
    "        if date in rebalancing_dates:\n",
    "            # 해당 월말 팩터\n",
    "            # factor_df는 일별 데이터이나, 월말값이 존재. 혹 월말에 값이 없을 경우 직전데이터를 ffill\n",
    "            if date in factor_df.index:\n",
    "                factor = factor_df.loc[date].dropna()\n",
    "            else:\n",
    "                factor = factor_df.loc[:date].ffill().iloc[-1].dropna()\n",
    "\n",
    "            # 종목 수 계산\n",
    "            num_assets = len(factor)\n",
    "            num_selected = int(num_assets * threshold)\n",
    "            num_cutoff = int(num_assets * cutoff)\n",
    "\n",
    "            if long_only:\n",
    "                # 롱 온리 전략\n",
    "                if reversal:\n",
    "                    # 하위 cutoff% ~ threshold% 종목을 선택\n",
    "                    selected_symbols = factor.nsmallest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                else:\n",
    "                    # 상위 cutoff% ~ threshold% 종목을 선택\n",
    "                    selected_symbols = factor.nlargest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "\n",
    "                # 가중치 계산\n",
    "                if weighting_method == 'equal':\n",
    "                    weights = pd.Series(1.0 / len(selected_symbols), index=selected_symbols)\n",
    "                elif weighting_method == 'value':\n",
    "                    weights = factor[selected_symbols] / factor[selected_symbols].abs().sum()\n",
    "                else:\n",
    "                    raise ValueError(\"weighting_method must be 'equal' or 'value'\")\n",
    "            else:\n",
    "                # 롱숏 전략\n",
    "                if reversal:\n",
    "                    # 하위 cutoff% ~ threshold% 종목을 롱, 상위 cutoff% ~ threshold% 종목을 숏\n",
    "                    long_symbols = factor.nsmallest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                    short_symbols = factor.nlargest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                else:\n",
    "                    # 상위 cutoff% ~ threshold% 종목을 롱, 하위 cutoff% ~ threshold% 종목을 숏\n",
    "                    long_symbols = factor.nlargest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "                    short_symbols = factor.nsmallest(num_selected + num_cutoff).iloc[num_cutoff:].index\n",
    "\n",
    "                # 가중치 계산\n",
    "                if weighting_method == 'equal':\n",
    "                    long_weights = pd.Series(1.0 / len(long_symbols), index=long_symbols)\n",
    "                    short_weights = pd.Series(-1.0 / len(short_symbols), index=short_symbols)\n",
    "                elif weighting_method == 'value':\n",
    "                    long_weights = factor[long_symbols] / factor[long_symbols].abs().sum()\n",
    "                    short_weights = -factor[short_symbols] / factor[short_symbols].abs().sum()\n",
    "                else:\n",
    "                    raise ValueError(\"weighting_method must be 'equal' or 'value'\")\n",
    "\n",
    "                # 롱과 숏 포지션 합치기\n",
    "                weights = pd.concat([long_weights, short_weights])\n",
    "\n",
    "            # 거래 비용 계산 (포지션 변경에 따른)\n",
    "            if prev_date is not None and prev_date in positions:\n",
    "                prev_weights = positions[prev_date]\n",
    "                # 포지션 변경량 계산\n",
    "                weight_diff = weights.reindex(prev_weights.index).fillna(0) - prev_weights.reindex(weights.index).fillna(0)\n",
    "            else:\n",
    "                # 처음 포지션을 잡을 때는 전체 포지션이 신규 진입\n",
    "                weight_diff = weights\n",
    "\n",
    "            # 거래 비용 계산\n",
    "            transaction_cost = transaction_cost_rate * weight_diff.abs().sum()\n",
    "\n",
    "            # 현재 포지션 저장\n",
    "            positions[date] = weights\n",
    "\n",
    "        else:\n",
    "            # 리밸런싱 시점이 아니면 이전 포지션을 그대로 유지\n",
    "            if prev_date in positions:\n",
    "                positions[date] = positions[prev_date]\n",
    "                transaction_cost = 0.0  # 거래 비용 없음\n",
    "            else:\n",
    "                # 이전 포지션이 없으면 포지션 없음\n",
    "                positions[date] = pd.Series()\n",
    "                transaction_cost = 0.0  # 거래 비용 없음\n",
    "\n",
    "        # 수익률 계산 (선행 편향 방지를 위해 이전 포지션 사용)\n",
    "        if prev_date in positions and not positions[prev_date].empty:\n",
    "            current_weights = positions[prev_date]\n",
    "\n",
    "            # 해당 일의 수익률 계산\n",
    "            daily_returns = returns_df.loc[date].reindex(current_weights.index).fillna(0)\n",
    "            \n",
    "            # 포트폴리오 수익률 계산 (벡터화 연산)\n",
    "            portfolio_return = (current_weights * daily_returns).sum()\n",
    "        else:\n",
    "            # 포지션이 없으면 수익률 0\n",
    "            portfolio_return = 0.0\n",
    "\n",
    "        # 거래 비용을 수익률에 반영\n",
    "        net_return = portfolio_return - transaction_cost\n",
    "\n",
    "        # 포트폴리오 가치 업데이트\n",
    "        if i > 0:\n",
    "            portfolio.loc[date, 'Daily Return'] = net_return\n",
    "            portfolio.loc[date, 'Transaction Cost'] = transaction_cost\n",
    "            portfolio.loc[date, 'Portfolio Value'] = portfolio.iloc[i - 1]['Portfolio Value'] * (1 + net_return)\n",
    "        else:\n",
    "            # 첫날은 초기값 유지\n",
    "            portfolio.loc[date, 'Daily Return'] = 0.0\n",
    "            portfolio.loc[date, 'Transaction Cost'] = 0.0\n",
    "\n",
    "    # 포지션 정보를 데이터프레임 변환\n",
    "    positions_df = pd.DataFrame.from_dict(positions, orient='index')\n",
    "    positions_df.index.name = 'Date'\n",
    "\n",
    "    #positions_df 멀티레벨 col 평탄화\n",
    "    if isinstance(positions_df.columns, pd.MultiIndex):\n",
    "        positions_df.columns = ['_'.join(map(str, col)) for col in positions_df.columns]\n",
    "\n",
    "    # 결과 합치기\n",
    "    results_df = portfolio.join(positions_df, how='left')\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9279f865-95d8-43a9-a8da-d6e60a76eb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼 ('A008080', '에스와이코퍼레이션', 'S41000170F', '수익률(%)') 처리 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 10/10 [1:26:58<00:00, 521.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# 'factor'라는 글자가 포함된 모든 CSV 파일 목록을 가져옵니다.\n",
    "factor_files = glob.glob('*factor*.csv')\n",
    "\n",
    "price_data_path = 'data/KSIF_수익률(영업일).csv'\n",
    "\n",
    "# 수정 종가 데이터 로드\n",
    "daily_returns = pd.read_csv(\n",
    "        price_data_path,\n",
    "        header=[0, 1, 2, 3],\n",
    "        index_col=0,\n",
    "        parse_dates=True\n",
    "    )\n",
    "\n",
    "# int 또는 str 타입의 열 확인\n",
    "non_float_columns = daily_returns.select_dtypes(include=['int', 'object']).columns\n",
    "\n",
    "# 데이터 처리\n",
    "for col in non_float_columns:\n",
    "    try:\n",
    "        # ',' 제거 후 float로 변환\n",
    "        daily_returns[col] = daily_returns[col].str.replace(',', '').astype(float)\n",
    "        # 절댓값이 31 이상인 값을 클리핑\n",
    "        daily_returns[col] = daily_returns[col].apply(lambda x: 31 if x > 31 else (-31 if x < -31 else x))\n",
    "        print(f\"컬럼 {col} 처리 완료\")\n",
    "    except ValueError as e:\n",
    "        print(f\"컬럼 {col} 처리 실패: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# 백테스팅에 사용할 파라미터 그리드 설정\n",
    "rebalancing_periods = [1, 3, 6]        # 리밸런싱 주기\n",
    "thresholds = [0.1, 0.2, 0.3]           # 상위/하위 퍼센트\n",
    "cutoffs = [0, 0.05, 0.1]               # 시작 퍼센트\n",
    "weighting_methods = ['equal', 'value'] # 가중치 방법\n",
    "start_date = '2008-10-31'              # 백테스트 시작일\n",
    "\n",
    "# 모든 팩터 파일에 대해 백테스팅 수행\n",
    "for factor_csv in tqdm(factor_files):\n",
    "    # print(f\"백테스팅 시작: {factor_csv}\")\n",
    "    \n",
    "    # 팩터 파일명에서 확장자를 제거하여 폴더명을 생성합니다.\n",
    "    factor_name = os.path.splitext(factor_csv)[0]\n",
    "    \n",
    "    # 팩터별 폴더 생성 (이미 존재하면 생략)\n",
    "    if not os.path.exists(factor_name):\n",
    "        os.makedirs(factor_name)\n",
    "    \n",
    "    # 모든 파라미터 조합에 대해 백테스팅 수행\n",
    "    for rebalancing_period, threshold, cutoff, weighting_method in itertools.product(\n",
    "        rebalancing_periods, thresholds, cutoffs, weighting_methods):\n",
    "        \n",
    "        # cutoff는 threshold보다 작아야 합니다.\n",
    "        if cutoff >= threshold:\n",
    "            continue\n",
    "        \n",
    "        # 백테스팅 함수 호출\n",
    "        try:\n",
    "            results_df = backtest_strategy_daily(\n",
    "                factor_csv=factor_csv,\n",
    "                daily_return_csv=daily_returns,  # 수익률 데이터가 포함된 데이터프레임 (사전에 정의되어 있어야 합니다)\n",
    "                rebalancing_period=rebalancing_period,\n",
    "                long_only=True,  # Long-only 전략\n",
    "                threshold=threshold,\n",
    "                cutoff=cutoff,\n",
    "                reversal=False,  # 기본값\n",
    "                weighting_method=weighting_method,\n",
    "                start_date=start_date\n",
    "            )\n",
    "            # 파일명 생성 (스네이크 케이스로 파라미터 명명)\n",
    "            file_name = f\"Daily_rebalancing_{rebalancing_period}_threshold_{threshold}_cutoff_{cutoff}_weighting_{weighting_method}\"\n",
    "            file_name = file_name.replace('.', '_')  # 파일명에 있는 점을 언더스코어로 변경\n",
    "\n",
    "            # 결과 저장 경로 생성\n",
    "            save_path = os.path.join('Daily_backtest/'+factor_name, file_name)\n",
    "\n",
    "            for i,path in enumerate(save_path.split(r'/')):\n",
    "                #폴더 생성\n",
    "                os.makedirs('/'.join(save_path.split(r'/')[:i+1]), exist_ok=True)\n",
    "                       \n",
    "            # 백테스팅 결과를 CSV 파일로 저장\n",
    "            results_df.to_csv(save_path+'.csv', encoding='utf-8-sig')\n",
    "            \n",
    "            # print(f\"완료: {factor_csv}, 리밸런싱 주기: {rebalancing_period}, threshold: {threshold}, cutoff: {cutoff}, 가중치 방법: {weighting_method}\")\n",
    "            # print(f\"저장 위치: {save_path}\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            print(f\"에러 발생: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "49b081e0-757d-4b56-85fd-933ce18445b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:13<00:00, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "각 팩터별로 Sharpe Ratio가 가장 높은 파일 목록:\n",
      "Daily_backtest\\factor_betting_against_beta\\Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_high_pe_ratio\\Daily_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_value.csv\n",
      "Daily_backtest\\factor_high_pe_ratio_large_industry\\Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_high_pe_ratio_medium_industry\\Daily_rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal.csv\n",
      "Daily_backtest\\factor_hml\\Daily_rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_momentum\\Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_momentum_large_industry\\Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_momentum_medium_industry\\Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_value.csv\n",
      "Daily_backtest\\factor_momentum_zscore\\Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_retained_earnings\\Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 시장 수익률 계산 (종가지수(포인트) 기반, 여기서는 ECO 지수 기반)\n",
    "def get_risk_free_rate():\n",
    "    \"\"\"\n",
    "    위험무시 수익률(rf)을 일별 기준으로 계산하는 함수입니다.\n",
    "    'ECO' 컬럼을 사용하여 일별 지수 수익률을 계산한 뒤 이를 위험무시 수익률로 가정합니다.\n",
    "    원래는 코스피, 코스닥 평균 등을 사용하였으나, 코드상 ECO를 사용하고 있음.\n",
    "    \n",
    "    Returns:\n",
    "    - rf_daily_returns (pd.Series): 일별 위험무시 수익률 시리즈\n",
    "    \"\"\"\n",
    "    # 시장 데이터 로드\n",
    "    try:\n",
    "        market_df = pd.read_csv(\n",
    "            'data/rf.csv',\n",
    "            skiprows=8,\n",
    "            header=[0, 1, 2, 3, 4, 5],\n",
    "            index_col=0,\n",
    "            encoding='cp949',\n",
    "            parse_dates=True\n",
    "        )\n",
    "    except UnicodeDecodeError:\n",
    "        market_df = pd.read_csv(\n",
    "            'data/rf.csv',\n",
    "            skiprows=8,\n",
    "            header=[0, 1, 2, 3, 4, 5],\n",
    "            index_col=0,\n",
    "            encoding='euc-kr',\n",
    "            parse_dates=True\n",
    "        )\n",
    "\n",
    "    # 멀티인덱스 컬럼 이름 지정\n",
    "    market_df.columns.names = ['Symbol', 'Symbol Name', 'Kind', 'item', 'item Name', 'Frequency']\n",
    "    market_df.index.name = 'Date'\n",
    "\n",
    "    # 'Kind', 'Frequency' 레벨 제거\n",
    "    market_df.columns = market_df.columns.droplevel(['Kind', 'Frequency'])\n",
    "\n",
    "    # '시장금리:국고1년(%)' 데이터 추출 (ECO라고 명시된 컬럼 사용)\n",
    "    index_mask = market_df.columns.get_level_values('item Name') == '시장금리:국고1년(%)'\n",
    "    index_df = market_df.loc[:, index_mask]\n",
    "\n",
    "    # ECO 컬럼 선택\n",
    "    symbol_names = index_df.columns.get_level_values('Symbol Name')\n",
    "    eco_mask = (symbol_names == 'ECO')\n",
    "    eco_indices = index_df.loc[:, eco_mask]\n",
    "    eco_indices.columns = eco_indices.columns.droplevel(['item', 'item Name'])\n",
    "\n",
    "    # 데이터 정제: 쉼표 제거 및 숫자 변환\n",
    "    eco_indices = (\n",
    "        eco_indices\n",
    "        .astype(str)\n",
    "        .replace(',', '', regex=True)\n",
    "        .replace(['', 'None', 'nan', 'NaN', 'N/A', ''], np.nan)\n",
    "        .apply(pd.to_numeric, errors='coerce')\n",
    "    )\n",
    "\n",
    "    # ECO 지수의 일별 수익률 계산\n",
    "    # pct_change()를 통해 일별 수익률 계산\n",
    "    rf_daily_returns = eco_indices.mean(axis=1).pct_change().dropna()\n",
    "    rf_daily_returns.name = 'Risk-Free Rate'\n",
    "\n",
    "    return rf_daily_returns\n",
    "\n",
    "# 위험 무시 수익률(rf) 시리즈 가져오기 (일별)\n",
    "rf_returns = get_risk_free_rate()\n",
    "\n",
    "def calculate_sharpe_ratio(returns_series, rf_series, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Sharpe Ratio를 계산하는 함수 (일별 데이터 기반).\n",
    "    \n",
    "    Parameters:\n",
    "    - returns_series (pd.Series): 일별 수익률 시리즈\n",
    "    - rf_series (pd.Series): 일별 위험 무시 수익률 시리즈\n",
    "    - start_date (str): Sharpe Ratio 계산에 사용할 시작 날짜 (예: '2008-10-31')\n",
    "    - end_date (str): Sharpe Ratio 계산에 사용할 종료 날짜 (예: '2018-09-30')\n",
    "    \n",
    "    Returns:\n",
    "    - sharpe_ratio (float): Sharpe Ratio 값 (일별 데이터 기준 연율화)\n",
    "    \"\"\"\n",
    "    # 지정된 기간으로 데이터 필터링\n",
    "    returns_series = returns_series.loc[start_date:end_date]\n",
    "    rf_series = rf_series.loc[start_date:end_date]\n",
    "\n",
    "    # 수익률과 위험 무시 수익률의 교집합 날짜 선택\n",
    "    common_index = returns_series.index.intersection(rf_series.index)\n",
    "    returns = returns_series.loc[common_index].dropna()\n",
    "    rf = rf_series.loc[common_index].dropna()\n",
    "\n",
    "    # 위험 프리미엄 계산 (초과 수익률)\n",
    "    excess_returns = returns - rf\n",
    "\n",
    "    # 결측치 제거\n",
    "    excess_returns = excess_returns.dropna()\n",
    "\n",
    "    # 일별 초과 수익률의 평균과 표준편차 계산\n",
    "    mean_excess_return = excess_returns.mean()\n",
    "    std_excess_return = excess_returns.std()\n",
    "\n",
    "    # Sharpe Ratio 계산 (연율화, 일별 기준 252거래일 가정)\n",
    "    if std_excess_return != 0:\n",
    "        sharpe_ratio = (mean_excess_return / std_excess_return) * np.sqrt(252)\n",
    "    else:\n",
    "        sharpe_ratio = np.nan\n",
    "    return sharpe_ratio\n",
    "\n",
    "# 'factor'로 시작하는 모든 폴더 목록을 가져옵니다.\n",
    "factor_folders = [folder for folder in glob.glob('Daily_backtest\\\\*') if os.path.isdir(folder)]\n",
    "\n",
    "# 각 팩터별로 Sharpe Ratio가 가장 높은 파일명을 저장할 리스트 초기화\n",
    "best_results = []\n",
    "\n",
    "# Training 데이터 기간 설정\n",
    "training_start_date = '2008-10-31'\n",
    "training_end_date = '2018-09-30'\n",
    "\n",
    "# 각 팩터 폴더에 대해 반복\n",
    "for folder in tqdm(factor_folders):\n",
    "    # 폴더 내의 모든 CSV 파일 목록 가져오기\n",
    "    csv_files = glob.glob(os.path.join(folder, '*.csv'))\n",
    "    \n",
    "    # Sharpe Ratio를 저장할 딕셔너리 초기화\n",
    "    sharpe_ratios = {}\n",
    "    \n",
    "    # 각 CSV 파일에 대해 반복\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            # CSV 파일 읽기\n",
    "            df = pd.read_csv(csv_file, index_col=0, parse_dates=True)\n",
    "            # 'Daily Return' 컬럼이 존재하는지 확인\n",
    "            if 'Daily Return' in df.columns:\n",
    "                # Sharpe Ratio 계산 (일별 기반)\n",
    "                sharpe_ratio = calculate_sharpe_ratio(df['Daily Return'], rf_returns, training_start_date, training_end_date)\n",
    "                # Sharpe Ratio 저장\n",
    "                sharpe_ratios[csv_file] = sharpe_ratio\n",
    "            else:\n",
    "                print(f\"'Daily Return' 컬럼이 없습니다: {csv_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"에러 발생: {csv_file}, 에러 내용: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 해당 팩터 폴더에서 Sharpe Ratio가 가장 높은 파일 찾기\n",
    "    if sharpe_ratios:\n",
    "        # 최대 Sharpe Ratio를 가진 파일 찾기\n",
    "        best_file = max(sharpe_ratios, key=sharpe_ratios.get)\n",
    "        best_sharpe = sharpe_ratios[best_file]\n",
    "        best_results.append(best_file)\n",
    "    else:\n",
    "        print(f\"Sharpe Ratio를 계산할 수 있는 파일이 없습니다: {folder}\")\n",
    "\n",
    "# best_results 리스트를 'best_results.txt' 파일에 저장\n",
    "with open('best_results.txt', 'w', encoding='utf-8') as f:\n",
    "    for file_path in best_results:\n",
    "        f.write(file_path + '\\n')\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n각 팩터별로 Sharpe Ratio가 가장 높은 파일 목록:\")\n",
    "for best_file in best_results:\n",
    "    print(best_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5744af42-dcbb-4471-aff2-fb1ca63a67d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 최종 선택된 경주마 발표(시각화)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776e0c99-cbaa-46da-a3a7-61832b68fc8a",
   "metadata": {},
   "source": [
    "factor_betting_against_beta\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
    "factor_high_pe_ratio\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
    "factor_high_pe_ratio_large_industry\\rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_high_pe_ratio_medium_industry\\rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal.csv\n",
    "factor_hml\\rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
    "factor_momentum\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_momentum_large_industry\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_momentum_medium_industry\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv\n",
    "factor_momentum_zscore\\rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
    "factor_retained_earnings\\rebalancing_1_threshold_0_1_cutoff_0_05_weighting_equal.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2402dd4c-2f82-409b-9469-3338925232bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import os\n",
    "\n",
    "# Plotly 렌더러 설정: 브라우저에서 그래프를 표시하도록 설정\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "# Training 데이터 기간 설정\n",
    "training_start_date = '2008-10-31'\n",
    "training_end_date = '2018-09-30'\n",
    "\n",
    "# 그래프의 트레이스를 저장할 리스트 초기화\n",
    "traces = []\n",
    "\n",
    "# Sharpe Ratio를 저장할 리스트 초기화\n",
    "sharpe_ratio_list = []\n",
    "\n",
    "# Sharpe Ratio 계산 함수 (이미 정의되어 있다고 가정)\n",
    "def calculate_sharpe_ratio(returns_series, rf_series, start_date, end_date):\n",
    "    # 지정된 기간으로 데이터 필터링\n",
    "    returns_series = returns_series.loc[start_date:end_date]\n",
    "    rf_series = rf_series.loc[start_date:end_date]\n",
    "\n",
    "    # 수익률과 위험 무시 수익률의 교집합 날짜 선택\n",
    "    common_index = returns_series.index.intersection(rf_series.index)\n",
    "    returns = returns_series.loc[common_index].dropna()\n",
    "    rf = rf_series.loc[common_index].dropna()\n",
    "\n",
    "    # 위험 프리미엄 계산 (초과 수익률)\n",
    "    excess_returns = returns - rf\n",
    "\n",
    "    # 결측치 제거\n",
    "    excess_returns = excess_returns.dropna()\n",
    "\n",
    "    # 월별 초과 수익률의 평균과 표준편차 계산\n",
    "    mean_excess_return = excess_returns.mean()\n",
    "    std_excess_return = excess_returns.std()\n",
    "\n",
    "    # Sharpe Ratio 계산 (연율화)\n",
    "    if std_excess_return != 0:\n",
    "        sharpe_ratio = (mean_excess_return / std_excess_return) * np.sqrt(12)\n",
    "    else:\n",
    "        sharpe_ratio = np.nan\n",
    "    return sharpe_ratio\n",
    "\n",
    "# 위험 무시 수익률(rf) 시리즈 가져오기 (이미 정의되어 있다고 가정)\n",
    "# rf_returns = get_risk_free_rate()\n",
    "\n",
    "# best_results 리스트에 담긴 CSV 파일들을 순회하면서 차트 생성 및 Sharpe Ratio 계산\n",
    "for csv_file in best_results:\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(csv_file, index_col=0, parse_dates=True)\n",
    "\n",
    "    # 기간 필터링 (Sharpe Ratio 계산 기간과 동일)\n",
    "    df_period = df.loc[training_start_date:training_end_date]\n",
    "\n",
    "    # 포트폴리오 가치와 월별 수익률이 존재하는지 확인\n",
    "    if 'Portfolio Value' in df_period.columns and 'Daily Return' in df_period.columns:\n",
    "        # 포트폴리오 가치 시계열 데이터 준비\n",
    "        portfolio_values = df_period['Portfolio Value']\n",
    "\n",
    "        # 전략 이름 생성 (팩터 이름과 전략 정보 결합)\n",
    "        folder_name, file_name = os.path.split(csv_file)\n",
    "        factor_name = folder_name\n",
    "        strategy_info = file_name.replace('.csv', '')\n",
    "        strategy_name = f\"{factor_name} - {strategy_info}\"\n",
    "\n",
    "        # 그래프의 트레이스 생성 및 추가\n",
    "        trace = go.Scatter(\n",
    "            x=portfolio_values.index,\n",
    "            y=portfolio_values.values,\n",
    "            mode='lines',\n",
    "            name=strategy_name\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "        rf_returns = get_risk_free_rate()\n",
    "        \n",
    "        # Sharpe Ratio 계산\n",
    "        sharpe_ratio = calculate_sharpe_ratio(df_period['Daily Return'], rf_returns, training_start_date, training_end_date)\n",
    "\n",
    "        # Sharpe Ratio를 리스트에 저장\n",
    "        sharpe_ratio_list.append({\n",
    "            'Strategy': strategy_name,\n",
    "            'Sharpe Ratio': sharpe_ratio\n",
    "        })\n",
    "    else:\n",
    "        print(f\"'Portfolio Value' 또는 'Monthly Return' 컬럼이 없습니다: {csv_file}\")\n",
    "\n",
    "# 그래프 레이아웃 설정\n",
    "layout = go.Layout(\n",
    "    title='최적의 전략별 포트폴리오 가치 비교 (2008-10-31 ~ 2018-09-30)',\n",
    "    xaxis=dict(title='날짜'),\n",
    "    yaxis=dict(title='포트폴리오 가치'),\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "# 그래프 생성 및 출력\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()\n",
    "\n",
    "# Sharpe Ratio를 데이터프레임으로 생성 및 출력\n",
    "sharpe_ratio_df = pd.DataFrame(sharpe_ratio_list)\n",
    "# print(\"\\n각 전략의 연율화 Sharpe Ratio:\")\n",
    "# print(sharpe_ratio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e2649d5-c7ac-4a14-811b-37cbbbdcbdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daily_backtest\\factor_betting_against_beta - Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.212378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daily_backtest\\factor_high_pe_ratio - Daily_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_value</td>\n",
       "      <td>0.353835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daily_backtest\\factor_high_pe_ratio_large_industry - Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.323825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daily_backtest\\factor_high_pe_ratio_medium_industry - Daily_rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal</td>\n",
       "      <td>0.318300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daily_backtest\\factor_hml - Daily_rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.333881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Daily_backtest\\factor_momentum - Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.265538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Daily_backtest\\factor_momentum_large_industry - Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.252958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Daily_backtest\\factor_momentum_medium_industry - Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_value</td>\n",
       "      <td>0.242361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Daily_backtest\\factor_momentum_zscore - Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal</td>\n",
       "      <td>0.265538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Daily_backtest\\factor_retained_earnings - Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal</td>\n",
       "      <td>0.353019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              Strategy  \\\n",
       "0            Daily_backtest\\factor_betting_against_beta - Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal   \n",
       "1                  Daily_backtest\\factor_high_pe_ratio - Daily_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_value   \n",
       "2    Daily_backtest\\factor_high_pe_ratio_large_industry - Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "3  Daily_backtest\\factor_high_pe_ratio_medium_industry - Daily_rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal   \n",
       "4                             Daily_backtest\\factor_hml - Daily_rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "5                        Daily_backtest\\factor_momentum - Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "6         Daily_backtest\\factor_momentum_large_industry - Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal   \n",
       "7        Daily_backtest\\factor_momentum_medium_industry - Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_value   \n",
       "8                 Daily_backtest\\factor_momentum_zscore - Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal   \n",
       "9                 Daily_backtest\\factor_retained_earnings - Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal   \n",
       "\n",
       "   Sharpe Ratio  \n",
       "0      0.212378  \n",
       "1      0.353835  \n",
       "2      0.323825  \n",
       "3      0.318300  \n",
       "4      0.333881  \n",
       "5      0.265538  \n",
       "6      0.252958  \n",
       "7      0.242361  \n",
       "8      0.265538  \n",
       "9      0.353019  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한 열에 표시되는 최대 문자 수 늘리기 (긴 문자열 표시)\n",
    "# 샤프 계산 연율화에 에러 생김 + PNL 뽑히는게 월 단위와 엔드포인트 불일치\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "sharpe_ratio_df.to_csv('picked_strategy.csv', encoding='utf-8-sig')\n",
    "sharpe_ratio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090e226c-2c8d-43e6-8598-4b1443d6244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c3802-5e5c-4264-aa1c-9e2aa89b81ee",
   "metadata": {},
   "source": [
    "# CausalAI(였지만 지금은 그냥 선작업)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529cc767-cfae-45f1-bf4a-2f102c621703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 백테스팅 CSV 파일 목록:\n",
      "Daily_backtest\\factor_betting_against_beta\\Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_high_pe_ratio\\Daily_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_value.csv\n",
      "Daily_backtest\\factor_high_pe_ratio_large_industry\\Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_high_pe_ratio_medium_industry\\Daily_rebalancing_1_threshold_0_2_cutoff_0_05_weighting_equal.csv\n",
      "Daily_backtest\\factor_hml\\Daily_rebalancing_3_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_momentum\\Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_momentum_large_industry\\Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_momentum_medium_industry\\Daily_rebalancing_1_threshold_0_3_cutoff_0_1_weighting_value.csv\n",
      "Daily_backtest\\factor_momentum_zscore\\Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal.csv\n",
      "Daily_backtest\\factor_retained_earnings\\Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2. 데이터 로드 및 전처리\n",
    "2.1 선택된 백테스팅 CSV 파일 로드\n",
    "'''\n",
    "# 'best_results.txt' 파일을 읽어서 best_results 리스트를 생성\n",
    "with open('best_results.txt', 'r', encoding='utf-8') as f:\n",
    "    best_results = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"선택된 백테스팅 CSV 파일 목록:\")\n",
    "for file_path in best_results:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d055bd-18d3-4717-9215-498c88d075a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. 데이터 로드 및 전처리\n",
    "2.2 그 외 데이터 로드\n",
    "'''\n",
    "\n",
    "# 코스피/코스닥 지수 데이터 로드\n",
    "market_indices = hs.load_market_indices()\n",
    "market_indices.columns = market_indices.columns.droplevel('Symbol')\n",
    "\n",
    "# 위험 무시 수익률 데이터 로드\n",
    "rf = hs.load_risk_free_rate()\n",
    "\n",
    "# 환율 데이터 로드\n",
    "exchange_rate = hs.load_exchange_rate()\n",
    "\n",
    "# 날짜 정렬 및 결측치 처리\n",
    "market_indices = market_indices.sort_index().fillna(method='ffill').dropna()\n",
    "rf = rf.sort_index().fillna(method='ffill').dropna()\n",
    "exchange_rate = exchange_rate.sort_index().fillna(method='ffill').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf1d262-0b84-47e0-99b6-13b1824d8f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily_backtest\\factor_high_pe_ratio\n",
      "Daily_backtest\\factor_momentum\n",
      "Daily_backtest\\factor_retained_earnings\n",
      "\n",
      "합쳐진 데이터프레임의 일부:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor_high_pe_ratio_Daily_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_value_Return</th>\n",
       "      <th>factor_high_pe_ratio_Daily_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_value_Value</th>\n",
       "      <th>factor_momentum_Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return</th>\n",
       "      <th>factor_momentum_Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value</th>\n",
       "      <th>factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return</th>\n",
       "      <th>factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Value</th>\n",
       "      <th>코스피</th>\n",
       "      <th>코스닥</th>\n",
       "      <th>Risk_Free_Rate</th>\n",
       "      <th>Exchange_Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-10-31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1113.06</td>\n",
       "      <td>308.03</td>\n",
       "      <td>4.900</td>\n",
       "      <td>1289.199951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-03</th>\n",
       "      <td>0.057406</td>\n",
       "      <td>1.057406</td>\n",
       "      <td>0.041391</td>\n",
       "      <td>1.041391</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>1.039780</td>\n",
       "      <td>1129.08</td>\n",
       "      <td>325.56</td>\n",
       "      <td>4.960</td>\n",
       "      <td>1289.199951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-04</th>\n",
       "      <td>0.031381</td>\n",
       "      <td>1.090589</td>\n",
       "      <td>0.023730</td>\n",
       "      <td>1.066104</td>\n",
       "      <td>0.024778</td>\n",
       "      <td>1.065544</td>\n",
       "      <td>1153.35</td>\n",
       "      <td>335.49</td>\n",
       "      <td>4.910</td>\n",
       "      <td>1289.199951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-05</th>\n",
       "      <td>0.041892</td>\n",
       "      <td>1.136276</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>1.090990</td>\n",
       "      <td>0.044366</td>\n",
       "      <td>1.112818</td>\n",
       "      <td>1181.50</td>\n",
       "      <td>340.85</td>\n",
       "      <td>4.860</td>\n",
       "      <td>1289.199951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-06</th>\n",
       "      <td>-0.089157</td>\n",
       "      <td>1.034969</td>\n",
       "      <td>-0.069811</td>\n",
       "      <td>1.014827</td>\n",
       "      <td>-0.073928</td>\n",
       "      <td>1.030550</td>\n",
       "      <td>1092.22</td>\n",
       "      <td>311.96</td>\n",
       "      <td>4.800</td>\n",
       "      <td>1289.199951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-14</th>\n",
       "      <td>-0.000296</td>\n",
       "      <td>25.081605</td>\n",
       "      <td>-0.004530</td>\n",
       "      <td>7.389070</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>17.316785</td>\n",
       "      <td>2418.86</td>\n",
       "      <td>681.56</td>\n",
       "      <td>2.873</td>\n",
       "      <td>1378.569946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-15</th>\n",
       "      <td>0.017016</td>\n",
       "      <td>25.508405</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>7.426813</td>\n",
       "      <td>0.005914</td>\n",
       "      <td>17.419204</td>\n",
       "      <td>2416.86</td>\n",
       "      <td>685.42</td>\n",
       "      <td>2.893</td>\n",
       "      <td>1378.569946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-18</th>\n",
       "      <td>0.011886</td>\n",
       "      <td>25.811586</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>7.499531</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>17.638292</td>\n",
       "      <td>2469.07</td>\n",
       "      <td>689.55</td>\n",
       "      <td>2.894</td>\n",
       "      <td>1378.569946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-19</th>\n",
       "      <td>0.002268</td>\n",
       "      <td>25.870116</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>7.513530</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>17.720189</td>\n",
       "      <td>2471.95</td>\n",
       "      <td>686.12</td>\n",
       "      <td>2.890</td>\n",
       "      <td>1378.569946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-20</th>\n",
       "      <td>-0.001692</td>\n",
       "      <td>25.826348</td>\n",
       "      <td>-0.001172</td>\n",
       "      <td>7.504721</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>17.715650</td>\n",
       "      <td>2482.29</td>\n",
       "      <td>682.91</td>\n",
       "      <td>2.886</td>\n",
       "      <td>1378.569946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3965 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            factor_high_pe_ratio_Daily_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_value_Return  \\\n",
       "Date                                                                                                    \n",
       "2008-10-31                                                                                   0.000000   \n",
       "2008-11-03                                                                                   0.057406   \n",
       "2008-11-04                                                                                   0.031381   \n",
       "2008-11-05                                                                                   0.041892   \n",
       "2008-11-06                                                                                  -0.089157   \n",
       "...                                                                                               ...   \n",
       "2024-11-14                                                                                  -0.000296   \n",
       "2024-11-15                                                                                   0.017016   \n",
       "2024-11-18                                                                                   0.011886   \n",
       "2024-11-19                                                                                   0.002268   \n",
       "2024-11-20                                                                                  -0.001692   \n",
       "\n",
       "            factor_high_pe_ratio_Daily_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_value_Value  \\\n",
       "Date                                                                                                   \n",
       "2008-10-31                                                                                  1.000000   \n",
       "2008-11-03                                                                                  1.057406   \n",
       "2008-11-04                                                                                  1.090589   \n",
       "2008-11-05                                                                                  1.136276   \n",
       "2008-11-06                                                                                  1.034969   \n",
       "...                                                                                              ...   \n",
       "2024-11-14                                                                                 25.081605   \n",
       "2024-11-15                                                                                 25.508405   \n",
       "2024-11-18                                                                                 25.811586   \n",
       "2024-11-19                                                                                 25.870116   \n",
       "2024-11-20                                                                                 25.826348   \n",
       "\n",
       "            factor_momentum_Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return  \\\n",
       "Date                                                                                              \n",
       "2008-10-31                                                                             0.000000   \n",
       "2008-11-03                                                                             0.041391   \n",
       "2008-11-04                                                                             0.023730   \n",
       "2008-11-05                                                                             0.023343   \n",
       "2008-11-06                                                                            -0.069811   \n",
       "...                                                                                         ...   \n",
       "2024-11-14                                                                            -0.004530   \n",
       "2024-11-15                                                                             0.005108   \n",
       "2024-11-18                                                                             0.009791   \n",
       "2024-11-19                                                                             0.001867   \n",
       "2024-11-20                                                                            -0.001172   \n",
       "\n",
       "            factor_momentum_Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Value  \\\n",
       "Date                                                                                             \n",
       "2008-10-31                                                                            1.000000   \n",
       "2008-11-03                                                                            1.041391   \n",
       "2008-11-04                                                                            1.066104   \n",
       "2008-11-05                                                                            1.090990   \n",
       "2008-11-06                                                                            1.014827   \n",
       "...                                                                                        ...   \n",
       "2024-11-14                                                                            7.389070   \n",
       "2024-11-15                                                                            7.426813   \n",
       "2024-11-18                                                                            7.499531   \n",
       "2024-11-19                                                                            7.513530   \n",
       "2024-11-20                                                                            7.504721   \n",
       "\n",
       "            factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return  \\\n",
       "Date                                                                                                     \n",
       "2008-10-31                                                                                    0.000000   \n",
       "2008-11-03                                                                                    0.039780   \n",
       "2008-11-04                                                                                    0.024778   \n",
       "2008-11-05                                                                                    0.044366   \n",
       "2008-11-06                                                                                   -0.073928   \n",
       "...                                                                                                ...   \n",
       "2024-11-14                                                                                    0.002175   \n",
       "2024-11-15                                                                                    0.005914   \n",
       "2024-11-18                                                                                    0.012577   \n",
       "2024-11-19                                                                                    0.004643   \n",
       "2024-11-20                                                                                   -0.000256   \n",
       "\n",
       "            factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Value  \\\n",
       "Date                                                                                                    \n",
       "2008-10-31                                                                                   1.000000   \n",
       "2008-11-03                                                                                   1.039780   \n",
       "2008-11-04                                                                                   1.065544   \n",
       "2008-11-05                                                                                   1.112818   \n",
       "2008-11-06                                                                                   1.030550   \n",
       "...                                                                                               ...   \n",
       "2024-11-14                                                                                  17.316785   \n",
       "2024-11-15                                                                                  17.419204   \n",
       "2024-11-18                                                                                  17.638292   \n",
       "2024-11-19                                                                                  17.720189   \n",
       "2024-11-20                                                                                  17.715650   \n",
       "\n",
       "                코스피     코스닥  Risk_Free_Rate  Exchange_Rate  \n",
       "Date                                                        \n",
       "2008-10-31  1113.06  308.03           4.900    1289.199951  \n",
       "2008-11-03  1129.08  325.56           4.960    1289.199951  \n",
       "2008-11-04  1153.35  335.49           4.910    1289.199951  \n",
       "2008-11-05  1181.50  340.85           4.860    1289.199951  \n",
       "2008-11-06  1092.22  311.96           4.800    1289.199951  \n",
       "...             ...     ...             ...            ...  \n",
       "2024-11-14  2418.86  681.56           2.873    1378.569946  \n",
       "2024-11-15  2416.86  685.42           2.893    1378.569946  \n",
       "2024-11-18  2469.07  689.55           2.894    1378.569946  \n",
       "2024-11-19  2471.95  686.12           2.890    1378.569946  \n",
       "2024-11-20  2482.29  682.91           2.886    1378.569946  \n",
       "\n",
       "[3965 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2.3 전략 데이터 로드 및 합치기\n",
    "'''\n",
    "#딱 세 개만 사용 : 위의 전략 목록중 3개 임의로 선택\n",
    "best_results = [best_results[1], best_results[5]\n",
    "                , best_results[9]\n",
    "               ]\n",
    "\n",
    "# 각 전략의 월별 수익률과 포트폴리오 가치를 저장할 데이터프레임 리스트 초기화\n",
    "strategy_returns = []\n",
    "\n",
    "# 각 CSV 파일을 읽어서 데이터프레임 생성\n",
    "for csv_file in best_results:\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(csv_file, index_col=0, parse_dates=True)\n",
    "    \n",
    "    # 전략 이름 생성\n",
    "    folder_name, file_name = os.path.split(csv_file)\n",
    "    print(folder_name)\n",
    "    factor_name = folder_name.split('\\\\')[-1]\n",
    "    strategy_info = file_name.replace('.csv', '')\n",
    "    strategy_name = f\"{factor_name}_{strategy_info}\"\n",
    "    \n",
    "    # 'Monthly Return'과 'Portfolio Value' 컬럼 존재 여부 확인\n",
    "    if 'Daily Return' in df.columns and 'Portfolio Value' in df.columns:\n",
    "        # 데이터프레임에 전략 이름을 접두사로 추가하여 컬럼 이름 변경\n",
    "        df = df[['Daily Return', 'Portfolio Value']].copy()\n",
    "        df.columns = [f\"{strategy_name}_Return\", f\"{strategy_name}_Value\"]\n",
    "        \n",
    "        # 리스트에 추가\n",
    "        strategy_returns.append(df)\n",
    "    else:\n",
    "        print(f\"'Monthly Return' 또는 'Portfolio Value' 컬럼이 없습니다: {csv_file}\")\n",
    "\n",
    "# 모든 전략의 데이터프레임을 하나로 합치기\n",
    "combined_df = pd.concat(strategy_returns, axis=1)\n",
    "\n",
    "# 날짜로 정렬\n",
    "combined_df = combined_df.sort_index()\n",
    "\n",
    "# 추가 데이터 합치기\n",
    "combined_df = combined_df.join(market_indices, how='left')\n",
    "combined_df = combined_df.join(rf, how='left')\n",
    "combined_df = combined_df.join(exchange_rate, how='left')\n",
    "\n",
    "# 결측치 처리 (앞 방향으로 채우기)\n",
    "combined_df = combined_df.fillna(method='ffill').dropna()\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\n합쳐진 데이터프레임의 일부:\")\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e15bf82-a76e-4e86-8e54-f208de69d4c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "레이블이 추가된 데이터프레임의 일부:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best_Strategy</th>\n",
       "      <th>Best_Strategy_Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-10-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-14</th>\n",
       "      <td>factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-15</th>\n",
       "      <td>factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-18</th>\n",
       "      <td>factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-19</th>\n",
       "      <td>factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-20</th>\n",
       "      <td>factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3965 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         Best_Strategy  \\\n",
       "Date                                                                                                     \n",
       "2008-10-31                                                                                         NaN   \n",
       "2008-11-03                                                                                         NaN   \n",
       "2008-11-04                                                                                         NaN   \n",
       "2008-11-05                                                                                         NaN   \n",
       "2008-11-06                                                                                         NaN   \n",
       "...                                                                                                ...   \n",
       "2024-11-14  factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return   \n",
       "2024-11-15  factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return   \n",
       "2024-11-18  factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return   \n",
       "2024-11-19  factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return   \n",
       "2024-11-20  factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return   \n",
       "\n",
       "            Best_Strategy_Label  \n",
       "Date                             \n",
       "2008-10-31                    3  \n",
       "2008-11-03                    3  \n",
       "2008-11-04                    3  \n",
       "2008-11-05                    3  \n",
       "2008-11-06                    3  \n",
       "...                         ...  \n",
       "2024-11-14                    2  \n",
       "2024-11-15                    2  \n",
       "2024-11-18                    2  \n",
       "2024-11-19                    2  \n",
       "2024-11-20                    2  \n",
       "\n",
       "[3965 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3. 레이블 생성\n",
    "'''\n",
    "# 각 시점마다 가장 높은 수익률을 보인 전략의 이름을 레이블로 생성\n",
    "return_columns = [col for col in combined_df.columns if '_Return' in col]\n",
    "# combined_df['Best_Strategy'] = combined_df[return_columns].idxmax(axis=1)\n",
    "# combined_df['Best_Strategy'] = combined_df[return_columns].rolling(window=21).mean().dropna().idxmax(axis=1)\n",
    "# 21 timestep 이동 누적 수익률 계산\n",
    "combined_df['Best_Strategy'] = combined_df[return_columns] \\\n",
    "    .rolling(window=21) \\\n",
    "    .apply(lambda x: (1 + x).prod() - 1, raw=True) \\\n",
    "    .dropna() \\\n",
    "    .idxmax(axis=1)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "combined_df['Best_Strategy_Label'] = label_encoder.fit_transform(combined_df['Best_Strategy'])\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\n레이블이 추가된 데이터프레임의 일부:\")\n",
    "combined_df[['Best_Strategy', 'Best_Strategy_Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a4ce0eb-e5a2-425b-8440-989e9735cf49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 개수: 2947\n",
      "Best_Strategy_Label\n",
      "0    1225\n",
      "2     881\n",
      "1     841\n",
      "Name: count, dtype: int64\n",
      "Validation 데이터 개수: 473\n",
      "Best_Strategy_Label\n",
      "1    167\n",
      "0    154\n",
      "2    152\n",
      "Name: count, dtype: int64\n",
      "Test 데이터 개수: 470\n",
      "Best_Strategy_Label\n",
      "0    164\n",
      "1    158\n",
      "2    148\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_start_date = pd.to_datetime('2008-11-28')\n",
    "train_end_date = pd.to_datetime('2020-10-31')\n",
    "val_start_date = pd.to_datetime('2020-11-30')\n",
    "val_end_date = pd.to_datetime('2022-10-31')\n",
    "test_start_date = pd.to_datetime('2022-11-30')\n",
    "test_end_date = pd.to_datetime('2024-10-31')\n",
    "\n",
    "# Train, validation, test 데이터 나누기\n",
    "train_data = combined_df[(combined_df.index >= train_start_date) & (combined_df.index <= train_end_date)]\n",
    "val_data = combined_df[(combined_df.index >= val_start_date) & (combined_df.index <= val_end_date)]\n",
    "test_data = combined_df[(combined_df.index >= test_start_date) & (combined_df.index <= test_end_date)]\n",
    "\n",
    "# 각 데이터셋의 샘플 개수 출력\n",
    "print(f\"Train 데이터 개수: {len(train_data)}\")\n",
    "print(train_data['Best_Strategy_Label'].value_counts())\n",
    "print(f\"Validation 데이터 개수: {len(val_data)}\")\n",
    "print(val_data['Best_Strategy_Label'].value_counts())\n",
    "print(f\"Test 데이터 개수: {len(test_data)}\")\n",
    "print(test_data['Best_Strategy_Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e686c-daf2-4ac9-854a-c80b5b4ec41c",
   "metadata": {},
   "source": [
    "# 딥-러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "312d6126-8d49-4611-a625-ce84d1d710fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# 0. 가정된 전역 변수들 (사용 예)\n",
    "###################################\n",
    "# 날짜 범위\n",
    "train_start_date = pd.to_datetime('2008-11-28')\n",
    "train_end_date = pd.to_datetime('2018-10-31')\n",
    "val_start_date = pd.to_datetime('2018-11-30')\n",
    "val_end_date = pd.to_datetime('2021-10-31')\n",
    "test_start_date = pd.to_datetime('2021-11-30')\n",
    "test_end_date = pd.to_datetime('2024-10-31')\n",
    "\n",
    "label_col = 'Best_Strategy_Label'\n",
    "strategy_return_cols = [\n",
    "    'factor_high_pe_ratio_Daily_rebalancing_1_threshold_0_1_cutoff_0_05_weighting_value_Return',\n",
    "    'factor_momentum_Daily_rebalancing_1_threshold_0_2_cutoff_0_1_weighting_equal_Return',\n",
    "    'factor_retained_earnings_Daily_rebalancing_3_threshold_0_1_cutoff_0_weighting_equal_Return'\n",
    "]\n",
    "\n",
    "num_classes = len(strategy_return_cols)\n",
    "\n",
    "# feature_cols에서 다음을 제외:\n",
    "# - 타겟 라벨(Best_Strategy_Label)\n",
    "# - 직접적으로 전략 수익률 컬럼(strategy_return_cols)\n",
    "# - Best_Strategy (라벨과 유사, 미래예측에 활용 불가한 정보)\n",
    "#\n",
    "# pct_change나 Value_zscore 컬럼도 사용해볼 수 있으므로 제외 조건 제거\n",
    "feature_cols = [\n",
    "    col for col in combined_df.columns \n",
    "    if col not in [label_col, 'Best_Strategy']# + strategy_return_cols\n",
    "]\n",
    "\n",
    "# Hyperparameters\n",
    "lookback = 252*2\n",
    "batch_size = 64\n",
    "epochs = 800\n",
    "learning_rate = 0.00001*5*2\n",
    "use_gru = True  # True면 GRU, False면 LSTM\n",
    "use_oversampling = True  # 오버샘플링 여부 (GAN augment)\n",
    "unit = 16*2\n",
    "augment_ratio = 0.7\n",
    "gan_generator_path = 'gan_generator.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c1cc9e0-48a1-44cb-b249-40e8ce061042",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# 함수 정의 (반복적으로 사용하는 것만)\n",
    "###################################\n",
    "def custom_loss_fn(y_true, y_pred, returns):\n",
    "    actual_return = tf.reduce_sum(y_true * returns, axis=1)\n",
    "    predicted_return = tf.reduce_sum(y_pred * returns, axis=1)\n",
    "    return tf.reduce_mean(tf.square(actual_return - predicted_return))\n",
    "    \n",
    "######################\n",
    "# cross-entropy 버전 (주석 해제 시 아래 코드로 교체)\n",
    "######################\n",
    "# def custom_loss_fn(y_true, y_pred, returns):\n",
    "#     # returns를 사용하지 않고 cross-entropy 손실을 계산\n",
    "#     # y_true: one-hot 인코딩된 라벨\n",
    "#     # y_pred: softmax 출력\n",
    "#     # 참고: returns 인자는 이 버전에서는 사용하지 않습니다.\n",
    "#     epsilon = 1e-7\n",
    "#     y_pred_clipped = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "#     cross_entropy = -tf.reduce_sum(y_true * tf.math.log(y_pred_clipped), axis=1)\n",
    "#     return tf.reduce_mean(cross_entropy)\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, optimizer, x, y, r):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True)\n",
    "        loss_value = custom_loss_fn(y, y_pred, r)\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def val_step(model, x, y, r):\n",
    "    y_pred = model(x, training=False)\n",
    "    loss_value = custom_loss_fn(y, y_pred, r)\n",
    "    return loss_value, y_pred\n",
    "\n",
    "def scale_returns(train_ret, val_ret, test_ret):\n",
    "    scaler = StandardScaler()\n",
    "    train_ret_scaled = scaler.fit_transform(train_ret)\n",
    "    val_ret_scaled = scaler.transform(val_ret)\n",
    "    test_ret_scaled = scaler.transform(test_ret)\n",
    "    return train_ret_scaled, val_ret_scaled, test_ret_scaled\n",
    "\n",
    "# create_sequences\n",
    "def create_sequences(X, y, returns, lookback=lookback):\n",
    "    X_seq, y_seq, ret_seq = [], [], []\n",
    "    for i in range(len(X)-lookback):\n",
    "        X_seq.append(X[i:i+lookback])\n",
    "        y_seq.append(y[i+lookback])\n",
    "        ret_seq.append(returns[i+lookback])\n",
    "    return np.array(X_seq), np.array(y_seq), np.array(ret_seq)\n",
    "\n",
    "# Early Stopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.best_val_loss = np.inf\n",
    "        self.counter = 0\n",
    "        self.stop_training = False\n",
    "\n",
    "    def check(self, val_loss):\n",
    "        if val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        if self.counter >= self.patience:\n",
    "            self.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f814d7a-30f3-47bf-8e34-230f4c366214",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# GAN 관련 함수\n",
    "###################################\n",
    "def build_discriminator(input_dim):\n",
    "    \"\"\"\n",
    "    기능: Discriminator 모델 생성\n",
    "    입력:\n",
    "      input_dim: 입력 벡터 차원\n",
    "    출력:\n",
    "      model: discriminator 모델\n",
    "    \"\"\"\n",
    "    x = tf.keras.Input(shape=(input_dim,))\n",
    "    h = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    h = tf.keras.layers.Dense(32, activation='relu')(h)\n",
    "    out = tf.keras.layers.Dense(1, activation='sigmoid')(h)\n",
    "    model = tf.keras.Model(x, out)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    return model\n",
    "\n",
    "def build_generator(noise_dim, output_dim):\n",
    "    \"\"\"\n",
    "    기능: Generator 모델 생성\n",
    "    입력:\n",
    "      noise_dim: 노이즈 벡터 크기\n",
    "      output_dim: 출력 벡터 크기\n",
    "    출력:\n",
    "      model: generator 모델\n",
    "    \"\"\"\n",
    "    z = tf.keras.Input(shape=(noise_dim,))\n",
    "    h = tf.keras.layers.Dense(64, activation='relu')(z)\n",
    "    h = tf.keras.layers.Dense(128, activation='relu')(h)\n",
    "    out = tf.keras.layers.Dense(output_dim, activation='linear')(h)\n",
    "    model = tf.keras.Model(z, out)\n",
    "    return model\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    \"\"\"\n",
    "    기능: GAN 모델(g->d) 생성\n",
    "    입력:\n",
    "      generator, discriminator\n",
    "    출력:\n",
    "      gan_model\n",
    "    \"\"\"\n",
    "    discriminator.trainable = False\n",
    "    z = tf.keras.Input(shape=(noise_dim,))\n",
    "    fake = generator(z)\n",
    "    validity = discriminator(fake)\n",
    "    gan_model = tf.keras.Model(z, validity)\n",
    "    gan_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0005))\n",
    "    return gan_model\n",
    "\n",
    "def train_gan(real_data, epochs=1000, batch_size=128, noise_dim=16, generator_path='gan_generator.keras'):\n",
    "    \"\"\"\n",
    "    기능: GAN 학습 (이미 generator_path에 모델 있으면 로드)\n",
    "    입력:\n",
    "      real_data: (samples, dim), log(1+x) 변환된 _return + other cols 데이터\n",
    "      epochs, batch_size, noise_dim, generator_path\n",
    "    출력:\n",
    "      g: 학습된 generator 모델\n",
    "    \"\"\"\n",
    "    if os.path.exists(generator_path):\n",
    "        g = tf.keras.models.load_model(generator_path, compile=False)\n",
    "        return g\n",
    "\n",
    "    d = build_discriminator(real_data.shape[1])\n",
    "    g = build_generator(noise_dim, real_data.shape[1])\n",
    "    gan = build_gan(g, d)\n",
    "\n",
    "    half_batch = batch_size // 2\n",
    "\n",
    "    # epoch마다 메모리 정리 및 모델 부분 저장\n",
    "    save_interval = 200\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, real_data.shape[0], half_batch)\n",
    "        real_batch = real_data[idx]\n",
    "        noise = np.random.uniform(-1., 1., size=(half_batch, noise_dim))\n",
    "        fake_batch = g.predict(noise)\n",
    "\n",
    "        combined_batch = np.concatenate([real_batch, fake_batch], axis=0)\n",
    "        labels = np.zeros(half_batch*2)\n",
    "        labels[:half_batch] = 0.9\n",
    "        labels[half_batch:] = 0.1\n",
    "        d_loss = d.train_on_batch(combined_batch, labels)\n",
    "        del combined_batch, real_batch, fake_batch\n",
    "        gc.collect()\n",
    "        \n",
    "        noise = np.random.uniform(-1., 1., size=(batch_size, noise_dim))\n",
    "        valid_y = np.ones((batch_size,)) * 0.9\n",
    "        g_loss = gan.train_on_batch(noise, valid_y)\n",
    "        del noise, valid_y\n",
    "        gc.collect()\n",
    "        \n",
    "        # d_loss, g_loss가 리스트 형태일 경우 첫 번째 요소만 취함\n",
    "        if isinstance(d_loss, list):\n",
    "            d_loss = d_loss[0]\n",
    "        if isinstance(g_loss, list):\n",
    "            g_loss = g_loss[0]\n",
    "\n",
    "        d_loss = float(d_loss)\n",
    "        g_loss = float(g_loss)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"GAN Epoch {epoch}, D-Loss: {d_loss:.4f}, G-Loss: {g_loss:.4f}\")\n",
    "\n",
    "        # 일정 주기마다 generator 저장\n",
    "        if epoch % save_interval == 0 and epoch > 0:\n",
    "            g.save(generator_path)\n",
    "            gc.collect()    \n",
    "    \n",
    "    g.save(generator_path)\n",
    "    gc.collect()\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42f40547-1fb4-4ce2-b07e-7a6996662566",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# 메인 코드 시작\n",
    "###################################\n",
    "# 2. Train/Val/Test split\n",
    "train_df = combined_df.loc[train_start_date:train_end_date]\n",
    "val_df = combined_df.loc[val_start_date:val_end_date]\n",
    "test_df = combined_df.loc[test_start_date:test_end_date]\n",
    "\n",
    "# 차분, PCA 등 전처리 완료 후 스케일링 전 단계\n",
    "train_df[feature_cols] = train_df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "val_df[feature_cols] = val_df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "test_df[feature_cols] = test_df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 결측치 드롭 (필요 시 전략적으로 처리)\n",
    "train_df = train_df.dropna(subset=feature_cols)\n",
    "val_df = val_df.dropna(subset=feature_cols)\n",
    "test_df = test_df.dropna(subset=feature_cols)\n",
    "\n",
    "# feature_cols 분리: value_cols, return_cols, other_cols\n",
    "value_cols = [c for c in feature_cols if c.endswith('_Value')]\n",
    "return_cols = [c for c in feature_cols if c.endswith('_Return')]\n",
    "other_cols = [c for c in feature_cols if c not in value_cols + return_cols]\n",
    "\n",
    "# 4. Scaling feature_cols\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_df[feature_cols])\n",
    "val_X = scaler.transform(val_df[feature_cols])\n",
    "test_X = scaler.transform(test_df[feature_cols])\n",
    "\n",
    "# 라벨, 리턴 추출\n",
    "train_y = train_df[label_col].values\n",
    "val_y = val_df[label_col].values\n",
    "test_y = test_df[label_col].values\n",
    "\n",
    "train_r = train_df[strategy_return_cols].values\n",
    "val_r = val_df[strategy_return_cols].values\n",
    "test_r = test_df[strategy_return_cols].values\n",
    "\n",
    "# 수익률 스케일링\n",
    "train_r, val_r, test_r = scale_returns(train_r, val_r, test_r)\n",
    "\n",
    "train_X_seq, train_y_seq, train_ret_seq = create_sequences(train_X, train_y, train_r, lookback)\n",
    "val_X_seq, val_y_seq, val_ret_seq = create_sequences(val_X, val_y, val_r, lookback)\n",
    "test_X_seq, test_y_seq, test_ret_seq = create_sequences(test_X, test_y, test_r, lookback)\n",
    "\n",
    "# One-hot label\n",
    "train_y_cat = tf.keras.utils.to_categorical(train_y_seq, num_classes=num_classes)\n",
    "val_y_cat = tf.keras.utils.to_categorical(val_y_seq, num_classes=num_classes)\n",
    "test_y_cat = tf.keras.utils.to_categorical(test_y_seq, num_classes=num_classes)\n",
    "\n",
    "train_X_seq = train_X_seq.astype(np.float32)\n",
    "train_y_cat = train_y_cat.astype(np.float32)\n",
    "train_ret_seq = train_ret_seq.astype(np.float32)\n",
    "\n",
    "val_X_seq = val_X_seq.astype(np.float32)\n",
    "val_y_cat = val_y_cat.astype(np.float32)\n",
    "val_ret_seq = val_ret_seq.astype(np.float32)\n",
    "\n",
    "test_X_seq = test_X_seq.astype(np.float32)\n",
    "test_y_cat = test_y_cat.astype(np.float32)\n",
    "test_ret_seq = test_ret_seq.astype(np.float32)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# value_cols 인덱스 추출\n",
    "all_cols = feature_cols\n",
    "value_idx = [all_cols.index(c) for c in value_cols]\n",
    "return_idx = [all_cols.index(c) for c in return_cols]\n",
    "other_idx = [all_cols.index(c) for c in other_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b444232f-a2f9-409d-89da-56d5f3afd44f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before augmentation : (1950, 504, 10)\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "After augmentation : (3315, 504, 10)\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# GAN 오버샘플링\n",
    "###################################\n",
    "if use_oversampling:\n",
    "    print(f'Before augmentation : {train_X_seq.shape}')\n",
    "    # GAN 대상: return_cols + other_cols\n",
    "    # log(1+x) 변환, x는 일별수익률 개념 가정\n",
    "    # train_X_seq[..., return_idx + other_idx]\n",
    "    gan_idx = return_idx + other_idx\n",
    "    gan_data_seq = train_X_seq[..., gan_idx]  # (samples, lookback, len(gan_idx))\n",
    "    s, lb, gd_dim = gan_data_seq.shape\n",
    "    gan_data_flat = gan_data_seq.reshape(s, lb*gd_dim)\n",
    "    # log(1+x) 변환\n",
    "    # x > -1 가정 필요\n",
    "    gan_data_flat = np.log(1.0 + gan_data_flat)\n",
    "\n",
    "    noise_dim = 16\n",
    "    g = train_gan(gan_data_flat, epochs=1000, batch_size=128, noise_dim=noise_dim, generator_path=gan_generator_path)\n",
    "\n",
    "    augment_count = int(s * augment_ratio)\n",
    "    noise = np.random.uniform(-1., 1., size=(augment_count, noise_dim))\n",
    "    synthetic_gan_flat = g.predict(noise)\n",
    "    # exp(...) - 1 역변환\n",
    "    synthetic_gan_flat = np.exp(synthetic_gan_flat)-1.0\n",
    "    synthetic_gan_seq = synthetic_gan_flat.reshape(augment_count, lb, gd_dim).astype(np.float32)\n",
    "\n",
    "    # synthetic_gan_seq가 return_cols + other_cols 값\n",
    "    # value_cols는 return_cols 기반으로 재계산 필요\n",
    "    # return_cols는 일별수익률이므로 누적해서 value 계산\n",
    "    # 우선 synthetic_X_seq 만들기\n",
    "    synthetic_X_seq = np.zeros((augment_count, lb, len(all_cols)), dtype=np.float32)\n",
    "    # return_cols + other_cols 대입\n",
    "    for i, idx_ in enumerate(gan_idx):\n",
    "        synthetic_X_seq[..., idx_] = synthetic_gan_seq[..., i]\n",
    "\n",
    "    # value_cols 재계산: value(t)=value(t-1)*(1+return(t)) 가정\n",
    "    # return_cols와 value_cols는 1:1 매칭 가정\n",
    "    # return_cols.sort(), value_cols.sort() 해서 매칭 (여기서는 단순히 인덱스 순서대로 매칭 가정)\n",
    "    return_cols_sorted = sorted(return_cols)\n",
    "    value_cols_sorted = sorted(value_cols)\n",
    "    # 인덱스 정렬\n",
    "    return_idx_sorted = [all_cols.index(c) for c in return_cols_sorted]\n",
    "    value_idx_sorted = [all_cols.index(c) for c in value_cols_sorted]\n",
    "\n",
    "    for r_i, v_i in zip(return_idx_sorted, value_idx_sorted):\n",
    "        # 각 시퀀스별 value 복원\n",
    "        # value(0)=1로 시작해서 cumulative\n",
    "        for sample_i in range(augment_count):\n",
    "            returns_arr = synthetic_X_seq[sample_i, :, r_i]\n",
    "            value_arr = np.zeros(lb, dtype=np.float32)\n",
    "            val = 1.0\n",
    "            for t in range(lb):\n",
    "                val = val*(1.0+returns_arr[t])\n",
    "                value_arr[t] = val\n",
    "            synthetic_X_seq[sample_i, :, v_i] = value_arr\n",
    "\n",
    "    # 라벨 및 ret_seq, y_cat도 기존에서 샘플링\n",
    "    rand_idx = np.random.randint(0, s, size=augment_count)\n",
    "    synthetic_y_cat = train_y_cat[rand_idx]\n",
    "    synthetic_ret_seq = train_ret_seq[rand_idx]\n",
    "    del rand_idx, noise, g\n",
    "    gc.collect()\n",
    "    \n",
    "    # synthetic_X_seq를 기존 X_seq 앞에 붙여 과거데이터 확장\n",
    "    train_X_seq = np.concatenate([synthetic_X_seq, train_X_seq], axis=0)\n",
    "    train_y_cat = np.concatenate([synthetic_y_cat, train_y_cat], axis=0)\n",
    "    train_ret_seq = np.concatenate([synthetic_ret_seq, train_ret_seq], axis=0)\n",
    "    print(f'After augmentation : {train_X_seq.shape}')\n",
    "    # 아무튼 만들어졌으니 좋았으!\n",
    "    # del synthetic_data, synthetic_y_cat, synthetic_ret_seq\n",
    "    # gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3de8fb54-6028-445e-b75b-c110a5d7ed80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 7. 모델 정의\n",
    "model = Sequential()\n",
    "if use_gru:\n",
    "    model.add(GRU(units=unit, activation='elu', input_shape=(lookback, len(feature_cols))))\n",
    "else:\n",
    "    model.add(LSTM(units=unit, activation='elu', input_shape=(lookback, len(feature_cols))))\n",
    "\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dense(int(unit), activation='elu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(int(unit), activation='elu', kernel_regularizer=regularizers.l2(1e-5)))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(int(unit), activation='elu', kernel_regularizer=regularizers.l2(1e-5)))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19139851-59a9-4152-ba7e-7f3ddc05b762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0806, Val Loss: 0.0888\n",
      "Epoch 20, Train Loss: 0.0781, Val Loss: 0.0802\n",
      "Epoch 30, Train Loss: 0.0762, Val Loss: 0.0743\n",
      "Epoch 40, Train Loss: 0.0747, Val Loss: 0.0705\n",
      "Epoch 50, Train Loss: 0.0730, Val Loss: 0.0682\n",
      "Epoch 60, Train Loss: 0.0712, Val Loss: 0.0674\n"
     ]
    }
   ],
   "source": [
    "# 8. Dataset 준비\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_X_seq, train_y_cat, train_ret_seq)).shuffle(1024).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_X_seq, val_y_cat, val_ret_seq)).batch(batch_size)\n",
    "\n",
    "# 여기서 더미 인퍼런스 한 번 실행 (train_dataset에서 하나 추출)\n",
    "# Creating variables on a non-first call to a function decorated with tf.function 에러 방지용\n",
    "x_dummy, y_dummy, r_dummy = next(iter(train_dataset))\n",
    "model(x_dummy)  # 이렇게 한 번 호출해서 변수 생성 완료\n",
    "\n",
    "best_val_loss = np.inf\n",
    "patience = 50  # Early Stopping 기준이 되는 patience 값\n",
    "early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "# 손실 저장용 리스트\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    for x_batch, y_batch, r_batch in train_dataset:\n",
    "        loss_value = train_step(model, optimizer, x_batch, y_batch, r_batch)\n",
    "        train_losses.append(loss_value.numpy())\n",
    "\n",
    "    val_losses = []\n",
    "    for x_batch, y_batch, r_batch in val_dataset:\n",
    "        val_loss_value, _ = val_step(model, x_batch, y_batch, r_batch)\n",
    "        val_losses.append(val_loss_value.numpy())\n",
    "\n",
    "    val_loss_mean = np.mean(val_losses)\n",
    "    train_loss_mean = np.mean(train_losses)\n",
    "    train_loss_history.append(train_loss_mean)\n",
    "    val_loss_history.append(val_loss_mean)\n",
    "    \n",
    "    if epoch%10==9:\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss_mean:.4f}, Val Loss: {val_loss_mean:.4f}\")\n",
    "\n",
    "    if val_loss_mean < best_val_loss:\n",
    "        best_val_loss = val_loss_mean\n",
    "        model.save('best_model.keras')\n",
    "\n",
    "    # Early Stopping 체크\n",
    "    early_stopping.check(val_loss_mean)\n",
    "    if early_stopping.stop_training:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "#0.644"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc398f30-febd-4785-9654-5a48286e9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=range(1, len(train_loss_history) + 1), y=train_loss_history, label=\"Train Loss\")\n",
    "sns.lineplot(x=range(1, len(val_loss_history) + 1), y=val_loss_history, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train and Validation Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c292c-5c08-44ca-b430-bef31a484113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
